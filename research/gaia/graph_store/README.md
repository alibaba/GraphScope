# Overview
The codes maintain the distributed graph storage for GAIA. We adopt the property graph model as
advocated in modern graph databses such as [Neo4j](https://neo4j.com/) adn [Tinkerpop](https://tinkerpop.apache.org/). 
We split the graph data into two parts, namely structure data and property data. The structure data contains
vertices and edges and their labels. Each vertex is identified by a globally unique identity, while the edges are
maintained in the associated vertices using the conventional adjacency list. We leverage the Rust graph library
[petgraph](https://github.com/petgraph/petgraph) to maintain the structure data.

The property data are maintained in a variety of ways, as can be found in `src/table.rs`, namely:
* `PropertyTable`: The default option of in-memory hash table.
* `SingleValueTable`: An optimized in-memory table that maintains one single value. Altough vertices
usually contain multiple properties, it is very common for the edges to only contain on single property in practice.
  In addition, edges are often in a much larger order (10X~100X largers) than vertices. We thus implement `SingleValueTable`
  as an optimization to ease the edges' storage burden.

# Usage of LDBC Parser
## Preliminaries
We currently provide a tool for parsing (and partitioning) the LDBC raw data generated by
[LDBC Datagen](https://github.com/ldbc/ldbc_snb_datagen) into our distributed storage. 
LDBC vertices are uniquely identified by its vertex type (label) and id. We leverage this feature by mapping
each vertex label to a label id, and then assign each vertex a globally unique id using the combination
of its label id and ldbc id. Note that certain vertex may have two-level (parimary and secondary) label, for 
example, a `Company` vertex also has a primary label of `Organization`. In this case, the primary 
label will be used. Edge is not the first-class citizen in our design, and will be indexed
according to its source (and target) vertex. Given the global id, partitioning is straightforward: 
in a cluster of k machines, we randomly assign each vertex to one of the machines according to the hash value of its global id; 
the edges associated with a vertex v will be placed in the machine of v. Here, both the incoming and outgoing edges
are considered by default, while an option of only outgoing edges will be provided. 

## LDBC Data Gen & Preprocess
After generating LDBC data in HDFS, there is a folder like `hdfs://<ip:port>/path/to/ldbc/data/social_network_xx/`, in which
the vertex data of type `VType` is maintained in the file of `VType_0_0.csv`, and the edge data of type `EType` (with
source vertex typed `<SrcType>` and target vertex typed `<TgtType>`) in maintained in the file of 
`<SrcType_EType_TgtType_0_0.csv>`. We require users to write a Hadoop MR program to initially partition the raw graph 
data. After the pre-partitioning, the vertex data `VType_0_0.csv` must be stored in a folder of 
`hdfs://<ip:port>/path/to/partitioned/data/VType/` that has the file fragments of `part-0000`, `part-0001` etc.
Same applies to each edge data. 

## Data Schema
The schema contains the following metadata for the graph storage:
* Mapping from vertex label to label id.
* Mapping from edge label to a 3-tuple, which contains edge label id, ource vertex label id, and target vertex
  label id. 
* The properties (name and datatype) of each type of vertex/edge.

The schema file is formatted using Json. We have provided a sampled schema file for LDBC data in `data/schema.json`.

