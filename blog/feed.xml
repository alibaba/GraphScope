<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title></title>
    <description>graphscope blog</description>
    <link>https://graphscope.io/blog/</link>
    <atom:link href="https://graphscope.io/blog/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Mon, 31 May 2021 15:01:12 +0800</pubDate>
    <lastBuildDate>Mon, 31 May 2021 15:01:12 +0800</lastBuildDate>
    <generator>Jekyll v4.1.1</generator>

    <item>
<title>Release Notes: v0.8.0</title>
<description><p><img src="/blog/assets/images/release_note_t.png" alt="release-note" /> We are glad to announce the availability of GraphScope v0.8. This release is a major update on many aspects of the project including deployment, system speed and APIs. For quickly getting started, this release supports to use GraphScope on standalone mode without Kubernetes. To improve the efficiency of operators and applications in NetworkX module, an immutable graph is applied by default, while it is converted to a dynamic graph only if modification operators for graphs are triggered. In addition, a notebook is integrated into the helm charts.</p> <p>We highlight the following improvements included in this release:</p> <ol> <li>Standalone mode support for GraphScope: <ul> <li>Users now can do <code class="language-plaintext highlighter-rouge">pip install graphscope</code> to deploy GraphScope together with runtime dependencies;</li> <li>Users now switch to <code class="language-plaintext highlighter-rouge">pip install graphscope_client</code> to install python client of GraphScope;</li> <li>MacOS support is added, and it is compatible with Apple clang 13.0.0.</li> </ul> </li> <li>Enhancement on <code class="language-plaintext highlighter-rouge">graphscope.nx</code> module: <ul> <li>Support NetworkX operators over immutable graphs;</li> <li>Support holding an immutable graph in <code class="language-plaintext highlighter-rouge">nx.Graph</code> and <code class="language-plaintext highlighter-rouge">copy-on-write</code> to a dynamic graph.</li> </ul> </li> <li>Enhancement of deployment, performance and APIs: <ul> <li>Integrate a jupyter-lab notebook container into the helm charts.</li> </ul> </li> </ol> <p>For more detailed improvements that have been made in this release, please refer to the complete <a href="https://github.com/alibaba/GraphScope/releases/tag/v0.8.0">changelog</a>.</p> </description>
<pubDate>Sat, 06 Nov 2021 03:33:20 +0000</pubDate>
<link>https://graphscope.io/blog/releasenotes/2021/11/06/release-notes-0.8.0.html</link>
<guid isPermaLink="true">https://graphscope.io/blog/releasenotes/2021/11/06/release-notes-0.8.0.html</guid>
<category>ReleaseNotes</category>
</item>

    <item>
<title>Release Notes: v0.7.0</title>
<description><p><img src="/blog/assets/images/release_note_t.png" alt="release-note" /> We are glad to announce the availability of GraphScope v0.7. This release includes major updates for the persistent graph store in GraphScope, providing APIs for real-time graph updates (inserts and deletes of individual vertices and edges). It also focuses on user-friendly improvements, security issues, code quality, and a series of bug fixes.</p> <p>We highlight the following improvements included in this release:</p> <ol> <li>Apart from bulk loading, this release introduces a set of APIs for real-time graph updates. Currently, these APIs have supported the following functions: <ul> <li>Insert/delete one or multiple vertices/edges;</li> <li>Update properties of a specific vertex/edge.</li> </ul> <p>More details can refer to <a href="https://github.com/alibaba/GraphScope/blob/main/docs/persistent_graph_store.rst#realtime-write">this</a>.</p> </li> <li>User-friendly improvement <ul> <li>Revise error handling in GraphScope and improve all error messages reported to users;</li> <li>Add a <a href="https://github.com/alibaba/GraphScope/blob/main/docs/persistent_graph_store.rst">document</a> to describe persistent graph store in GraphScope;</li> <li>The logs in the <code class="language-plaintext highlighter-rouge">err</code> channel are always fetched to the client for debugging;</li> <li>The <a href="https://github.com/alibaba/GraphScope/releases/download/v0.7.0/graphscope_store_data_load.tar.gz">bulk-loading tool</a> of the persistent graph store is released to help load graphs into the store;</li> <li>Revise some descriptions for APIs in documents.</li> </ul> </li> <li>Optimizations and enhancements <ul> <li>Using <a href="https://github.com/etcd-io/zetcd">zetcd</a> to replace zookeeper in the graph interactive engine;</li> <li>Update third-party dependencies to address some security issues;</li> <li>More test coverages for GAIA and client;</li> <li>Integrate GIE GraphManager into Coordinator;</li> <li>During <code class="language-plaintext highlighter-rouge">sess.gremlin</code>, the pod will not be created dynamically for reducing the response time.</li> </ul> </li> <li>Some Breaking API Changes: <ul> <li>Remove GIE GraphManager role;</li> <li>Remove zookeeper and replace with zetcd;</li> <li><code class="language-plaintext highlighter-rouge">k8s_gie_graph_manager_image</code>, <code class="language-plaintext highlighter-rouge">k8s_gie_graph_manager_cpu</code>, <code class="language-plaintext highlighter-rouge">k8s_gie_graph_manager_mem</code> Deprecated;</li> <li><code class="language-plaintext highlighter-rouge">k8s_zookeeper_image</code>, <code class="language-plaintext highlighter-rouge">k8s_zookeeper_cpu</code>, <code class="language-plaintext highlighter-rouge">k8s_zookeeper_mem</code> Deprecated;</li> <li><code class="language-plaintext highlighter-rouge">k8s_gie_gremlin_server_cpu</code>, <code class="language-plaintext highlighter-rouge">k8s_gie_gremlin_server_mem</code> Deprecated.</li> </ul> </li> </ol> <p>For more detailed improvements that have been made in this release, please refer to the complete <a href="https://github.com/alibaba/GraphScope/releases/tag/v0.7.0">changelog</a>.</p> </description>
<pubDate>Wed, 08 Sep 2021 03:33:20 +0000</pubDate>
<link>https://graphscope.io/blog/releasenotes/2021/09/08/release-notes-0.7.0.html</link>
<guid isPermaLink="true">https://graphscope.io/blog/releasenotes/2021/09/08/release-notes-0.7.0.html</guid>
<category>ReleaseNotes</category>
</item>

    <item>
<title>Release Notes: v0.6.0</title>
<description><p><img src="/blog/assets/images/release_note_t.png" alt="release-note" /> We are glad to announce the release of GraphScope 0.6. This major release integrates a new graph interactive engine GAIA, which supports efficient parallel execution and bounded-memory execution for Gremlin queries. More technical details of GAIA can refer to our published <a href="https://graphscope.io/blog/tech/2021/08/05/GAIA-Deep-Dive-Bounded-Memory-Execution-and-Early-Stop-Optimization-for-Efficient-Graph-Traversal-at-Scale.html">tech blog</a>. Note that currently the integration of GAIA with GraphScope is experimental, and is not recommended for production use yet! In addition, this release improves the experience of local deployment on MacOS, Ubuntu and CentOS, and adds more graph analytics algorithms.</p> <p>We highlight the following improvements included in this release:</p> <ol> <li>[Experimental] Integrate GAIA, a graph interactive query engine, into GraphScope. Currently, it has supported the following features/functions: <ul> <li>Dynamic memory management for arbitrary graph traversal with ensuring bounded use of memory;</li> <li>Automatic and adaptive strategy for optimizing Gremlin traversal, such as hybrid DFS/BFS traversal to balance parallelism and memory usage;</li> <li>Early-stop optimization for Gremlin (limit, nested conditional, etc.) to minimize wasted computation;</li> <li>Improvement of performance and scalability (a new LDBC Social Network Benchmark will be released around year end);</li> <li>Support both Vineyard and the new persistent graph store.</li> </ul> </li> <li> <p>Lazy evaluation support for graph interactive engine and graph learning engine.</p> </li> <li> <p>A <a href="https://github.com/alibaba/GraphScope/blob/main/scripts/deploy_local.sh">script</a> supporting local deployment on MacOS, Ubuntu and CentOS.</p> </li> <li>Add more graph analytics algorithms as built-in applications. <ul> <li><a href="https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.boundary.node_boundary.html#networkx.algorithms.boundary.node_boundary">node_boundary</a> and <a href="https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.boundary.edge_boundary.html#networkx.algorithms.boundary.edge_boundary">edge_boundary</a> applications;</li> <li><a href="https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.link_analysis.pagerank_alg.pagerank.html#networkx.algorithms.link_analysis.pagerank_alg.pagerank">pagerank</a> in NetworkX version;</li> <li><a href="https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.simple_paths.is_simple_path.html#networkx.algorithms.simple_paths.is_simple_path">is_simple_path</a> application.</li> </ul> </li> </ol> <p>For more detailed improvements that have been made in this release, please refer to the complete <a href="https://github.com/alibaba/GraphScope/releases/tag/v0.6.0">changelog</a>.</p> </description>
<pubDate>Sun, 08 Aug 2021 03:33:20 +0000</pubDate>
<link>https://graphscope.io/blog/releasenotes/2021/08/08/release-notes-0.6.0.html</link>
<guid isPermaLink="true">https://graphscope.io/blog/releasenotes/2021/08/08/release-notes-0.6.0.html</guid>
<category>ReleaseNotes</category>
</item>

    <item>
<title>GAIA Deep Dive: Bounded-Memory Execution and Early-Stop Optimization for Efficient Graph Traversal at Scale</title>
<description><p><img src="/blog/assets/images/gaia.png" alt="knife" /> <a href="https://graphscope.io/blog/tech/2021/04/29/Introducing-gaia-a-scalable-engine-for-gremlin-the-sql-for-graphs.html">Last time</a>, we presented an overview of the GAIA engine for scaling Gremlin for large distributed graphs. In contrast to other, existing batch-oriented big graph processing systems, such as <a href="https://research.google/pubs/pub37252">Google Pregel</a>, <a href="https://giraph.apache.org/">Apache Giraph</a>, <a href="https://github.com/jegonzal/PowerGraph">GraphLab PowerGraph</a>, and <a href="https://spark.apache.org/graphx/">Apache Spark GraphX</a>, GAIA focuses on low-latency graph traversal at scale. Achieving this goal requires a different distributed infrastructure. Today, we continue to explain why with highlighting two unique and key features of GAIA.</p> <h3 id="bounded-memory-execution">Bounded-Memory Execution</h3> <p>Graph traversal can produce paths of arbitrary length, leading to memory usage growing exponentially with the number of hops. Although it is very common for Gremlin queries to terminate with a top-k constraint and/or aggregate operation, such an explosion of <em>intermediate</em> results can often lead to memory crisis, especially in an interactive environment with limited memory configuration.</p> <p>On the other hand, the traversal strategies can greatly impact the memory usage. There are two typical traversal strategies, namely (breadth-first-search) BFS-like traversal and (depth-like-search) DFS-like traversal. BFS-like traversal can better utilize parallelism, while it may produce data all at once that drives high the memory usage. On the contrary, DFS-like traversal tends to consume much less memory, while it may suffer from low parallelism.</p> <p>To ensure <em>bounded-memory execution</em> without sacrificing performance (parallelism), GAIA employs <em>dynamic scheduling</em> for executing each Gremlin operator. GAIA packs a segment of consecutive data entries in an input stream into a single batch, and such a batch constitutes the finest data granularity for communication and computation. A <em>task</em> can be logically viewed as the combination of an operator and a batch of data entries to be computed. GAIA dynamically creates such tasks corresponding to each operator when there is one or more batches available from all its inputs, and maintains all the tasks in a same scheduling queue to share resources.</p> <p>Furthermore, GAIA can schedule tasks with priorities according to the occurrence order of its corresponding operators in a Gremlin query. Specifically, it can schedule the operators that appear first with higher priority for a BFS-like traversal, and prioritize those that appear last to follow a DFS-like traversal. To balance the memory usage with the performance (parallelism), GAIA by default adopts a hybrid traversal strategy, that is, it uses BFS-prioritized scheduling as it has better opportunities for parallelization, and automatically switches to DFS-prioritized in case that the current operator arrives at the memory bound.</p> <p>To validate the hypothesis, we use the following cycle-detection query as an example to compare GAIA with the current <a href="https://github.com/alibaba/GraphScope/tree/main/interactive_engine">MaxGraph release</a> in GraphScope without memory control.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>g.V([vertices]).as('a').repeat(out().simplePath()) .times(k-1) .out().where(as('a')) .path().limit(n) </code></pre></div></div> <p>The above cycle-detection query starts from <code class="language-plaintext highlighter-rouge">m</code> (default 10) vertices in V, it traverses from V via at most <code class="language-plaintext highlighter-rouge">k</code> (default 3) hops, and returns at most <code class="language-plaintext highlighter-rouge">n</code> cycles found along the traversal.</p> <p>We generate large LDBC data sets with scale factor 30. The generated LDBC data sets which have 89 million vertices and 541 million edges would be used for the following experiments. In this experiment, we set memory upper bound of GAIA to 256MB, and compare with MaxGraph. For this query, We vary the number of start vertices, set <code class="language-plaintext highlighter-rouge">k</code> to 3 and set result limit to infinity. We report both the query latency and max memory consumption in the following.</p> <p><img src="/blog/assets/images/memory-bound.jpg" alt="memory-bound.jpg" height="50%" width="50%" /></p> <p>As the figure shows, GAIA achieves much lower memory usage (up to 9× memory saving) comparing to MaxGraph as well as comparable performance. We can see the actual memory usage of all cases in GAIA is very close to the bounded value 256MB. This expriment shows that GAIA ensure <em>bounded-memory execution</em> without sacrificing performance (parallelism) thanks to powerful dynamic scheduling.</p> <h3 id="early-stop-optimization">Early-Stop Optimization</h3> <p>Traversing all candidate paths fully is often unnecessary, especially for interactive queries with dynamic conditions running on diverse input graphs. For example, in the above query, only the first <code class="language-plaintext highlighter-rouge">k</code> results are needed. This leads to an interesting tradeoff between parallel traversal and wasted computation, as further illustrated in the following figure.</p> <p><img src="/blog/assets/images/early_stop_case.jpg" alt="early_stop_case.png" height="50%" width="50%" /></p> <p>The figure shows an example run of the query with <code class="language-plaintext highlighter-rouge">k=1</code>. The circle denotes the traversal specified by the <code class="language-plaintext highlighter-rouge">repeat</code>-loop. Assume we have enough computation resource (CPU cores), the paths can be explored in a fully parallel fashion. However, once a <code class="language-plaintext highlighter-rouge">4</code>-hop path is found, all the remaining parallel traversal will be no longer required.</p> <p>For real-world queries on large graph data, such wasted computation can be hidden deeply in nested traversals (e.g., a predicate that can be evaluated early from partial inputs) and significantly impact query performance. While avoiding such wastage is straightforward in a sequential implementation, it is challenging to do so for a fully-parallel execution.</p> <p>To minimize such wastage, GAIA tracks data dependencies dynamically at runtime. When enough results are collected, the system automatically creates a <em>cancellation token</em> that is sent backward along input streams to its upstream operators within the same execution context. The token serves as a signal for receiving operators to clear any unsent output data and immediately cancel any on-going computation for the particular output stream. Such cancellation notification is implemented at a system level by GAIA. Below, we continue to use the cycle-detection query as a running example to demonstrate that such early-stop optimization can significantly improve query performance.</p> <p>In this experiment, we vary the number of result limit and report the latency of GAIA and MaxGraph.</p> <p><img src="/blog/assets/images/early-stop.jpg" alt="early-stop.jpg" height="50%" width="50%" /></p> <p>The figure shows that GAIA outpeforms MaxGraph in all cases thanks to the ablility of cancelling wasted computation. GAIA achieves 4.5× better performance in average, up to 8.1×. Even the number of limit results is close to the complete query result, GAIA can also show better performance due to the fine-grained early-stop mechanism. Note that MaxGraph can also achieve low latency when the limit size is small (50), this is because a naive early-stop is implemented in MaxGraph to cancel the job from source operator to the end when already collected needed results. But the performance degrades rapidly when the limit size become larger due to coarse-grained job cancelling in MaxGraph.</p> <h3 id="scalability">Scalability</h3> <p>Finally, we study the scalability while running the same query as above. This is to prove that both features do not introduce additional overheads that impact performance/scalability of GAIA.</p> <p>In this experiment, we set the query result limit to infinity and vary the number of computing threads to show the scale-up performance of GAIA. We test the scalability using different size of queries by varying the number of start vertices.</p> <p><img src="/blog/assets/images/gaia-scalability.jpg" alt="gaia-scalability.jpg" height="50%" width="50%" /></p> <p>As we can see from the above figure, GAIA has linear scalability in all type (both large and small) of queries. It shows that new features such as dynamic scheduling do not hurt the scalability of GAIA.</p> <h3 id="conclusion">Conclusion</h3> <p>Diverse and irregular graph data and algorithms impose significant challenges in efficient distributed and parallel execution. Implementation choices can have a huge impact on system performance and memory requirements. GAIA is the first engine to support efficient graph traversal at scale that enables bounded-memory execution with minimum wastage. It will be included as an experimental feature in the coming release of GraphScope v0.6.0. We welcome community feedback!</p> </description>
<pubDate>Thu, 05 Aug 2021 03:10:42 +0000</pubDate>
<link>https://graphscope.io/blog/tech/2021/08/05/GAIA-Deep-Dive-Bounded-Memory-Execution-and-Early-Stop-Optimization-for-Efficient-Graph-Traversal-at-Scale.html</link>
<guid isPermaLink="true">https://graphscope.io/blog/tech/2021/08/05/GAIA-Deep-Dive-Bounded-Memory-Execution-and-Early-Stop-Optimization-for-Efficient-Graph-Traversal-at-Scale.html</guid>
<category>Tech</category>
</item>
    
    <item>
<title>Release Notes: v0.5.0</title>
<description><p><img src="/blog/assets/images/release_note_t.png" alt="release-note" /> We are glad to announce the GraphScope 0.5 release. As the first step towards the ease of deployment in production, this major release includes two new features, namely <strong>a persistent graph store</strong> to enable a “service mode” for real-time graph computing, and <strong>lazy evaluation</strong> of GraphScope programs–an execution strategy which delays the execution of a GraphScope program until later when needed for efficiency. In addition, we improve the compatibility with NetworkX.​We highlight the following improvements included in this release:​</p> <ol> <li> <p>GraphScope-Store: A persistent store for mutable graphs. Currently, it has supported the following features/functions:</p> <ul> <li>A bulk-load tool to import a property graph from files to the GraphScope-Store instance.</li> <li>Helm support to launch GraphScope as a service with a store.</li> <li>Support for multiple session connections to a store.</li> <li>Interactive queries on graphs in the store with Gremlin.</li> </ul> </li> <li> <p>Lazy evaluation</p> <ul> <li>Support to switch between lazy-mode and eager-mode by just setting the value of <code class="language-plaintext highlighter-rouge">mode</code> as <code class="language-plaintext highlighter-rouge">lazy</code> or <code class="language-plaintext highlighter-rouge">eager</code> when creating a session <code class="language-plaintext highlighter-rouge">graphscope.session(mode='lazy'or 'eager')</code>.</li> <li>Adapt the NetworkX interfaces to switch between eager and lazy modes.</li> </ul> </li> <li> <p>Enhanced NetworkX compatibility</p> <ul> <li>Support for multi-queries on duplications of the whole graph.</li> <li>Add all-pairs shortest paths and closeness centrality algorithms.</li> </ul> </li> <li> <p>Provide a <a href="https://graphscope.io/docs/frequently_asked_questions.html">Q&amp;A page</a> for beginners</p> </li> </ol> <p>For more detailed improvements that have been made in this release, please refer to the complete <a href="https://github.com/alibaba/GraphScope/releases/tag/v0.5.0">changelog</a>.</p> </description>
<pubDate>Tue, 15 Jun 2021 03:33:20 +0000</pubDate>
<link>https://graphscope.io/blog/releasenotes/2021/06/15/release-notes-0.5.0.html</link>
<guid isPermaLink="true">https://graphscope.io/blog/releasenotes/2021/06/15/release-notes-0.5.0.html</guid>
<category>ReleaseNotes</category>
</item>
    
      <item>
        <title>Towards a Swiss Army Knife for a Continuous Life Cycle of Big Graph Analytics</title>
        <description>&lt;p&gt;&lt;img src=&quot;/blog/assets/images/knife.png&quot; alt=&quot;knife&quot; /&gt;
In this post, we will present a high-level road-map of the GraphScope project with highlighting new exciting features coming in the v0.5 release.&lt;/p&gt;

&lt;h3 id=&quot;how-it-all-gets-started&quot;&gt;How It All Gets Started&lt;/h3&gt;

&lt;p&gt;To begin with, let us reflect on why we start this project. Due to huge diversity of graph data, scenarios, and algorithms, agility is key to the success of a big graph infrastructure, which boils down firstly to the ease of programming and interoperability. GraphScope generalizes previous execution environments such as &lt;a href=&quot;https://giraph.apache.org/&quot;&gt;Giraph&lt;/a&gt; and &lt;a href=&quot;https://spark.apache.org/graphx/&quot;&gt;GraphX&lt;/a&gt; in two ways: by providing a single-machine programming abstraction in Python that supports familiar notations for a variety of graph operations (&lt;a href=&quot;https://tinkerpop.apache.org/&quot;&gt;Gremlin&lt;/a&gt;, &lt;a href=&quot;https://networkx.org/&quot;&gt;NetworkX&lt;/a&gt;, &lt;a href=&quot;https://github.com/alibaba/graph-learn&quot;&gt;Graph Neural Networks&lt;/a&gt;, etc.) while hiding the system complexity from the programmer; and by bridging with other, existing big data infrastructure through &lt;a href=&quot;https://github.com/v6d-io/v6d&quot;&gt;Vineyard&lt;/a&gt; which provides efficient in-memory data transfer with high-level data structures as interface, as shown in Figure 1.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/system-stack.png&quot; alt=&quot;system-stack.png&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Figure 1: The GraphScope system stack, and how it interacts with the &lt;a href=&quot;https://pydata.org/&quot;&gt;PyData&lt;/a&gt; ecosystem.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;a-vision-on-big-graph-infrastructure&quot;&gt;A Vision on Big Graph Infrastructure&lt;/h3&gt;

&lt;p&gt;In addition, we believe big graph infrastructure must be developed for a continuous life cycle. As illustrated in Figure 2, the centered box of “interactive analysis and testing” represents the current version of GraphScope, which facilitates the design of new (or specific) graph algorithms for each particular task in an exploratory manner. As such a process is highly experimental in nature, GraphScope makes it easy to construct and load large graphs on demand and to efficiently perform a wide range of graph computations.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/lifecycle.png&quot; alt=&quot;lifecycle.png&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Figure 2: A continuous life cycle of big graph analytics.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Once such a design is achieved and selected, it will typically be &lt;em&gt;deployed in production&lt;/em&gt; for processing real dynamic graphs to generate insights in a continuous manner. The left and right box in Figure 2 show two representative processing paradigms for such a deployment: the real-time streaming and the batch-oriented processing, respectively, at two ends of the latency spectrum. In the real-time streaming, ideally, each update to the graph model has to be reflected in the output within a couple of seconds, and therefore the system optimizes for low latency and high availability. In the batch-oriented processing where the latency requirement is much relaxed, it is often more efficient to perform computation periodically (such as every one hour or day) to allow sophisticated optimizations for throughput.&lt;/p&gt;

&lt;h3 id=&quot;graphscope-v05&quot;&gt;GraphScope v0.5&lt;/h3&gt;

&lt;p&gt;As the first step towards the ease of deployment in production, we are introducing two new features in the coming release of GraphScope v0.5, including &lt;em&gt;a persistent graph store&lt;/em&gt; to enable a “service mode” for real-time graph computation, and &lt;em&gt;lazy evaluation&lt;/em&gt; of GraphScope programs–an execution strategy which delays the execution of a GraphScope program until later when needed for efficiency. We briefly introduce them below and will provide more details in the Release Note soon.&lt;/p&gt;

&lt;h4 id=&quot;persistent-graph-store&quot;&gt;Persistent Graph Store&lt;/h4&gt;

&lt;p&gt;In addition to Vineyard, the in-memory columnar graph store currently supported in GraphScope, we will introduce a new disk-based row-oriented multi-versioned persistent graph store. While Vineyard focuses on great support for in-memory whole graph analytics workload, the new persistent graph store is geared towards better supporting for running continuous graph data management service that frequently updates the graph and answers traversal queries.&lt;/p&gt;

&lt;p&gt;The store is a distributed graph store built on top of the popular RocksDB key value store. It adopts row-oriented design to support frequent small updates to the graph. Each row is tagged with a snapshot ID as its version. A query reads most recent version of rows relative to the snapshot ID when it starts and hence not blocked by writes. For writes we take a compromise between consistency and higher throughput (in a similar design to Kineograph [1]). In our design writes in the same session can be grouped and executed atomically as a unit and the persistent store assigns a snapshot ID (which is a low-resolution timestamp of current time) to each group and executes groups of writes by the order of their snapshot IDs and by a deterministic (though arbitrary) order for groups of writes that occur in the same snapshot ID. It provides high write throughput while still with some degree of order and isolation though it provides less consistency than strict snapshot isolation common in database. We hope our design choice provides an interesting trade-off for practical usage.&lt;/p&gt;

&lt;p&gt;Initially, the new persistent store is provided as a separate option from Vineyard. Going foward we hope to evole them into an integrated hybrid graph store suitable for all kinds of workloads.&lt;/p&gt;

&lt;h4 id=&quot;lazy-evaluation&quot;&gt;Lazy Evaluation&lt;/h4&gt;
&lt;p&gt;As an important performance optimization technique, lazy evaluation has been widely applied by many big data processing systems like &lt;a href=&quot;https://www.tensorflow.org/&quot;&gt;TensorFlow&lt;/a&gt;. We will introduce the support of lazy evaluation into the coming GraphScope v0.5, which provides three-fold benefits compared with eager evaluation. First, in the lazy evaluation, a job is expressed logically in a directed acyclic graph (DAG) where different nodes represent different operators of the overall job and edges represent the data dependencies between operators. When evaluating the operator (i.e., a vertex in the DAG), GraphScope looks back to check all the nodes that are required for this requested node. Only those nodes are evaluated in the appropriate order. Thus, a node in the DAG is evaluated only when needed; only if it is needed. Second, with the DAG in place, it can avoid repeatedly evaluating the same operator, blindly, regardless whether the operator can be memorized. Third, it allows to combine multiple operators (e.g., adding an edge to a graph) into a single batch-oriented operator (e.g., aggregating multiple edges into a batch and adding the batch to a graph), which is more efficient in GraphScope.&lt;/p&gt;

&lt;p&gt;In GraphScope, developers can easily switch between lazy-mode and eager-mode by just setting the value of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mode&lt;/code&gt; as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lazy&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;eager&lt;/code&gt; when creating a session &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;graphscope.session(mode='lazy'or 'eager')&lt;/code&gt;. Typically, developers can choose the eager-mode in the development stage, as it can ease the debugging of applications, while switch to the lazy-mode in the deployment stage for better performance.&lt;/p&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;A tool or infrastructure built for a continuous life cycle of big graph applications requires to do much more than the ease of deployment, but also to help testing and diagnosis of real-world graph applications, and to allow a data-driven approach for continuous evolution of an on-line service or periodic pipeline. Even so, the new features coming in the GraphScope v0.5 release take us one step closer to that vision. Please give it a try and let us know what you think! Really appreciated.&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;[1] Raymond Cheng, Ji Hong, Aapo Kyrola, Youshan Miao, Xuetian Weng, Ming Wu, Fan Yang, Lidong Zhou, Feng Zhao, and Enhong Chen. 2012. Kineograph: Taking the Pulse of A Fast-changing and Connected World. In EuroSys ‘12. (&lt;a href=&quot;https://www.cl.cam.ac.uk/~ey204/teaching/ACS/R212_2013_2014/papers/cheng_eurosys_2012.pdf&quot;&gt;pdf&lt;/a&gt;)&lt;/p&gt;
</description>
        <pubDate>Sat, 29 May 2021 11:10:42 +0800</pubDate>
        <link>https://graphscope.io/blog/tech/2021/05/29/Towards-a-Swiss-Army-Knife-for-a-Continuous-Life-Cycle-of-Big-Graph-Analytics.html</link>
        <guid isPermaLink="true">https://graphscope.io/blog/tech/2021/05/29/Towards-a-Swiss-Army-Knife-for-a-Continuous-Life-Cycle-of-Big-Graph-Analytics.html</guid>
        
        
        <category>Tech</category>
        
      </item>
    
      <item>
        <title>Release Notes: v0.4.0</title>
        <description>&lt;p&gt;&lt;img src=&quot;/blog/assets/images/release_note_t.png&quot; alt=&quot;release-note&quot; /&gt;
Today, we’re announcing the availability of GraphScope v0.4.0. This release focuses on
 the compatibility improvement with &lt;a href=&quot;https://networkx.org/&quot;&gt;NetworkX&lt;/a&gt;, with the aim of allowing users to
 develop graph applications on large-scale graphs in a distributed environment just
 like doing this on a single machine. In addition, this release improves the
 experience of standalone deployment.&lt;/p&gt;

&lt;p&gt;We highlight the following improvements included in this release:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Improved compatibility with NetworkX:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Support &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Graph/DiGraph&lt;/code&gt; types in NetworkX;&lt;/li&gt;
      &lt;li&gt;Support Networkx APIs of operations and manipulations over the above two types of graphs;&lt;/li&gt;
      &lt;li&gt;A new &lt;a href=&quot;https://github.com/alibaba/GraphScope/blob/62b3bbff00767784d0bb3693fe9bb24e8a1b4b2a/tutorials/2_graph_manipulations_with_networkx_compatible_apis.ipynb&quot;&gt;tutorial&lt;/a&gt; in Playground to introduce graph processing with NetworkX APIs.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Improve the experience of standalone deployment:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Support to launch multiple sessions/instances in standalone mode.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;For more detailed improvements that have been made in this release, please refer to the complete &lt;a href=&quot;https://github.com/alibaba/GraphScope/releases/tag/v0.4.0&quot;&gt;changelog&lt;/a&gt;.&lt;/p&gt;
</description>
        <pubDate>Mon, 10 May 2021 13:08:20 +0800</pubDate>
        <link>https://graphscope.io/blog/releasenotes/2021/05/10/release-notes-0.4.0.html</link>
        <guid isPermaLink="true">https://graphscope.io/blog/releasenotes/2021/05/10/release-notes-0.4.0.html</guid>
        
        
        <category>ReleaseNotes</category>
        
      </item>
    
      <item>
        <title>Introducing GAIA: A Scalable Engine for Gremlin – the SQL for Graphs</title>
        <description>&lt;p&gt;&lt;img src=&quot;/blog/assets/images/gaia.png&quot; alt=&quot;gaia&quot; /&gt;
GAIA extends GraphScope with &lt;a href=&quot;https://tinkerpop.apache.org/gremlin.html&quot;&gt;Gremlin&lt;/a&gt;, the industry’s de facto standard property graph query language defined and maintained by &lt;a href=&quot;http://tinkerpop.apache.org/&quot;&gt;the Apache TinkerPop project&lt;/a&gt;, which is widely adopted by popular graph database vendors such as &lt;a href=&quot;https://neo4j.com/&quot;&gt;Neo4j&lt;/a&gt;, &lt;a href=&quot;https://www.orientdb.org/&quot;&gt;OrientDB&lt;/a&gt;, &lt;a href=&quot;https://janusgraph.org/&quot;&gt;JanusGraph&lt;/a&gt;, &lt;a href=&quot;https://azure.microsoft.com/en-us/services/cosmos-db/&quot;&gt;Microsoft Cosmos DB&lt;/a&gt;, and &lt;a href=&quot;https://aws.amazon.com/neptune/&quot;&gt;Amazon Neptune&lt;/a&gt;. GAIA is the first open-source implementation of Gremlin in a distributed or big-data environment in the industry.&lt;/p&gt;

&lt;h4 id=&quot;making-gremlin-accessible-to-data-scientists-historical-background&quot;&gt;Making Gremlin Accessible to Data Scientists: Historical Background&lt;/h4&gt;

&lt;p&gt;Since about two years ago, we have heard an increasing demand from data scientists at Alibaba to extract insights from structural patterns on massive heterogeneous datasets in a wide variety of important application domains such as e-commerce, on-line payments, and social media. Such data is naturally modeled as graphs to encode complex interrelationships among entities.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/gaia-graph.png&quot; alt=&quot;cycle_detection.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As an example, consider the graph depicted in the above figure. It is a simplified subgraph pattern of the one employed at Alibaba for credit-card fraud detection [2,3]. By using a fake identifier, the “criminal” may obtain a short-term credit from a bank (vertex 4). He/she tries to illegally cash out money by forging a purchase (edge 2–&amp;gt;3) at time t1 with the help of a merchant (vertex 3). Once receiving payment (edge 4–&amp;gt;3) from the bank (vertex 4), the merchant tries to send the money back (edges 3–&amp;gt;1 and 1–&amp;gt;2) to the “criminal” via multiple accounts of a middle man (vertex 1) at time t3 and t4, respectively. This pattern eventually forms a cycle (2–&amp;gt;3–&amp;gt;1…–&amp;gt;2).&lt;/p&gt;

&lt;p&gt;In practice, the graph can contain billions of vertices (e.g., users) and hundreds of billions to trillions of edges (e.g., payments), and the entire fraudulent process can involve much more complex chains of transactions, through many entities, with various constraints, which therefore requires complex interactive analysis to identify. Although many distributed and parallel graph processing frameworks exist, writing efficient distributed algorithms for each particular task is exceedingly hard [4], especially for our target users of domain experts or data scientists.&lt;/p&gt;

&lt;p&gt;Motivated by the above (and many other) use cases, we started the GAIA project to offer a new distributed infrastructure for this new class of graph applications. GAIA differs from prior systems in two important ways: by exploiting Gremlin to provide a high-level language for graph and/or pattern traversal, and by supporting automatic parallel execution with advanced optimizations such as hybrid (BFS/DFS) traversal for bounded-memory execution and early stop (to avoid wasted computation).&lt;/p&gt;

&lt;h4 id=&quot;scaling-gremlin-for-large-distributed-graphs-a-closer-look&quot;&gt;Scaling Gremlin for Large Distributed Graphs: A Closer Look&lt;/h4&gt;

&lt;p&gt;Gremlin offers a flexible and expressive programming model to enable non-technical users to succinctly express complex traversal patterns in real-world applications. For example, one can write the above fraud-detection query in just a couple of lines using Gremlin, as shown below. In contrast, even common operations like cycle detection, which is a core part of the fraud-detection use case, is tricky to implement in existing graph systems.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;g.V('account').has('id','2').as('s')
  .repeat(out('transfer').simplePath())
  .times(k-1)
  .where(out('transfer').as('s'))
  .path().limit(1)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;The query finds cyclic paths of length &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;k&lt;/code&gt;, starting from a given account. First, the source operator &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;V&lt;/code&gt; (with the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;has&lt;/code&gt; filter) returns all the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;account&lt;/code&gt; vertices with an identifier of “2”. The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;as&lt;/code&gt; operator is a &lt;em&gt;modulator&lt;/em&gt; that introduces a tag (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;s&lt;/code&gt; in this case) for later references. Second, it traverses the outgoing &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;transfer&lt;/code&gt; edges for exactly &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;k-1&lt;/code&gt; times, skipping any repeated vertices (by the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;simplePath&lt;/code&gt; operator). Third, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;where&lt;/code&gt; operator checks if the starting vertex &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;s&lt;/code&gt; can be reached by one more step, that is, whether a cycle of length &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;k&lt;/code&gt; is formed. Finally, for qualifying traversers, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;path&lt;/code&gt; operator returns the full path information. The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;limit&lt;/code&gt; operator at the end indicates only one such result is needed.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;GAIA is designed to faithfully preserve the programming model of Gremlin. As a result, it can be used to scale existing Gremlin applications to large compute clusters with no (or minimum) modification. GAIA achieves high performance for complex Gremlin traversal by compiling it into a  dataflow that can be executed efficiently in a distributed system deployed on large clusters. We refer interested readers to this paper [1] for the full technical details of GAIA.&lt;/p&gt;

&lt;p&gt;The following figure shows a comparison between GAIA and JanusGraph using the &lt;a href=&quot;http://ldbcouncil.org/benchmarks/snb&quot;&gt;LDBC Social Network Benchmark&lt;/a&gt; (Interactive Workload). JanusGraph cannot process query in parallel, and we run GAIA in one machine for fair comparison. We run each query on GAIA with the degree of parallelism varying from 1 to 16, and report its max and min latency for each query while compared to JanusGraph.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/gaia-perf.png&quot; alt=&quot;GAIA-perf_JanusGraph.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;JanusGraph fails to answer many queries (CR-&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;3,5,9&lt;/code&gt;) due to out-of-time (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;OT&lt;/code&gt;). As shown, even the maximum latency (single-thread) of GAIA is much shorter than that of JanusGraph in all cases. In addition, GAIA can scale those large, complex traversal queries almost linearly across multiple servers [1].&lt;/p&gt;

&lt;h4 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h4&gt;

&lt;p&gt;We’ve been building GAIA at Alibaba for over a year now and it is still under very active development. Find the current &lt;a href=&quot;https://github.com/alibaba/GraphScope/tree/main/research/gaia&quot;&gt;pre-release on GitHub here&lt;/a&gt;. Meanwhile, we are working on integrating GAIA into &lt;a href=&quot;https://github.com/alibaba/GraphScope&quot;&gt;the GraphScope project&lt;/a&gt; to make the “SQL for Graphs” available for a wider community of users to work with big data or data science. An early alpha release of GAIA will be included in GraphScope coming this summer, and we will further develop and refine GAIA to ship more Gremlin features such as the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;match&lt;/code&gt;-step for declarative pattern queries and iterative graph algorithms via the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;subgraph&lt;/code&gt;-step, both tentatively scheduled for release in late 2021.&lt;/p&gt;

&lt;p&gt;Graph technology is changing AI [5]. We’re excited to be creating new tools and fostering innovative graph solutions in the amazing community. We look forward to your feedbacks and contributions.&lt;/p&gt;

&lt;h4 id=&quot;references&quot;&gt;References&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;[1] Zhengping Qian, Chenqiang Min, Longbin Lai, Yong Fang, Gaofeng Li, Youyang Yao, Bingqing Lyu, Zhimin Chen, Jingren Zhou. GraphScope: A System for Interactive Analysis on Distributed Graphs Using a High-Level Language. (&lt;a href=&quot;https://www.usenix.org/system/files/nsdi21-qian.pdf&quot;&gt;pdf&lt;/a&gt;)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;[2] Bingqing Lyu, Lu Qin, Xuemin Lin, Ying Zhang, Zhengping Qian, and Jingren Zhou. Maximum biclique search at billion scale.  Awarded Best Paper Runner-up in VLDB 2020. (&lt;a href=&quot;http://www.vldb.org/pvldb/vol13/p1359-lyu.pdf&quot;&gt;pdf&lt;/a&gt;)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;[3] Xiafei Qiu, Wubin Cen, Zhengping Qian, You Peng, Ying Zhang, Xuemin Lin, and Jingren Zhou. Real-time constrained cycle detection in large dynamic graphs.  In VLDB 2018. (&lt;a href=&quot;http://www.vldb.org/pvldb/vol11/p1876-qiu.pdf&quot;&gt;pdf&lt;/a&gt;)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;[4] Vasiliki Kalavri, Vladimir Vlassov, Seif Haridi. High-Level Programming Abstractions for Distributed Graph Processing. (&lt;a href=&quot;https://arxiv.org/pdf/1607.02646v1.pdf&quot;&gt;pdf&lt;/a&gt;)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;[5] Robert H.P. Engels. The Rise of Graph Technology. https://www.linkedin.com/pulse/rise-graph-technology-robert-h-p-engels-/&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Thu, 29 Apr 2021 10:10:42 +0800</pubDate>
        <link>https://graphscope.io/blog/tech/2021/04/29/Introducing-gaia-a-scalable-engine-for-gremlin-the-sql-for-graphs.html</link>
        <guid isPermaLink="true">https://graphscope.io/blog/tech/2021/04/29/Introducing-gaia-a-scalable-engine-for-gremlin-the-sql-for-graphs.html</guid>
        
        
        <category>Tech</category>
        
      </item>
    
      <item>
        <title>Release Notes: v0.3.0</title>
        <description>&lt;p&gt;&lt;img src=&quot;/blog/assets/images/release_note_t.png&quot; alt=&quot;release-note&quot; /&gt;
GraphScope v0.3.0 is released as scheduled. This release includes new features and major updates for  frontend APIs for graph manipulation, integration with other systems as well as code optimization for some operators. Another direction we are working on is to ease the deployment of GraphScope with/without Kubernetes.&lt;/p&gt;

&lt;p&gt;We highlight the following improvements included in this release:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Better integration with other systems&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;GraphScope aims to support easy integrations with other big data processing systems. As a first step, this release supported that the results (in the format of dataframe) of GraphScope can be further processed by Mars, a distributed tensor-based computation engine.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Performance and function enhancement&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Pre-compile a set of commonly used applications and graphs into the docker image to improve the response time of each operation in Python.&lt;/li&gt;
      &lt;li&gt;Optimize the implementation of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;session.gremlin(...)&lt;/code&gt;and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;session.close()&lt;/code&gt;.&lt;/li&gt;
      &lt;li&gt;Support Louvain algorithm as a built-in application in the graph analytics engine.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Improved graph manipulation APIs&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Support for adding vertices and edges to an existing graph.&lt;/li&gt;
      &lt;li&gt;Add a general project operator.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Easier deployment with/without Kubernetes.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;GraphScope v0.3.0 provided a &lt;a href=&quot;https://github.com/alibaba/GraphScope/blob/main/scripts/launch_cluster.py&quot;&gt;script&lt;/a&gt; to deploy GraphScope on a Kubernetes cluster of AWS/aliyun.&lt;/li&gt;
      &lt;li&gt;Support deployment with &lt;a href=&quot;https://artifacthub.io/packages/helm/graphscope/graphscope&quot;&gt;HELM&lt;/a&gt; and generalize &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;k8s_volumes&lt;/code&gt; to support PVC mount.&lt;/li&gt;
      &lt;li&gt;This release started to support the deployment and running of GraphScope locally without Kubernetes.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;For more detailed improvements that have been made in this release, please refer to the complete &lt;a href=&quot;https://github.com/alibaba/GraphScope/releases/tag/v0.3.0&quot;&gt;changelog&lt;/a&gt;.&lt;/p&gt;
</description>
        <pubDate>Sun, 11 Apr 2021 11:33:20 +0800</pubDate>
        <link>https://graphscope.io/blog/releasenotes/2021/04/11/release-notes-0.3.0.html</link>
        <guid isPermaLink="true">https://graphscope.io/blog/releasenotes/2021/04/11/release-notes-0.3.0.html</guid>
        
        
        <category>ReleaseNotes</category>
        
      </item>
    
      <item>
        <title>A Review of Programming Models for Parallel Graph Processing</title>
        <description>&lt;p&gt;&lt;img src=&quot;/blog/assets/images/programing-models.jpg&quot; alt=&quot;programing-models&quot; /&gt;
To explore underlying insights hidden in graph data, many graph analytics algorithms, e.g., PageRank and single source shortest paths (the Dijkstra’s algorithm), have been designed to solve different problems.&lt;/p&gt;

&lt;p&gt;In a single machine environment, developers can easily implement sequential solutions to these algorithms as they have a global view of the graph and can freely iterate through all vertices and edges. Current graph data in real industrial scenarios usually consists of billions of vertices and trillions of edges. Such a graph has to be divided into multiple partitions, and stored and processed in a distributed/parallel way. To allow developers to succinctly express graph algorithms under such environment, many programming models for parallel graph processing have been proposed. In this post, we would like to introduce some commonly used programming models, and further discuss their pros and cons.&lt;/p&gt;

&lt;h4 id=&quot;think-like-a-vertex&quot;&gt;Think like a vertex&lt;/h4&gt;

&lt;p&gt;The vertex-centric model proposed in Pregel[1] follows the philosophy of “think like a vertex”, where each vertex contains information about itself as well as all its adjacent edges, and the computation is expressed at the level of a single vertex. More specifically, the entire computation process is divided into multiple iterations (called &lt;em&gt;supersteps&lt;/em&gt;), and in each superstep, all vertices execute the same user-defined function (called &lt;em&gt;vertex program&lt;/em&gt;) that expresses the logic of a given algorithm. The vertex program defines how each vertex processes incoming messages (sent in the previous superstep), and sends messages to other vertices (for the next superstep). The iterations terminate until no messages are sent from any vertex, indicating a halt.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/vertex-messaging.png&quot; alt=&quot;vertex-model&quot; /&gt;&lt;/p&gt;

&lt;p&gt;With the vertex-centric model, the vertex program of single source shortest paths (SSSP) is expressed as follows.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;VertexProgramForSSSP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# receive and merge incoming messages
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;incoming_msgs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ReceiveMessages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;merged_msg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Reduce&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;incoming_msgs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MIN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# update vertex property
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dist&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;merged_msg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;dist&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;merged_msg&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# send messages to neighbors
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;neighbor&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;neighbors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dist&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edge_weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;neighbor_dist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;SendMessage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;neighbor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dist&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edge_weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;However, the performance of Pregel drops dramatically when facing natural graphs which follow a power-law distribution. To solve this problem, PowerGraph[2] proposed the GAS (Gather-Apply-Scatter) programming model for the vertex-cut graph partitioning strategy. The &lt;em&gt;Gather&lt;/em&gt; function runs locally on each partition and then one accumulator is sent from each mirror to the master. The master runs the &lt;em&gt;Apply&lt;/em&gt; function and then sends the updated vertex data to all mirrors. Finally, the &lt;em&gt;Scatter&lt;/em&gt; phase is run in parallel on mirrors to update the data on adjacent edges.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/gas.png&quot; alt=&quot;gas-model&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Following the GAS abstraction, the SSSP can be implemented as follows.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;GASForSSSP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# gather_nbrs: ALL_NBRS
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;gather&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D_u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D_v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D_v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; 
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D_u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;new_dist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;D_u&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;new_dist&lt;/span&gt;
        
    &lt;span class=&quot;c1&quot;&gt;# scatter_nbrs: ALL_NBRS
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D_u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D_v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# If changed, activate neighbor
&lt;/span&gt;	&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;changed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D_u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
	    &lt;span class=&quot;n&quot;&gt;Activate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;increased&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D_u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
	    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NULL&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D_u&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;pros&quot;&gt;Pros:&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;Powerful expressiveness to express various graph algorithms.&lt;/li&gt;
  &lt;li&gt;The vertex program is easy to run parallelly.&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;cons&quot;&gt;Cons:&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;Existing sequential (single-machine) graph algorithms have to be modified to comply with the “think like a vertex” principle.&lt;/li&gt;
  &lt;li&gt;Each vertex is very short-sighted: it only has information about its 1-hop neighbors, and thus information is propagated through the graph slowly, one hop at a time. As a result, it may take many computation iterations to propagate a piece of information from a source to a destination.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;think-like-a-graph&quot;&gt;Think like a graph&lt;/h4&gt;

&lt;p&gt;To tackle the problem of short-sighted vertices in the vertex-centric model, the subgraph-centric (a.k.a. block-centric, partition-centric) programming model[3, 4] is proposed. Different from the vertex-centric model, the subgraph-centric model focuses on the entire subgraph, and is labeled as “think like a graph”. For the vertex-centric model, it uses the information of 1-hop neighbors to update the value of each vertex in one superstep. Instead, the subgraph-centric model leverages information within the whole subgraph. In addition, each vertex can send messages to any vertex in the graph, instead of 1-hop neighbors. In this way, the communication overhead and the number of supersteps are greatly reduced.&lt;/p&gt;

&lt;p&gt;The SSSP is expressed as follows in the subgraph-centric model.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;ComputeSSSP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subgraph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;messages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# vertices with improved distances
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;openset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NULL&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;superstep&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# initialize distances
&lt;/span&gt;    	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;subgraph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;internal_vertices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
	    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SOURCE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# set distance to source as 0
&lt;/span&gt;		&lt;span class=&quot;n&quot;&gt;openset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# distance has improved
&lt;/span&gt;	    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MAX_INT&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# not source vertex
&lt;/span&gt;	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;messages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# process input messages
&lt;/span&gt;	    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;subgraph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vertices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vertex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;subgraph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vertices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vertex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;openset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vertex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# distance improved
&lt;/span&gt;	&lt;span class=&quot;n&quot;&gt;boundarySet&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dijkstra&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;openset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;c1&quot;&gt;# Send new distances to boundary vertices
&lt;/span&gt;	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;boundarySG&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vertex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;boundarySet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
	    &lt;span class=&quot;n&quot;&gt;SendToSubgraphVertex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;boundarySG&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vertex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;VoteToHalt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;dijkstra&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;openset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;boundaryOpenset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NULL&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;openset&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GetShortestVertex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;openset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v2&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;neighbors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# update neighbors, notify if boundary.
&lt;/span&gt;	    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isBoundary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;boundaryOpenset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subgraph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
	    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;openset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# distance has improved
&lt;/span&gt;	&lt;span class=&quot;n&quot;&gt;openset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;remove&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# done with this local vertex
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;boundaryOpenset&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;pros-1&quot;&gt;Pros:&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;The same expressiveness with the vertex-centric model.&lt;/li&gt;
  &lt;li&gt;Offer lower communication overhead, lower scheduling overhead, and lower memory overhead compared with vertex-centric approaches.&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;cons-1&quot;&gt;Cons:&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;Still need to recast existing sequential graph algorithms into the new programming model.&lt;/li&gt;
  &lt;li&gt;Developers need to know a lot of concepts (e.g., internal and boundary vertices), causing the implementation challenge.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;think-sequential-run-parallel&quot;&gt;Think sequential, run parallel&lt;/h4&gt;

&lt;p&gt;To make parallel graph computations accessible to average users while achieving high performance at the same time, the PIE (PEval-IncEval-Assemble) programming model[5] is proposed. In this model, users only need to provide three functions,&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;(1) PEval, a sequential (single-machine) function for given a query, computes the answer on a local partition;&lt;/li&gt;
  &lt;li&gt;(2) IncEval, a sequential incremental function, computes changes to the old output by treating incoming messages as updates; and&lt;/li&gt;
  &lt;li&gt;(3) Assemble, which collects partial answers, and combines them into a complete answer.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The PIE model works on a graph G and each worker maintains a partition of G. Given a query, each worker first executes PEval against its local partition, to compute partial answers in parallel. Then each worker may exchange partial results with other workers via synchronous message passing. Upon receiving messages, each worker incrementally computes IncEval. The incremental step iterates until no further messages can be generated. At this point, Assemble pulls partial answers and assembles the final result. In this way, the PIE model parallelizes existing sequential graph algorithms, without revising their logic and workflow.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/gs-workflow.png&quot; alt=&quot;vertex-model&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The following pseudo-code shows how SSSP is expressed in the PIE model, where the Dijkstra’s algorithm is directly used for the computation of parallel SSSP.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;dijkstra&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vals&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;updates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;heap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;VertexHeap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;updates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;vals&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;updates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;heap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;push&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vals&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        
    &lt;span class=&quot;n&quot;&gt;updates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;clear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;heap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;empty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;heap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;top&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vid&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;distu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;heap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;top&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;val&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;heap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_outgoing_edges&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
	    &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_neighbor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
	    &lt;span class=&quot;n&quot;&gt;distv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
	    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vals&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;vals&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distv&lt;/span&gt;
		    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;is_inner_vertex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
			&lt;span class=&quot;n&quot;&gt;heap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;push&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
			&lt;span class=&quot;n&quot;&gt;updates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distv&lt;/span&gt;       
	&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;updates&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;PEval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vals&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;updates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vertices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;updates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MAX_INT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;updates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dijkstra&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vals&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;updates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;IncEval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vals&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;updates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dijkstra&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vals&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;updates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Currently, the PIE model has been developed and evaluated in the graph analytical engine of GraphScope. On the LDBC Graph Analytics benchmark, GraphScope outperforms other state-of-the-art graph processing systems (see &lt;a href=&quot;https://github.com/alibaba/libgrape-lite/blob/master/Performance.md&quot;&gt;link&lt;/a&gt;). Welcome to try and develop your own graph algorithms with GraphScope.&lt;/p&gt;

&lt;h4 id=&quot;references&quot;&gt;References&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Some images in this article are cited from [2] and https://twitter.com/katestarbird/status/1358088750765539329/photo/1.&lt;/li&gt;
  &lt;li&gt;[1] Malewicz, Grzegorz, et al. “Pregel: a system for large-scale graph processing.” Proceedings of the 2010 ACM SIGMOD International Conference on Management of data. 2010.&lt;/li&gt;
  &lt;li&gt;[2] Gonzalez, Joseph E., et al. “Powergraph: Distributed graph-parallel computation on natural graphs.” 10th USENIX Symposium on Operating Systems Design and Implementation (OSDI 12). 2012.&lt;/li&gt;
  &lt;li&gt;[3] Tian, Yuanyuan, et al. “From” think like a vertex” to” think like a graph”.” Proceedings of the VLDB Endowment 7.3 (2013): 193-204.&lt;/li&gt;
  &lt;li&gt;[4] Yan, Da, et al. “Blogel: A block-centric framework for distributed computation on real-world graphs.” Proceedings of the VLDB Endowment 7.14 (2014): 1981-1992.&lt;/li&gt;
  &lt;li&gt;[5] Fan, Wenfei, et al. “Parallelizing sequential graph computations.” ACM Transactions on Database Systems (TODS) 43.4 (2018): 1-39.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Thu, 25 Mar 2021 18:21:42 +0800</pubDate>
        <link>https://graphscope.io/blog/tech/2021/03/25/a-review-of-programming-models-for-parallel-graph-processing.html</link>
        <guid isPermaLink="true">https://graphscope.io/blog/tech/2021/03/25/a-review-of-programming-models-for-parallel-graph-processing.html</guid>
        
        
        <category>Tech</category>
        
      </item>
    
      <item>
        <title>Introducing GraphScope Playground</title>
        <description>&lt;p&gt;&lt;img src=&quot;/blog/assets/images/try-record.gif&quot; alt=&quot;try-record.gif&quot; /&gt; 
Today we released &lt;a href=&quot;https://github.com/alibaba/GraphScope/releases/tag/v0.2.0&quot;&gt;GraphScope 0.2.0&lt;/a&gt;.  With this release, we are happy to introduce &lt;a href=&quot;http://try.graphscope.app/&quot;&gt;GraphScope Playground&lt;/a&gt;, a hosted JupyterLab with GraphScope ready out-of-the-box. Now you can get started with GraphScope straight away in your browser without any hassle for setting it up.&lt;/p&gt;

&lt;h4 id=&quot;signing-in&quot;&gt;Signing-in&lt;/h4&gt;
&lt;p&gt;The GraphScope Playground is built on top of &lt;a href=&quot;https://jupyter.org/hub&quot;&gt;JupyterHub&lt;/a&gt;. At the moment, it only supports Github OAuth for signing-in. Please make sure you have a &lt;a href=&quot;https://github.com/join&quot;&gt;Github account&lt;/a&gt; before proceed.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/try-login.gif&quot; alt=&quot;try-login.gif&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Open &lt;a href=&quot;https://try.graphscope.app/&quot;&gt;GraphScope PlayGround&lt;/a&gt; in your browser. You will be shown a landing page of GraphScope Playground. It only take a few clicks to get authenticated with your Github account. A JupyterLab session will be created for you in a few seconds.&lt;/p&gt;

&lt;h4 id=&quot;in-the-playground&quot;&gt;In the Playground&lt;/h4&gt;
&lt;p&gt;You will be redirected to the JupyterLab interface after signing-in. It is a modern integrated development environment for Notebooks, where documents and activities integrate with each other, enabling new workflows for interactive computing in Python.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/raw-playground-snapshot.png&quot; alt=&quot;gs-snapshot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;On the left, there is a sidebar, where you can navigate your workspace with the file browser, as well as check the list of running kernels and terminals, the command palette, and the list of tabs in the main work area etc. One the right, it is the main work area, where tabs and panes can be created for the files and notebooks you edit. You can also open a terminal if you like.&lt;/p&gt;

&lt;p&gt;A JupyterLab session lives inside a docker container is specifically created for you after signing-in. The session will live for up to 120 mins (or 15 mins without user interactions). Based on the the official &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;jupyterhub/singleuser:1.3&lt;/code&gt; image, we added necessary packages, tutorials and sample datasets for running GraphScope to the  Playground image. You are given 1 CPU core and 2GB memory for the JupyterLab container, and you are also given the access to a Kubernetes cluster with a limit of 16 CPU cores and 32GB memory for you to run GraphScope sessions. Following the convention of JupyterLab, the default working directory is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/home/jovyan/&lt;/code&gt;,  where you can find tutorials at the root, datasets under the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;datasets&lt;/code&gt; folder and a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;workspace&lt;/code&gt; folder.&lt;/p&gt;

&lt;p&gt;You can open an existing / create a new notebook, and start coding with GraphScope straight away. If you want to access the files you edited at a later time, you can place them under &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;workspace&lt;/code&gt; folder. All the changes elsewhere will be reset after session ends. We place  &lt;strong&gt;a copy of the sample datasets&lt;/strong&gt; on K8s hosts, which can be &lt;a href=&quot;https://nbviewer.jupyter.org/github/alibaba/GraphScope/blob/main/tutorials/1_how_to_launch_a_session.ipynb#Mounting-Volumes&quot;&gt;mounted to the GraphScope pods&lt;/a&gt;. Please note that your local edits to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;~/datasets&lt;/code&gt; won’t affect the copy on K8s hosts (&lt;em&gt;stay tuned!&lt;/em&gt;).&lt;/p&gt;

&lt;h4 id=&quot;tutorials&quot;&gt;Tutorials&lt;/h4&gt;

&lt;p&gt;In the GraphScope Playground, you have access to a set of comprehensive tutorials to get started with GraphScope. In the tutorials you could learn how to launch a session, to load graphs, and to run analytical analysis, interactive queries as well as graph neural network trainings in GraphScope. At the moment, we have the following tutorials included.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://nbviewer.jupyter.org/github/alibaba/GraphScope/blob/main/tutorials/1_how_to_launch_a_session.ipynb&quot;&gt;How to Create a Session&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://nbviewer.jupyter.org/github/alibaba/GraphScope/blob/main/tutorials/2_loading_graphs.ipynb&quot;&gt;Loading Graphs&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://nbviewer.jupyter.org/github/alibaba/GraphScope/blob/main/tutorials/3_builtin_analytical_algorithms.ipynb&quot;&gt;Built-in Analytical Algorithms&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://nbviewer.jupyter.org/github/alibaba/GraphScope/blob/main/tutorials/4_writing_your_own_algorithms.ipynb&quot;&gt;Writing Your Own Algorithms&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://nbviewer.jupyter.org/github/alibaba/GraphScope/blob/main/tutorials/5_interactive_query_with_gremlin.ipynb&quot;&gt;Interactive Query with Gremlin&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://nbviewer.jupyter.org/github/alibaba/GraphScope/blob/main/tutorials/6_unsupervised_learning_with_graphsage.ipynb&quot;&gt;Unsupervised Learning with GraphSage&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://nbviewer.jupyter.org/github/alibaba/GraphScope/blob/main/tutorials/7_supervised_learning_with_gcn.ipynb&quot;&gt;Supervised Learning with GCN&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://nbviewer.jupyter.org/github/alibaba/GraphScope/blob/main/tutorials/8_node_classification_on_citation_network.ipynb&quot;&gt;A Complex Workflow: Node Classification on Citation Network&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;stay-tuned-for-new-features&quot;&gt;Stay tuned for new features&lt;/h1&gt;
&lt;p&gt;With GraphScope Playground, we wish to make getting started with GraphScope as easy as possible. We are constantly working on improving the experience. If you have any questions or feedbacks, feel free to write a &lt;a href=&quot;https://github.com/alibaba/GraphScope/discussions&quot;&gt;post at Github Discussions&lt;/a&gt;. Happy Coding!&lt;/p&gt;

&lt;p&gt;Please note that the service provided by GraphScope Playground is strictly limited to the trial of GraphScope only. Any other use is strictly prohibited. Your use of the service will be at your own risk. And we provide no warranties to the service.&lt;/p&gt;
</description>
        <pubDate>Mon, 01 Feb 2021 14:33:20 +0800</pubDate>
        <link>https://graphscope.io/blog/newsroom/2021/02/01/introducing-graphscope-playground.html</link>
        <guid isPermaLink="true">https://graphscope.io/blog/newsroom/2021/02/01/introducing-graphscope-playground.html</guid>
        
        
        <category>Newsroom</category>
        
      </item>
    
      <item>
        <title>Release Notes: v0.2.0</title>
        <description>&lt;p&gt;&lt;img src=&quot;/blog/assets/images/release_note_t.png&quot; alt=&quot;release-note&quot; /&gt;
The GraphScope team is pleased to announce the 0.2.0 release after two-months development.
The 0.2.0 release is focused on better getting started experience for end-users and we have
make a lot of improvements since the last minor release. We have improved our documentation
a lot, and made the kubernetes integration work for more settings. We have also brought the
support for various I/O to make GraphScope suitable for more production environments.&lt;/p&gt;

&lt;p&gt;Along with the 0.2.0 release we also bring &lt;a href=&quot;https://try.graphscope.app&quot;&gt;GraphScope Playground&lt;/a&gt; to users
for getting started with GraphScope easier.&lt;/p&gt;

&lt;p&gt;We highlights the following improvements included in this releases:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Better Kubernetes integration.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LoadBalancer&lt;/code&gt; service type has been supported in this release, which brings GraphScope to
vendored could environments like Alibabacloud, AWS and Azure.&lt;/li&gt;
      &lt;li&gt;A &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;volumes&lt;/code&gt; parameter has been added to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;graphscope.session()&lt;/code&gt; to allow users mount their
volumes (host path, or cloud volumes, etc.) to worker pods for input graph data and retrieve
results.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Enhancement for interactive query.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;GraphScope v0.2.0 added a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;InteractiveQuery.traversal_source()&lt;/code&gt; method to allows an interative
query seamlessly works with the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gremlinpython&lt;/code&gt; SDK.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Better I/O and serialization support.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;GraphScope v0.2.0 started to support various I/O, including Aliyun OSS, AWS S3, HDFS and other
storage services that the filesystem-spec could support, for input datasets and result sink.&lt;/li&gt;
      &lt;li&gt;GraphScope v0.2.0 added a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Graph.serialize()&lt;/code&gt; method to allow users serialize a graph to external
storage and restore it back via &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Graph.deserailize()&lt;/code&gt;.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Bugfix for learning engine.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;A bug in closing learning instance of a graph has been fixed along this release.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;For more detailed bugfixes and improvements that have been made in
this version, please refer to the &lt;a href=&quot;https://github.com/alibaba/GraphScope/releases/tag/v0.2.0&quot;&gt;complete changelog&lt;/a&gt;.&lt;/p&gt;
</description>
        <pubDate>Mon, 01 Feb 2021 11:33:20 +0800</pubDate>
        <link>https://graphscope.io/blog/releasenotes/2021/02/01/release-notes-0.2.0.html</link>
        <guid isPermaLink="true">https://graphscope.io/blog/releasenotes/2021/02/01/release-notes-0.2.0.html</guid>
        
        
        <category>ReleaseNotes</category>
        
      </item>
    
      <item>
        <title>Say Hello to GraphScope!</title>
        <description>&lt;p&gt;&lt;img src=&quot;/blog/assets/images/releasing.png&quot; alt=&quot;graphscope-releasing&quot; /&gt;
The source code of GraphScope is released today!&lt;/p&gt;

&lt;p&gt;github repo: &lt;a href=&quot;https://github.com/alibaba/graphscope&quot;&gt;https://github.com/alibaba/graphscope&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GraphScope aims to provide a single system that is able to support three
types of computation tasks, i.e., graph interactive query, graph analytics and graph deep learning.
We carefully design GraphScope with user-friendly interface and extensible programming APIs,
so that users can easily construct customized end-to-end graph processing pipelines involving
different types of graph computation tasks. In specific, GraphScope fully embraces the Python and
Gremlin ecosystem, and thus comes with a shallow learning curve for both data scientists and
developers. Under the hood, GraphScope comprises core engines specifically optimized for each
graph computation paradigm, and can smoothly orchestrate multiple engines to cooperate efficiently,
avoiding the complexity of manually stitching multiple independent systems together. GraphScope
can scale to ultra-large graphs, and run in industrial speed and robustness.&lt;/p&gt;

&lt;p&gt;GraphScope is released under Apache License 2.0. Any contributions are greatly appreciated!
You may reach us at &lt;a href=&quot;http://slack.graphscope.io/&quot;&gt;Slack channel&lt;/a&gt; or submit 
&lt;a href=&quot;https://github.com/alibaba/GraphScope/issues&quot;&gt;GitHub issues&lt;/a&gt;.&lt;/p&gt;
</description>
        <pubDate>Mon, 07 Dec 2020 18:18:42 +0800</pubDate>
        <link>https://graphscope.io/blog/newsroom/2020/12/07/say-hello-to-graphscope.html</link>
        <guid isPermaLink="true">https://graphscope.io/blog/newsroom/2020/12/07/say-hello-to-graphscope.html</guid>
        
        
        <category>Newsroom</category>
        
      </item>
    
  </channel>
</rss>
