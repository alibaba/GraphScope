<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title></title>
    <description>graphscope blog</description>
    <link>https://graphscope.io/blog/</link>
    <atom:link href="https://graphscope.io/blog/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Thu, 17 Aug 2023 06:50:10 +0000</pubDate>
    <lastBuildDate>Thu, 17 Aug 2023 06:50:10 +0000</lastBuildDate>
    <generator>Jekyll v4.3.2</generator>
    
      <item>
        <title>FLASH: A Programming Model for Distributed Graph Algorithms</title>
        <description>&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-08-16-title-picture.jpg&quot; alt=&quot;flash-model&quot; /&gt;
In this post, we will introduce &lt;a href=&quot;https://graphscope.io/publication/flash.pdf&quot;&gt;FLASH&lt;/a&gt;, which is a distributed programming model for programming a broad spectrum of graph algorithms, including clustering, centrality, traversal, matching, mining, etc. It makes diverse complex graph algorithms easy to write at the distributed runtime. The algorithms expressed in FLASH take only a few lines of code, and provide a satisfactory performance.&lt;/p&gt;

&lt;h3 id=&quot;motivation&quot;&gt;Motivation&lt;/h3&gt;

&lt;p&gt;The majority of recent graph processing frameworks only focus on a handful of fix-point graph algorithms such as breadth-first search, PageRank, shortest path, etc. It leaves the distributed computation of a large variety of graph algorithms suffering from low efficiency, limited expressiveness, or high implementation complexity with existing frameworks. The well-known vertex-centric implementation of a graph algorithm follows a common iterative, single-phased and value-propagation-based (short of ISVP) pattern: the algorithm runs iteratively until convergence, and in each iteration, all vertices receive messages from their neighbors to update their own states, then they send the updated states as messages to the neighbors for the next iteration. Such high-level abstraction brings productivity to some extent to users, however, at the sacrifice of expressiveness. This abstraction, while designed specifically for the ISVP algorithms, is almost infeasible to be applied to a large variety of algorithms that are not of the kind. At the same time, modern graph scenarios bring in the needs of more advanced and complex graph algorithms, which poses a big challenge for existing graph processing frameworks.&lt;/p&gt;

&lt;p&gt;After investigating representative distributed graph algorithms, including many non-ISVP ones, we have distilled three requirements that are critical for programming them efficiently and productively in a distributed context, namely (1) flexible control flow; (2) operations on vertex subsets; and (3) beyond-neighborhood communication. However, existing graph frameworks all fall short in meeting these requirements. Therefore, there is a need to design a new programming model which fulfills all of the three requirements, and supports to program in a distributed context.&lt;/p&gt;

&lt;h3 id=&quot;the-flash-programming-model&quot;&gt;The FLASH Programming Model&lt;/h3&gt;

&lt;h4 id=&quot;overview&quot;&gt;Overview&lt;/h4&gt;

&lt;p&gt;FLASH follows the &lt;a href=&quot;https://graphscope.io/docs/latest/analytical_engine/vertex_centric_models.html&quot;&gt;vertex-centric&lt;/a&gt; philosophy, but it moves a step further for stronger expressiveness by providing flexible control flow, the operations on arbitrary vertex sets and beyond-neighborhood communication.&lt;/p&gt;

&lt;p&gt;The FLASH programming model is based on &lt;a href=&quot;https://github.com/jshun/ligra&quot;&gt;Ligra&lt;/a&gt; to inherit its support for the requirements of flexible control flow and operations on vertex subsets. By further enabling beyond-neighborhood communication, FLASH improves the expressiveness for programming a diverse variety of graph algorithms. Since Ligra is a single-machine parallel library, FLASH makes an extension to the distributed context, for which it must handle communication, synchronization, data races and task scheduling. To do so, a middleware called FlashWare is proposed that hides all the above details for distribution, and provides the capability to apply multiple system optimizations automatically and adaptively at the runtime.&lt;/p&gt;

&lt;p&gt;We have implemented &lt;a href=&quot;https://github.com/alibaba/GraphScope/blob/main/python/graphscope/analytical/app/flash/__init__.py&quot;&gt;70+ graph algorithms&lt;/a&gt; with FLASH for 40+ different commonly used applications, and we can now program much more succinct codes using the FLASH programming interfaces, which also helps productivity. The evaluation results demonstrate FLASH’s capability of expressing many advanced algorithms (takes up to 92% less lines of code), while providing a satisfactory performance at the same time.&lt;/p&gt;

&lt;h4 id=&quot;flash-api&quot;&gt;FLASH API&lt;/h4&gt;

&lt;p&gt;FLASH is a functional programming model specific for distributed graph processing. It follows the Bulk Synchronous Parallel (BSP) computing paradigm with each of the primary functions constitutes a single superstep. It utilizes the &lt;em&gt;VertexSubset&lt;/em&gt; type which represents a set of vertices of the graph &lt;em&gt;G&lt;/em&gt;, containing a set of indices for all vertices in this set. The properties of vertices are maintained only once for a graph, shared by all &lt;em&gt;VertexSubset&lt;/em&gt;s. The following describes the APIs of FLASH based on &lt;em&gt;VertexSubset&lt;/em&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;VSize&lt;/em&gt;: This function returns the size of a &lt;em&gt;VertexSubset&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kt&quot;&gt;size_t&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;VSize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;VertexSubset&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;U&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;VertexMap&lt;/em&gt;: This interface applies the map function to each vertex in &lt;em&gt;U&lt;/em&gt; that passes the condition checking function &lt;em&gt;F&lt;/em&gt;. The indices of the output vertices form the resulting &lt;em&gt;VertexSubset&lt;/em&gt;. Specially, the &lt;em&gt;M&lt;/em&gt; function could be omitted for implementing the filter semantics, with the vertex data unchanged.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;VertexSubset&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;VertexMap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;VertexSubset&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;U&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                       &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Vertex&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;bool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                       &lt;span class=&quot;n&quot;&gt;M&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Vertex&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vertex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;EdgeMap&lt;/em&gt;: For a graph &lt;em&gt;G(V,E)&lt;/em&gt;, EdgeMap applies the update logic to the specific edges with source vertex in &lt;em&gt;U&lt;/em&gt; and target vertex satisfying &lt;em&gt;C&lt;/em&gt;. &lt;em&gt;H&lt;/em&gt; represents the edge set to conduct updates, which is &lt;em&gt;E&lt;/em&gt; in common cases. We allow the users to define arbitrary edge sets they want dynamically at runtime, even virtual edges generated during the algorithm’s execution. The edge set can be defined through defining a function which maps a source vertex index to a set of indices of the targets. We also provide some pre-defined operators for convenience, such as reverse edges, or edges with targets in a specific &lt;em&gt;VertexSubset&lt;/em&gt;. This extension makes the communication beyond the neighborhood-exchange limitation.
If a chosen edge passes the condition checking &lt;em&gt;F&lt;/em&gt;, the map function &lt;em&gt;M&lt;/em&gt; is applied on it. The output of the function &lt;em&gt;M&lt;/em&gt; represents a temporary new value of the target vertex. This new value is applied immediately and sequentially if it is in the pull mode, while in the push mode, another parameter &lt;em&gt;R&lt;/em&gt; is required to apply all the temporary new values on a specific vertex to get its final value. The updated target vertices form the output set of &lt;em&gt;EdgeMap&lt;/em&gt;. The reduce function &lt;em&gt;R&lt;/em&gt; should be associative and commutative to ensure correctness, or it is not required for sequentially applying &lt;em&gt;M&lt;/em&gt;, i.e., to run EdgeMap always in the pull mode. The function &lt;em&gt;C&lt;/em&gt; is useful in algorithms where a value associated with a vertex only needs to be updated once. FLASH provides a default function &lt;em&gt;CTrue&lt;/em&gt; which always returns true, since the user does not need this functionality sometimes. Similarly, the &lt;em&gt;F&lt;/em&gt; function of EdgeMap and VertexMap can also be supplied using &lt;em&gt;CTrue&lt;/em&gt;, if it is unnecessary.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;VertexSubset&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;EdgeMap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;VertexSubset&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;U&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                     &lt;span class=&quot;n&quot;&gt;EdgeSet&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;H&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                     &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Vertex&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Vertex&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;bool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                     &lt;span class=&quot;n&quot;&gt;M&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Vertex&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Vertex&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Vertex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                     &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Vertex&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;bool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                     &lt;span class=&quot;n&quot;&gt;R&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Vertex&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Vertex&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Vertex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Other auxiliary APIs are provided by FLASH for conveniently conducting set operations (including &lt;em&gt;Union&lt;/em&gt;, &lt;em&gt;Minus&lt;/em&gt;, &lt;em&gt;Intersect&lt;/em&gt;, &lt;em&gt;Add&lt;/em&gt;, &lt;em&gt;Contain&lt;/em&gt;, etc.), traversing all vertices in a set (&lt;em&gt;Traverse&lt;/em&gt;), getting the data value of a single vertex (&lt;em&gt;GetV&lt;/em&gt;) and so on.&lt;/p&gt;

&lt;h4 id=&quot;strong-expressiveness&quot;&gt;Strong Expressiveness&lt;/h4&gt;

&lt;p&gt;Besides expressing existing vertex-centric algorithms, FLASH provides the possibility of expressing more advanced algorithms. It is the first distributed graph processing model that satisfies all of the three critical requirements for programming non-ISVP algorithms.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;FLASH allows the users to define the arbitrary control flow by combining the primitives, thus it can naturally support multi-phased algorithms. In traditional vertex-centric models, these algorithms are supported in an awkward way since they only allow to provide a single user-defined function.&lt;/li&gt;
  &lt;li&gt;The &lt;em&gt;VertexSubset&lt;/em&gt; structure supplements the perspective of a single vertex, allowing to conduct updates on arbitrary vertices. Multiple vertex subsets can be maintained at the same time, they can even be defined in a recursive function. Without this feature, a framework has to start from the whole graph every time and pick up specific vertices every time.&lt;/li&gt;
  &lt;li&gt;FLASH allows the users to provide the arbitrary edge set they want to transfer messages, even when the edges do not exist in the original graph. Therefore, algorithms that contain communication beyond neighborhood can be expressed intuitively.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;implementation&quot;&gt;Implementation&lt;/h3&gt;

&lt;h4 id=&quot;architecture&quot;&gt;Architecture&lt;/h4&gt;

&lt;p&gt;The architecture of FLASH contains several main components, as shown in the following figure. The first is a code generator which takes the high-level FLASH APIs as input, and generates execution code to be run on the second component named FlashWare, which is a middleware designed and optimized for the FLASH model and is implemented based on the fundamental modules of GraphScope. The FlashWare executes the code produced by the code generator on the distributed runtime, utilizing the ability of parallel computing and communication ability of GraphScope.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-08-16-flash-architecture.jpg&quot; alt=&quot;flash-architecture&quot; /&gt;&lt;/p&gt;
&lt;center&gt; Figure 1: The architecture of FLASH. &lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;optimizations&quot;&gt;Optimizations&lt;/h4&gt;

&lt;p&gt;Some optimizations are introduced in the implementation of the FLASH model:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;During graph processing, the type of an active set may be dense or sparse, FLASH could dispatch different computation kernels for different types of the active set: the push mode for sparse active sets and the pull mode for dense active sets. This auto-switch scheme is proved to be useful for real-world graphs. Also, FLASH ’s dual mode processing is optional: users may choose to execute in only one mode through calling EdgeMapDense/EdgeMapSparse, instead of EdgeMap.&lt;/li&gt;
  &lt;li&gt;FLASH utilizes separate threads to execute message passing, while other threads perform parallel vertex-centric processing, thus the computation and communication tasks are co-scheduled, leading to a performance improvement.&lt;/li&gt;
  &lt;li&gt;In some cases, there are multiple vertex properties, but not all of them are critical. A property is critical only if it is accessed by other vertices, thus the update to the master need to be broadcasted to its mirrors. On the contrary, if it is only useful in local computation, it is not critical. This optimization reduces the size of a single message from the total size of all properties to only that of critical properties.&lt;/li&gt;
  &lt;li&gt;Another way to eliminate redundant messages is to communicate with only the necessary mirrors. For normal graph applications, the messages are transferred along the edges. Therefore, a vertex should only broadcast to the partitions that contain at least one neighbor of this vertex. Only in the cases that the programmers define virtual edges for EdgeMap, which beyond the scope of &lt;em&gt;E&lt;/em&gt;, FlashWare synchronizes the update on a vertex to all partitions, thus this optimization is disabled.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Wed, 16 Aug 2023 03:10:42 +0000</pubDate>
        <link>https://graphscope.io/blog/tech/2023/08/16/FLASH-A-Programming-Model-for-Distributed-Graph-Algorithms.html</link>
        <guid isPermaLink="true">https://graphscope.io/blog/tech/2023/08/16/FLASH-A-Programming-Model-for-Distributed-Graph-Algorithms.html</guid>
        
        
        <category>Tech</category>
        
      </item>
    
      <item>
        <title>Processing 100-billion edges in one second: Empowering Graphalytics with GPU Acceleration</title>
        <description>&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-08-08-title-picture.jpg&quot; alt=&quot;GPU-feature&quot; /&gt;
Graph algorithms serve as essential building blocks for a wide range of applications, such as social network analytics, routing, constructing protein network and &lt;a href=&quot;https://en.wikipedia.org/wiki/De_Bruijn_graph&quot;&gt;De Bruijn graphs&lt;/a&gt;, and mining valuable information in RDF (Resource Description Framework) graphs. Generally, graph analytics involve propagating labels across edges or iteratively accumulating values from adjacent vertices. Existing engines in both academia and industry, like &lt;a href=&quot;https://github.com/jegonzal/PowerGraph&quot;&gt;PowerGraph&lt;/a&gt;, &lt;a href=&quot;https://kowshik.github.io/JPregel/pregel_paper.pdf&quot;&gt;Pregel&lt;/a&gt;, and &lt;a href=&quot;https://spark.apache.org/graphx/&quot;&gt;GraphX&lt;/a&gt;, have paved the way. However, in the era of big data, the computational and storage complexity of sophisticated algorithms coupled with rapidly growing datasets have exhausted the limits of a single device.&lt;/p&gt;

&lt;p&gt;Traditionally, graph analysis tasks, characterized by data-intensive workloads, have been performed on CPUs. 
However, the emergence of diverse new hardware in recent years has led to the recognition of the potential in constructing heterogeneous computing platforms using accelerator cards (such as FPGAs and GPUs).
These accelerators often offer higher degrees of parallelism; for instance, an Nvidia V100 GPU can provide over 5,000 computation cores.
Additionally, they exhibit enhanced memory bandwidth capabilities; HBM, for instance, can deliver several TB/s of memory bandwidth. 
Numerous tasks have already harnessed the potential of such accelerator to achieve significant performance boosts, including deep learning and image processing, and graph computation is no exception.&lt;/p&gt;

&lt;h3 id=&quot;cpu-vs-gpu&quot;&gt;CPU vs GPU&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-08-08-cpu-vs-gpu.jpg&quot; alt=&quot;CPU vs GPU&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The above figure illustrates the key differences in architecture between CPUs and GPUs.
CPUs feature relatively complex components, with most of the area dedicated to elements like prefetching, branch prediction, and caching, all aimed at improving CPU core computational efficiency, enabling them to handle intricate logic. 
In contrast, GPUs have simpler components but stack a large number of cores, with longer pipelines. 
When processing data, GPUs operate in a SIMT (Single Instruction, Multiple Threads) manner, typically grouping 32 threads together (some GPUs use groups of 64 threads), known as thread warps (warp in Nvidia GPUs, wave in AMD GPUs). 
These thread warps execute the same instruction stream simultaneously, and GPUs rely on warp schedulers to hide data fetch latencies. 
Moreover, GPUs have multiple memory hierarchies, necessitating data movement between main memory, video memory, on-chip shared memory, and vector registers.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt;E5 2682&lt;/th&gt;
      &lt;th&gt;NVIDIA V100&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Clock&lt;/td&gt;
      &lt;td&gt;2.5GHz&lt;/td&gt;
      &lt;td&gt;877MHz&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Cores&lt;/td&gt;
      &lt;td&gt;8x2&lt;/td&gt;
      &lt;td&gt;5120 (FP32)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Prices&lt;/td&gt;
      &lt;td&gt;~$1,000&lt;/td&gt;
      &lt;td&gt;~$10,000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Mem b/w&lt;/td&gt;
      &lt;td&gt;~40GB/s&lt;/td&gt;
      &lt;td&gt;~1TB/s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Mem size&lt;/td&gt;
      &lt;td&gt;~2TB&lt;/td&gt;
      &lt;td&gt;16GB&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;This table provides a comparison of specific hardware parameters between CPUs and GPUs. 
In terms of computational power, GPUs have more cores, allowing them to process more data simultaneously and achieve higher levels of parallelism. 
This higher parallelism aligns well with the inherently high concurrency of graph algorithms, where each vertex can serve as a parallel unit. 
Consequently, GPUs demonstrate higher throughput when handling graph algorithms. However, individual GPU cores are weaker and operate at lower clock frequencies compared to CPUs.
This characteristic makes GPUs more susceptible to long tail effects when facing load imbalances.
In scenarios with imbalanced workloads, most GPU cores might idle while waiting for a few weaker cores to complete their computations. 
Unfortunately, graph data exhibits inherent irregularity, with skewed edge distributions, where a small number of vertices possess the majority of edges, while most vertices are only connected by a few edges. This irregularity further amplifies the challenge of achieving load balance on GPUs.&lt;/p&gt;

&lt;p&gt;When it comes to memory access capabilities, GPUs indeed have higher bandwidth, such as the Nvidia V100 equipped with HBM2, which offers a bandwidth of up to 1TB/s. When GPU warps access adjacent data blocks, they can trigger coalesced memory access, combining multiple memory requests into a single one, providing an advantage over CPUs when handling large amounts of data. However, graph algorithms, especially parallel graph traversal algorithms, require simultaneous processing of a large number of edge data. Although GPUs boast higher memory bandwidth than CPUs, the memory access patterns of graph algorithms are unpredictable. Graph algorithms often need to randomly access a significant amount of data from memory, with each access touching only a small portion of memory (usually representing vertex states, which are not very large in graph analysis tasks). This leads to highly inefficient memory bandwidth utilization, often falling short of the theoretical peak.
Additionally, GPU memory capacity is much smaller than that of CPUs, making it challenging for GPUs to handle larger-scale graph data. Furthermore, GPUs struggle to execute algorithms with high memory requirements, especially those that need to store large amounts of intermediate results for graph mining tasks.&lt;/p&gt;

&lt;h3 id=&quot;when-efficient-graph-algorithms-go-inefficient-on-gpus&quot;&gt;When Efficient Graph Algorithms Go Inefficient on GPUs&lt;/h3&gt;

&lt;p&gt;There is a significant gap between GPU and CPU architectures. Merely transferring CPU algorithms to GPUs may not lead to improved performance; it could even result in performance degradation.&lt;/p&gt;

&lt;p&gt;Due to GPUs having more but weaker cores compared to CPUs, graph algorithms running on GPUs should be adjusted appropriately to fully leverage the high concurrency of GPUs. We can achieve higher concurrency by sacrificing some single-thread efficiency in the algorithm.
For instance, in the case of the shortest path problem, efficient algorithms like &lt;a href=&quot;https://en.wikipedia.org/wiki/Edsger_W._Dijkstra&quot;&gt;Dijkstra&lt;/a&gt; are commonly used on CPUs. 
Dijkstra maintains a small min-heap and processes only the closest unprocessed vertices to the source vertex, ensuring that each vertex is processed only once. This ordered update approach is highly efficient but limits concurrency based on the degree of each vertex.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-08-08-efficiency-vs-parallelism.jpg&quot; alt=&quot;Efficiency vs Parallelism&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In contrast, Bellman-Ford processes all edges in each update round, providing higher concurrency, but with slightly lower update efficiency as each vertex might be processed multiple times. 
As shown in the above Figure, during the first round of updates from the source vertex &lt;em&gt;S&lt;/em&gt;, vertices &lt;em&gt;A&lt;/em&gt; and &lt;em&gt;B&lt;/em&gt; are modified, and &lt;em&gt;B&lt;/em&gt;’s distance is updated to 30.
Subsequently, vertex &lt;em&gt;B&lt;/em&gt; updates its neighbors, and in the next round, its distance is modified to 21 via vertex &lt;em&gt;A&lt;/em&gt;, triggering updates to other vertices by vertex &lt;em&gt;B&lt;/em&gt;. Using Dijkstra, however, only the closer vertices are processed, avoiding repetitive transmission of invalid data by vertex B.&lt;/p&gt;

&lt;p&gt;By carefully considering the trade-off between concurrency and single-thread efficiency, graph algorithms can be tailored to effectively harness the potential of GPU’s high concurrency while optimizing their performance on GPUs.&lt;/p&gt;

&lt;p&gt;When considering GPUs, a delicate balance between parallelism and computational efficiency must be struck. On one hand, GPUs possess numerous cores; however, utilizing Dijkstra’s algorithm on them demands maintaining a costly concurrent heap, which subsequently curtails the achievable level of concurrency, thus impeding the exploitation of the GPU’s potential. 
On the other hand, given the relatively weaker nature of GPU cores, adopting algorithms with lower computational efficiency could potentially lead to slower performance compared to directly employing efficient algorithms on CPUs.&lt;/p&gt;

&lt;p&gt;To navigate this trade-off, we introduce the concept of an update window, denoted as &lt;em&gt;w&lt;/em&gt;. 
&lt;em&gt;w&lt;/em&gt; serve as a soft adjustable threshold value to balance the efficiency and parallelism.
In each iteration round, only vertices with distances falling within the update window are processed (specifically, those vertices &lt;em&gt;u&lt;/em&gt; satisfying &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dis[u] &amp;lt; w&lt;/code&gt;). 
After completing updates within a window, the window &lt;em&gt;w&lt;/em&gt; is slid, targeting vertices with distances in next window, i.e. interval &lt;em&gt;[w, 2w)&lt;/em&gt;. 
This process continues until all active vertices have undergone updates, signaling the transition to the next iteration. 
The size of the window &lt;em&gt;w&lt;/em&gt; serves as a tuning parameter, affording users the flexibility to specify &lt;em&gt;w&lt;/em&gt; and thus adapt to diverse datasets and computing platforms with precision.&lt;/p&gt;

&lt;h3 id=&quot;load-balance-is-more-important-than-you-think&quot;&gt;Load Balance is More Important than You Think&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-08-08-load-balance.jpg&quot; alt=&quot;Load balance&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As mentioned above, due to the irregular nature of graph algorithms, which does not align well with the SIMT architecture of GPUs, this irregular computation can result in severe load imbalance, making it crucial for GPU-based graph algorithms. 
To cope with load imbalance, we have four different load balancing strategies, as illustrated in above.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;TWC (Thread-Warp-CTA) is the lowest-overhead load balancing method. It divides the currently active vertex set based on their out-degrees into low, medium, and high-degree vertices, and then maps them to threads, warps, and CTAs for processing.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;WM (Warp-Managed) primarily addresses load imbalance within a warp. It processes a fixed number of vertices as a batch and loads their neighbors into the GPU’s shared memory until all neighbors are processed before moving to the next batch. Each thread performs a binary search on the edges to determine their corresponding vertex.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;CM (CTA-Managed) is similar to WM, but focuses on load imbalance within a CTA. Like WM, it processes a fixed number of vertices as a batch and loads their neighbors into shared memory. However, CM uses a broader binary search to find the corresponding vertex for the edge, and threads in CM require explicit synchronization.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;STRICT is the highest-overhead load balancing method, ensuring that each thread in the GPU handles the same number of edges. It enforces equal edge distribution in each CTA, requiring additional preprocessing to partition the edges that need processing, with some nodes’ edges distributed across different CTAs, necessitating atomic operations during updates for consistency.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Theoretically, STRICT guarantees the best load balancing, but it incurs the highest overhead. It is often the optimal choice when the active vertex set contains a vertex with a large number of edges. TWC offers the lowest overhead but only guarantees approximate balance. WM/CM falls between the two extremes, with WM’s primary overhead being the binary search, taking no more than &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;log2(warpsize)&lt;/code&gt; steps to complete, while CM’s overhead is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;log2(blocksize)&lt;/code&gt; steps.&lt;/p&gt;

&lt;h3 id=&quot;try-gpu-based-graphalytics-on-graphscope&quot;&gt;Try GPU-based Graphalytics on GraphScope&lt;/h3&gt;

&lt;p&gt;If you are looking for an out-of-box GPU-based graphalytics library, come and try &lt;a href=&quot;https://github.com/alibaba/GraphScope&quot;&gt;GraphScope&lt;/a&gt;.
Our recent update on graph analytical engine (&lt;a href=&quot;https://github.com/alibaba/libgrape-lite/&quot;&gt;GAE&lt;/a&gt;) of GraphScope introduces a new feature for GPU acceleration and achieves amazing performance on large graphs.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-08-08-performance.jpg&quot; alt=&quot;Performance&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The above chart illustrates the performance achieved by GPU-based GraphScope on a single node with eight A100 GPUs when running on graph data of various sizes. It showcases the throughput in terms of edges processed per second while handling this data. Processing a graph data set with 8 billion edges takes just 85 milliseconds, significantly outperforming the results obtained from a distributed cluster composed of multiple CPU nodes.&lt;/p&gt;

&lt;p&gt;GraphScope continues to evolve, and we are working on ways to provide flexibility and performance. 
We are building out the next version of GraphScope that will start to provide more exciting features like GPU, &lt;a href=&quot;https://en.wikipedia.org/wiki/Remote_direct_memory_access&quot;&gt;RDMA&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/Compute_Express_Link&quot;&gt;CXL&lt;/a&gt;. 
Reach out to us via &lt;a href=&quot;https://github.com/alibaba/GraphScope/discussions&quot;&gt;Github Discussions&lt;/a&gt;. We’re here to help.&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;[1] Farzad Khorasani, Keval Vora, Rajiv Gupta, and Laxmi N. Bhuyan. CuSha: vertex-centric graph processing on GPUs. (&lt;a href=&quot;https://dl.acm.org/doi/abs/10.1145/2600212.2600227&quot;&gt;link&lt;/a&gt;)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;[2] Jianlong Zhong and Bingsheng He. Medusa: Simplified Graph Processing on GPUs. (&lt;a href=&quot;https://ieeexplore.ieee.org/document/6497047&quot;&gt;link&lt;/a&gt;)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;[3] Yangzihao Wang, Yuechao Pan, Andrew Davidson, Yuduo Wu, Carl Yang, Leyuan Wang, Muhammad Osama, Chenshan Yuan, Weitang Liu, Andy T. Riffel, and John D. Owens. Gunrock: GPU Graph Analytics. (&lt;a href=&quot;https://dl.acm.org/doi/10.1145/3108140&quot;&gt;link&lt;/a&gt;)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;[4] Tal Ben-Nun, Michael Sutton, Sreepathi Pai, and Keshav Pingali. Groute: An Asynchronous Multi-GPU Programming Model for Irregular Computations. (&lt;a href=&quot;https://dl.acm.org/doi/10.1145/3018743.3018756&quot;&gt;link&lt;/a&gt;)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;[5] Ke Meng, Jiajia Li, Guangming Tan, and Ninghui Sun. A pattern based algorithmic autotuner for graph processing on GPUs. (&lt;a href=&quot;https://dl.acm.org/doi/10.1145/3293883.3295716&quot;&gt;link&lt;/a&gt;)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;[6] K. Meng, L. Geng, X. Li, Q. Tao, W. Yu and J. Zhou, “Efficient Multi-GPU Graph Processing with Remote Work Stealing. (&lt;a href=&quot;https://ieeexplore.ieee.org/document/10184847&quot;&gt;link&lt;/a&gt;)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Tue, 08 Aug 2023 14:10:44 +0000</pubDate>
        <link>https://graphscope.io/blog/tech/2023/08/08/Empowering-Graph-Analysis-Tasks-with-GPU-Acceleration.html</link>
        <guid isPermaLink="true">https://graphscope.io/blog/tech/2023/08/08/Empowering-Graph-Analysis-Tasks-with-GPU-Acceleration.html</guid>
        
        
        <category>Tech</category>
        
      </item>
    
      <item>
        <title>Dynamic Graph Sampling Service for Realtime GNN Inference at Scale</title>
        <description>&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-08-06-title.jpg&quot; alt=&quot;dgs&quot; /&gt;
Graph neural networks(GNNs) learn graph vertex representations by aggregating multi-hop neighbor information. Industrial applications often adopt mini-batch training to scale out GNNs on large-scale graphs, where neighbor sampling is used during both model training and inference. Since the structure and attributes of real-world graphs often change dynamically, it is imperative that the inferred vertex representation can accurately reflect these updates.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/dgs.jpg&quot; alt=&quot;Training and Inference in Dynamic Graph&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;challenges-in-sampling-dynamic-graph&quot;&gt;Challenges in Sampling Dynamic Graph&lt;/h3&gt;
&lt;p&gt;GNN inference services, such as real-time recommendation systems, often require stable millisecond-level latency SLOs. However, meeting this requirement can be challenging due to highly concurrent inference requests and dynamic graph updates. Firstly, multi-hop sampling can introduce high time complexity, as sampling a vertex often requires traversing all its neighbors. Secondly, as the graphs in industrial 
settings often exceed the single-machine memory, graphs are either persisted in disk or partitioned and stored in memory in a distributed cluster. Both approaches will incur significant I/O overheads during graph sampling. Thirdly, the computation required for sampling different vertices can vary significantly due to the inherent skewness in real-world graphs, which will lead to unstable latency performance among
concurrent inference requests. Given these observations, existing approaches, e.g., using graph databases for storage and graph sampling, cannot fulfill the performance SLOs of real-time GNN inference services.&lt;/p&gt;

&lt;h3 id=&quot;how-does-dgs-solve-the-problem&quot;&gt;How does DGS Solve the Problem?&lt;/h3&gt;
&lt;p&gt;We propose Dynamic Graph Sampling Service (DGS), which aims to address the challenges associated with graph sampling in real-time GNN inference on dynamic graphs. Our key insight is that the GNN inference service is query-aware: given a GNN model, the graph sampling query for both training and inference is fixed. With this observation, we propose an event-driven pre-sampling mechanism in DGS. Driven by the graph updates, sample caches of vertices are dynamically updated using reservoir sampling following the specified query. In specific, DGS decomposes a k-hop sampling query into $k$ one-hop sampling queries. For each one-hop query, when a graph update of a relevant vertex (e.g., an edge sourcing from this vertex with a specified vertex label) arrives, the one-hop sampling results of this vertex will be updated accordingly. The k-hop sampling result of an inference request can be constructed via a fixed number of point look-ups in the cached one-hop sampling results. The following figure depicts an example of query decomposition.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/query.jpg&quot; alt=&quot;Query Decomposition&quot; /&gt;&lt;/p&gt;

&lt;p&gt;DGS further isolates graph pre-sampling and inference serving physically to avoid the interference between read and write workloads.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/DGSoverview.jpg&quot; alt=&quot;DGS Overview&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The overall architecture of DGS is depicted in the above figure. DGS mainly consists of two types of components: sampling workers and serving workers. The input graph updates are partitioned according to the key (e.g., vertex IDs) range. Each sampling worker is responsible for a specific partition: conducting pre-sampling for the one-hop sampling queries and transmitting the results to the serving workers. Each serving worker caches the sampling results of $k$ one-hop queries received from sampling workers and serves the inference requests for a partition of vertices in the graph. The sampling and serving workers can scale independently to cope with workload fluctuations of graph updates and inference requests. To minimize the latency in generating complete k-hop sampling results, DGS sends all k-hop sampling results of vertex $v_i$ to the serving worker that handles $v_i$’s inference request, such that generating the complete graph sampling for an inference request only requires accessing local caches on a single serving worker. To achieve this, every sampling worker maintains a subscription table for each one-hop query recording the list of serving workers that subscribe to the one-hop query results. E.g., either adding or deleting vertex $v_j$ from the first-hop samples of $v_i$ triggers a message recording this event sent to the sampling server that holds the partition containing $v_j$, and the subscription information of $v_j$ will be updated correspondingly. With this design, DGS can achieve a very stable latency performance under highly concurrent inference workloads.&lt;/p&gt;

&lt;h3 id=&quot;performance-of-dgs&quot;&gt;Performance of DGS&lt;/h3&gt;
&lt;p&gt;Experiments on real Alibaba e-commerce datasets show that DGS can maintain the P99 latency of inference requests  (of a two-hop random sampling query) within $20ms$ milliseconds, and process around $20,000$ requests per second in each serving worker. The throughput of update ingestion of a single sampling worker reaches $109$MB/s and can scale out linearly.&lt;/p&gt;

&lt;p&gt;This blog briefly introduces the design concept, system architecture, and performance of DGS. With DGS, users can infer the latest graph representation based on real-time changes in graph structure and features. We provide an end-to-end &lt;a href=&quot;https://graph-learn.readthedocs.io/en/latest/en/dgs/tutorial.html&quot;&gt;tutorial&lt;/a&gt; for training and model deployment, as well as online inference based on DGS. Please feel free to try it out! For more details, please refer to the &lt;a href=&quot;https://github.com/alibaba/graph-learn/tree/master/dynamic_graph_service&quot;&gt;source code&lt;/a&gt; and &lt;a href=&quot;https://graph-learn.readthedocs.io/en/latest/en/dgs/intro.html&quot;&gt;documents&lt;/a&gt;.&lt;/p&gt;

</description>
        <pubDate>Sun, 06 Aug 2023 11:00:00 +0000</pubDate>
        <link>https://graphscope.io/blog/tech/2023/08/06/Dynamic-Graph-Sampling-Service-for-Realtime-GNN-Inference-at-Scale.html</link>
        <guid isPermaLink="true">https://graphscope.io/blog/tech/2023/08/06/Dynamic-Graph-Sampling-Service-for-Realtime-GNN-Inference-at-Scale.html</guid>
        
        
        <category>Tech</category>
        
      </item>
    
      <item>
        <title>Developing and Running Customized Analytical Algorithms for GraphScope</title>
        <description>&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-07-23-title-picture.jpg&quot; alt=&quot;jupyter-notebook&quot; /&gt;
We provide a template repository for graph analysis applications, where users can customize graph analysis algorithms by replacing several C++ functions with their own logic, and run them on GraphScope.&lt;/p&gt;

&lt;p&gt;As a sophisticated model, graphs can naturally express a large number of real-life datasets, and tons of graph analytics algorithms have been proposed for different purposes. Typical graph analytics algorithms include &lt;a href=&quot;https://en.wikipedia.org/wiki/PageRank&quot;&gt;Pagerank&lt;/a&gt;、&lt;a href=&quot;https://arxiv.org/abs/cs/0310049&quot;&gt;K-core&lt;/a&gt; which have demonstrated strong capabilities in node importance analysis scenarios. The GraphScope graph analysis engine inherits the open source version of the &lt;a href=&quot;https://github.com/alibaba/libgrape-lite&quot;&gt;GRAPE&lt;/a&gt; system and includes various graph analysis algorithms, providing a one-stop graph analysis solution. However, users often need to customize algorithms based on their own bussiness. Therefore, to facilitate the development of custom graph analysis algorithms, we provide a C++ template library, and this article will introduce the usage of this template library.&lt;/p&gt;

&lt;h3 id=&quot;step1-install-graphscope&quot;&gt;Step1. Install GraphScope&lt;/h3&gt;

&lt;p&gt;First, we need to install GraphScope in the local environment with the following command:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pip3 &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;graphscope 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;step2-develop-algorithms-using-template-library&quot;&gt;Step2. Develop Algorithms Using Template Library&lt;/h3&gt;

&lt;p&gt;Open the &lt;a href=&quot;https://github.com/GraphScope/cpp-template&quot;&gt;address of the template library&lt;/a&gt; in your browser, click on the “Use this template” button on the right side of the repository to create your own code repository, and clone the repository to your local machine using the following command:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-07-23-template-repository.jpg&quot; alt=&quot;Template-Repository&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Make sure to replace the &amp;lt;username&amp;gt; and &amp;lt;repo-name&amp;gt; to the right values.&lt;/span&gt;
git clone https://github.com/&amp;lt;username&amp;gt;/&amp;lt;repo-name&amp;gt;.git 
&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; &amp;lt;repo-name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Next, we will implement custom algorithm logic by modifying the files in the src directory, including:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;my_app.h: This file is used to implement the main algorithm logic, namely the PEval and IncEval functions&lt;/li&gt;
  &lt;li&gt;my_app_context.h: This file is used to store and define the runtime results and data structures used by the algorithm&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;define-the-data-structures&quot;&gt;Define the Data Structures&lt;/h4&gt;

&lt;p&gt;To simplify the algorithm logic and highlight the algorithm development process, in this case, our algorithm will be responsible for counting the degrees of neighboring nodes for each node in the graph. In this step, we need to: 1) Define the data structure for algorithm runtime in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;my_app_context.h&lt;/code&gt; file; 2) Initialize these data structures in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Init&lt;/code&gt; function.&lt;/p&gt;

&lt;p&gt;The data structures are as follows:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Variable&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Type&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Comment&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;result&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;vertex_array_t&lt;size_t&gt;&lt;/size_t&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;result for each node&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Finally, the implementation of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;my_app_context.h&lt;/code&gt; as follows:&lt;/p&gt;

&lt;div class=&quot;language-c++ highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#ifndef MY_APP_CONTEXT_H_
#define MY_APP_CONTEXT_H_
&lt;/span&gt;
&lt;span class=&quot;cp&quot;&gt;#include&lt;/span&gt; &lt;span class=&quot;cpf&quot;&gt;&quot;grape/grape.h&quot;&lt;/span&gt;&lt;span class=&quot;cp&quot;&gt;
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;namespace&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gs&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

&lt;span class=&quot;cm&quot;&gt;/**
 * @brief Context for &quot;MyApp&quot; Application.
 *
 * &apos;Context&apos; class used to record the intermediate data of each iteration.
 *
 * @tparam FRAG_T
 */&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;template&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;typename&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;FRAG_T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MyAppContext&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;VertexDataContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FRAG_T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;uint64_t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oid_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;typename&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FRAG_T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;oid_t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vid_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;typename&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FRAG_T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vid_t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vertex_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;typename&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FRAG_T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vertex_t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

 &lt;span class=&quot;nl&quot;&gt;public:&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;explicit&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MyAppContext&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FRAG_T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fragment&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;VertexDataContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FRAG_T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;uint64_t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fragment&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;

  &lt;span class=&quot;cm&quot;&gt;/**
   * @param param1: algorithm specific parameter, such as
   *                &quot;source vertex&quot; for SSSP (single source shortest path)
   *                &quot;delta, max_round&quot; for Pagerank
   */&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;Init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ParallelMessageManager&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;messages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;param1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// record current superstep&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;param1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;param1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// init results&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SetValue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;c1&quot;&gt;// current superstep&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;// algorithm specific parameter&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;param1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;c1&quot;&gt;// result for each vertex, with &apos;uint64_t&apos; type&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;typename&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FRAG_T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;template&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vertex_array_t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;uint64_t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;// namespace gs&lt;/span&gt;

&lt;span class=&quot;cp&quot;&gt;#endif  // MY_APP_CONTEXT_H_
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;implement-algorithm&quot;&gt;Implement Algorithm&lt;/h4&gt;

&lt;p&gt;After defining the data structure, we can implement the corresponding algorithm logic in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;my_app.h&lt;/code&gt;, specifically the PEval and IncEval functions. The definitions of the these functions can be found in the introduction to the &lt;a href=&quot;https://graphscope.io/docs/analytical_engine/programming_model_pie&quot;&gt;PIE programming model&lt;/a&gt;. In this example, We calculate the sum of the degrees of the neighboring nodes for each node in IncEval phase and do nothing but force continue in PEval.&lt;/p&gt;

&lt;p&gt;Finally, the implementation of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;my_app.h&lt;/code&gt; as follows:&lt;/p&gt;

&lt;div class=&quot;language-c++ highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#ifndef MY_APP_H
#define MY_APP_H
&lt;/span&gt;
&lt;span class=&quot;cp&quot;&gt;#include&lt;/span&gt; &lt;span class=&quot;cpf&quot;&gt;&quot;my_app_context.h&quot;&lt;/span&gt;&lt;span class=&quot;cp&quot;&gt;
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;namespace&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gs&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

&lt;span class=&quot;cm&quot;&gt;/**
 * @brief Compute the degree for each vertex.
 *
 * @tparam FRAG_T
 */&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;template&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;typename&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;FRAG_T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MyApp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ParallelAppBase&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FRAG_T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MyAppContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FRAG_T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;k&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ParallelEngine&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;k&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Communicator&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
 &lt;span class=&quot;nl&quot;&gt;public:&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;INSTALL_PARALLEL_WORKER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MyApp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FRAG_T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MyAppContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FRAG_T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FRAG_T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;constexpr&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MessageStrategy&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;message_strategy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;grape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MessageStrategy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kSyncOnOuterVertex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;constexpr&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LoadStrategy&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_strategy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;grape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LoadStrategy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kBothOutIn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vertex_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;typename&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fragment_t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vertex_t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;cm&quot;&gt;/**
   * @brief Implement your partial evaluation here.
   *
   * @param fragment
   * @param context
   * @param messages
   */&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PEval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fragment_t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fragment&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;context_t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
             &lt;span class=&quot;n&quot;&gt;message_manager_t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;messages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;messages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;InitChannels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;thread_num&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// Implement your partial evaluation here.&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// We put all compute logic in IncEval phase, thus do nothing but force continue.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;messages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ForceContinue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;IncEval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fragment_t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fragment&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;context_t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
               &lt;span class=&quot;n&quot;&gt;message_manager_t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;messages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// superstep&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;// Process received messages sent by other fragment here.&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;messages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ParallelProcess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fragment_t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;double&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;thread_num&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fragment&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vertex_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;double&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;msg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;// Implement your logic here.&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;// Compute the degree for each vertex, set the result in context&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inner_vertices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fragment&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;InnerVertices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ForEach&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inner_vertices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inner_vertices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fragment&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vertex_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;static_cast&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;uint64_t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                  &lt;span class=&quot;n&quot;&gt;fragment&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GetOutgoingAdjList&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
                  &lt;span class=&quot;n&quot;&gt;fragment&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GetIncomingAdjList&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
                &lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;// namespace gs&lt;/span&gt;

&lt;span class=&quot;cp&quot;&gt;#endif  // MY_APP_H
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;step3-build-and-test-your-algorithm-locally&quot;&gt;Step3. Build and Test Your Algorithm Locally&lt;/h3&gt;

&lt;p&gt;Use the following command to compile and build the algorithm:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;make build &amp;amp; &lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;build
cmake .. &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; make    &lt;span class=&quot;c&quot;&gt;# compile&lt;/span&gt;
make package        &lt;span class=&quot;c&quot;&gt;# Package the algorithm as a resource (.gar file) that can be run on GraphScope&lt;/span&gt;
make &lt;span class=&quot;nb&quot;&gt;test&lt;/span&gt;           &lt;span class=&quot;c&quot;&gt;# unit test&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;step4-run-on-graphscope-cluster-with-python-interface&quot;&gt;Step4. Run on GraphScope Cluster with Python Interface&lt;/h3&gt;

&lt;p&gt;After development is completed, we can run the algorithm’s resource (gar file) on the GraphScope cluster. The steps are as follows:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;graphscope&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;graphscope&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set_option&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show_log&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# enable logging
&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;graphscope.framework.app&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_app&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;graphscope.dataset&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_p2p_network&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# create session locally
&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# you can create session on kubernetes by replacing &quot;hosts&quot; with &quot;k8s&quot;
&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;graphscope&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cluster_type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;hosts&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# load property graph and project to simple graph to run the algorithm
&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;simple_graph&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;load_p2p_network&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;_project_to_simple&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# load your algorithm&apos;s resource
&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_app&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;load_app&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;lt;path_to_your_gar_resource&amp;gt;&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# run your algorithm
&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;my_app&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;simple_graph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# output numpy result
&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;to_numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;This article provides a detailed guide on how to develop a graph analysis algorithm that can be run on the GraphScope cluster based on the C++ template library. We will also share more algorithm examples based on this template library in real-world scenarios in the future, stay tuned!&lt;/p&gt;

&lt;h3 id=&quot;useful-links&quot;&gt;Useful links&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/GraphScope/cpp-template&quot;&gt;C++ Template Library Repository&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://graphscope.io/docs/reference/analytical_engine_index.html&quot;&gt;Analytical Engine API&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Sun, 23 Jul 2023 11:00:00 +0000</pubDate>
        <link>https://graphscope.io/blog/tech/2023/07/23/Developing-and-Running-Customized-Analytical-Algorithms-for-GraphScope.html</link>
        <guid isPermaLink="true">https://graphscope.io/blog/tech/2023/07/23/Developing-and-Running-Customized-Analytical-Algorithms-for-GraphScope.html</guid>
        
        
        <category>Tech</category>
        
      </item>
    
      <item>
        <title>GraphScope Achieved Record-breaking (2.45X) Results on LDBC SNB Interactive Workload</title>
        <description>&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-07-20-title.jpg&quot; alt=&quot;release-note&quot; /&gt;
Recently, &lt;a href=&quot;https://ldbcouncil.org&quot;&gt;LDBC&lt;/a&gt; (Linked Data Benchmark Council) announced the &lt;a href=&quot;https://ldbcouncil.org/benchmarks/snb-interactive/&quot;&gt;latest results of the LDBC Social Network Benchmark Interactive workload&lt;/a&gt;. GraphScope ranked first with a throughput of over 33,000 QPS, which is over two times higher than the second-place (previous record holder).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-07-20-benchmark.jpg&quot; alt=&quot;Benchmark screenshot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;LDBC also announced this result on their &lt;a href=&quot;https://twitter.com/LDBCouncil/status/1681551160753242112&quot;&gt;Twitter offical account&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-07-20-twitter.jpg&quot; alt=&quot;Twitter screenshot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;LDBC is an international non-profit organization dedicated to the development of the graph data management industry. Its members include major graph database vendors such as Intel, AWS, Neo4j, TigerGraph, and Oracle, among others. One of LDBC’s core activities is the design and review of graph related benchmarks. They have developed a series of graph related benchmarks, including the &lt;a href=&quot;https://ldbcouncil.org/benchmarks/snb/&quot;&gt;Social Network Benchmark (SNB)&lt;/a&gt;, &lt;a href=&quot;https://ldbcouncil.org/benchmarks/graphalytics/&quot;&gt;Graphalytics Benchmark&lt;/a&gt;, and &lt;a href=&quot;https://ldbcouncil.org/benchmarks/finbench/&quot;&gt;Financial Benchmark (FinBench)&lt;/a&gt;, to systematically measure the functionality and performance of different types of graph systems.&lt;/p&gt;

&lt;p&gt;The LDBC SNB Interactive benchmark that GraphScope participated in is suitable for transactional online query scenarios. It includes basic CRUD operations as well as complex operations like shortest path and multi-hop neighbor queries. This benchmark covers common scenarios and operations of graph databases and is recognized as the industry’s only benchmark for evaluating graph databases. During the test, three types of queries are sent to the system rapidly and continuously through a driver. The performance of the system is primarily measured by queries per second (QPS). The dataset used for the test simulates a social network graph similar to Facebook, and the scale of data is measured by a scal factor (SF). In this round of evaluation, the maximum scale factor for data is SF-300 (occupying approximately 300GB of raw data on the disk).&lt;/p&gt;

&lt;p&gt;In recent years, several graph database vendors have participated in the LDBC SNB Interactive benchmark test:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.galaxybase.com/&quot;&gt;Galaxybase&lt;/a&gt;: The graph database product of Create Link. They participated in this benchmark test in May 2022 and published a test report.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.tugraph.org/&quot;&gt;TuGraph&lt;/a&gt;: An open-source graph database product by Ant Group. Their most recent participation in the benchmark test was in January 2023, and they were the previous record holder.&lt;/p&gt;

&lt;p&gt;In the LDBC SNB Interactive benchmark test, GraphScope achieved a throughput of over 30,000 QPS on a single node, which is twice the previous record holder. Additionally, GraphScope’s results were not dependent on any “pre-computation”. In contrast, according to publicly available test reports, previous participants in the evaluation had varying degrees of “pre-computation”.&lt;/p&gt;

&lt;p&gt;We will later publish an article that thoroughly analyzes the challenges GraphScope faced and the key technologies and optimizations employed in this benchmark test. Please stay tuned!&lt;/p&gt;
</description>
        <pubDate>Thu, 20 Jul 2023 06:03:00 +0000</pubDate>
        <link>https://graphscope.io/blog/tech/2023/07/20/graphscope-achieved-record-breaking-on-ldbc-snb-interactive-workload.html</link>
        <guid isPermaLink="true">https://graphscope.io/blog/tech/2023/07/20/graphscope-achieved-record-breaking-on-ldbc-snb-interactive-workload.html</guid>
        
        
        <category>Tech</category>
        
      </item>
    
      <item>
        <title>Simplifying Complex Graph Loading with Jupyter Notebook</title>
        <description>&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-07-11-title-picture.jpg&quot; alt=&quot;jupyter-notebook&quot; /&gt;
Schema construction and graph data loading are usually the complicated steps in graph computing processes. Currently, GraphScope has released a &lt;a href=&quot;https://pypi.org/project/graphscope-notebook/&quot;&gt;graphscope-notebook plugin&lt;/a&gt; which through an interactive way help users complete the graph loading in the Jupyterlab environment. This article will provide a detailed introduction to the use of this plugin, and users can try it in the &lt;a href=&quot;https://try.graphscope.app/&quot;&gt;Playground&lt;/a&gt; environment.&lt;/p&gt;

&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;
&lt;p&gt;For any graph computing product, the loading of graph data is often the first and most important step, as well as a very complicated step, mainly due to the complexity of the graph data itself. Therefore, in order to improve the loading experience, GraphScope has built-in various datasets. For example, for the &lt;a href=&quot;https://tinkerpop.apache.org/docs/current/tutorials/getting-started&quot;&gt;TinkerPop Modern Graph&lt;/a&gt;, users just need one statement to complete the loading operation:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;graphscope.dataset&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_modern_graph&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;modern_graph&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;load_modern_graph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;However, for the user’s dataset, the loading process needs to define a very long code, we use &lt;a href=&quot;https://ogb.stanford.edu/docs/nodeprop/#ogbn-mag&quot;&gt;ogbn-mag&lt;/a&gt; this property graph as an example:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-07-11-modern-graph-schema.jpg&quot; alt=&quot;modern-graph-schema&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This graph has four kinds of vertices, labeled as paper, author, institution and field_of_study. There are four kinds of edges connecting them, each kind of edges has a label and specifies the vertex labels for its two ends. For example, cites edges connect two vertices labeled paper. Another example is writes, it requires the source vertex is labeled author and the destination is a paper vertex. All the vertices and edges may have properties. e.g., paper vertices have properties like features, publish year, subject label, etc.&lt;/p&gt;

&lt;p&gt;Usually, each type of vertex(edge) corresponds to a csv file, which can be downloaded from &lt;a href=&quot;https://graphscope.oss-cn-beijing.aliyuncs.com/dataset/ogbn_mag_small.tar.gz&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;tree
├── author_affiliated_with_institution.csv
├── author.csv
├── author_writes_paper.csv
├── field_of_study.csv
├── institution.csv
├── paper_cites_paper.csv
├── paper.csv
└── paper_has_topic_field_of_study.csv
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Finally, for the user, the actual loading code is as follows:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-07-11-modern-graph-python-loading-code.jpg&quot; alt=&quot;modern-graph-python-loading-code&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We can see that even for such a flexible language as Python, the schema definition is very complicated for the above-mentioned property graph containing 4 labels, not to mention hundreds of labels of vertices and edges. Even each vertex(edge) may have thousands of properties.&lt;/p&gt;

&lt;p&gt;Therefore, in order to reduce the complexity and error rate of the loading process, GraphScope has developed a &lt;a href=&quot;https://pypi.org/project/graphscope-notebook/&quot;&gt;graphscope-notebook plugin&lt;/a&gt;, which can help GraphScope to complete the loading process of complex graph data interactively in the Jupyterlab environment. Currently, the plugin has been deployed in the &lt;a href=&quot;https://try.graphscope.app/&quot;&gt;GraphScope Playground&lt;/a&gt; environment, and everyone is welcome to try it out. Next, this article will use this above-mentioned property graph as an example to introduce in detail how to load graph interactively in the Jupyterlab environment.&lt;/p&gt;

&lt;h3 id=&quot;plugin-installation&quot;&gt;Plugin Installation&lt;/h3&gt;
&lt;p&gt;The plugin requires the following conditions:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;JupyterLab &amp;gt;= 3.0&lt;/li&gt;
  &lt;li&gt;GraphScope &amp;gt;= 0.12.0&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You can install the plugin with the following command:&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pip3 &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;graphscope-notebook
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It is worth noting that after the plugin installation is complete, you need to restart Jupyterlab. Finally, if the left sidebar displays as following, it means that the installation is successful; Or you can find it in &lt;a href=&quot;https://github.com/alibaba/GraphScope/issues&quot;&gt;GraphScope Community&lt;/a&gt; to report problems encountered.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-07-11-plugin-installaion-successful.jpg&quot; alt=&quot;plugin-installation-successful&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;using-the-plugin&quot;&gt;Using the Plugin&lt;/h3&gt;

&lt;p&gt;First, we run the following code in the Jupyterlab to create a &lt;a href=&quot;https://graphscope.io/docs/reference/session.html#session-object&quot;&gt;GraphScope Session&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;graphscope&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;graphscope&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set_option&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show_log&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;graphscope&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cluster_type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;hosts&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After the Session is created, we can monitor the resource in the &lt;strong&gt;left resource panel&lt;/strong&gt;. Click the “+” button to open the interactive page on the right side of the notebook:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-07-11-open-interactive-page.jpg&quot; alt=&quot;open-interactive-page&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;1-create-vertex&quot;&gt;1. Create Vertex&lt;/h4&gt;

&lt;p&gt;Next, we can complete the graph data construction according to the prompts on the interactive page. Take the “paper” type of vertex as an example. The page for creating points is as follows. After the information is filled in, click “Create Vertex” to complete the construction of the point.&lt;/p&gt;

&lt;p&gt;Next, we can complete the construction of the graph data according to the prompts on the interactive page. Taking the “paper” type of vertex  as an example. After filling in the information, click “Create Vertex” to complete the vertex construction.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-07-11-create-vertex.jpg&quot; alt=&quot;create-vertex&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The explanations for each field are as follows:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;field&lt;/th&gt;
      &lt;th&gt;comment&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Label&lt;/td&gt;
      &lt;td&gt;the label of the vertex&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Data Source&lt;/td&gt;
      &lt;td&gt;local file represents local data files; online file represents network files, such as OSS, etc.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Location&lt;/td&gt;
      &lt;td&gt;the path of the data source&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Header Row&lt;/td&gt;
      &lt;td&gt;If true, the column name will be read from the first row of the source file&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Delimiter&lt;/td&gt;
      &lt;td&gt;optional values are “,” “;”, “ “, “\t”&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Extra Params&lt;/td&gt;
      &lt;td&gt;additional parameters required by data loading, such as OSS key/secret and endpoint&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;ID Field&lt;/td&gt;
      &lt;td&gt;which column in the source file is selected as the ID, it can be a number like 0, 1, 2, or a string represents the property name&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Select all Properties&lt;/td&gt;
      &lt;td&gt;If true, all properties are loaded, otherwise the properties to be loaded need to be specified&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&quot;2-create-edge&quot;&gt;2. Create Edge&lt;/h4&gt;

&lt;p&gt;Similar to “Create Vertex”, take the “cites” type of edge as an example (paper -&amp;gt; cites -&amp;gt; paper). After the information is filled in, click “Create Edge” to complete the construction of the edge.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-07-11-create-edge.jpg&quot; alt=&quot;create-edge&quot; /&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;field&lt;/th&gt;
      &lt;th&gt;comment&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Edge Only&lt;/td&gt;
      &lt;td&gt;True for cases where only one edge file and no vertex file&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Src Vertex Label&lt;/td&gt;
      &lt;td&gt;the label of source vertex&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Dst Vertex Label&lt;/td&gt;
      &lt;td&gt;the label of destination vertex&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Src Vertex Field&lt;/td&gt;
      &lt;td&gt;which column used as the ID of the source vertex, it can be a number like 0, 1, 2, or a string represents the property name&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Dst Vertex Field&lt;/td&gt;
      &lt;td&gt;which column used as the ID of the destination vertex, it can be a number like 0, 1, 2, or a string represents the property name&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&quot;3-define-graph-related-information&quot;&gt;3. Define Graph-Related Information&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-07-11-define-graph-info.jpg&quot; alt=&quot;define-graph-info&quot; /&gt;&lt;/p&gt;

&lt;p&gt;After building all types of vertices/edges, we set the graph-related information:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;field&lt;/th&gt;
      &lt;th&gt;comment&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Name&lt;/td&gt;
      &lt;td&gt;the name of the graph&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;OID Type&lt;/td&gt;
      &lt;td&gt;the original vertex type of the graph, optional values are “string” and “int64”&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Directed&lt;/td&gt;
      &lt;td&gt;whether the graph is directed or not&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Generate EID&lt;/td&gt;
      &lt;td&gt;whether to generate a unique id for each edge. Set True if you need to use the GIE service&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&quot;4-generate-code-and-load-graph&quot;&gt;4. Generate Code and Load Graph&lt;/h4&gt;

&lt;p&gt;After all the information above is filled in, select one “Notebook Cell” with the mouse, and click the “Generate Code” button to generate the corresponding graph loading code. Run this cell to finish the data loading process, and monitor the graph resource in the left resource panel:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-07-11-data-loading-in-cell.jpg&quot; alt=&quot;dataloading-in-cell&quot; /&gt;&lt;/p&gt;

&lt;p&gt;So far, we have successfully used the graphscope-notebook plugin to complete the graph data loading process. Next, we can refer to the &lt;a href=&quot;https://graphscope.io/docs/&quot;&gt;documentation&lt;/a&gt; to play with GraphScope.&lt;/p&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;The graphscope-notebook jupterlab plugin currently has the functions of 1) monitoring GraphScope runtime resources; 2) loading graph through an interactive way to reduce the complexity during graph loading process. In addition, we also plan to add visualization analysis of graph data in subsequent versions. Stay tuned!&lt;/p&gt;

</description>
        <pubDate>Tue, 11 Jul 2023 11:00:00 +0000</pubDate>
        <link>https://graphscope.io/blog/tech/2023/07/11/Simplifying-Complex-Graph-Loading-with-Jupyter-Notebook.html</link>
        <guid isPermaLink="true">https://graphscope.io/blog/tech/2023/07/11/Simplifying-Complex-Graph-Loading-with-Jupyter-Notebook.html</guid>
        
        
        <category>Tech</category>
        
      </item>
    
      <item>
        <title>Release Notes: v0.23.0</title>
        <description>&lt;p&gt;&lt;img src=&quot;/blog/assets/images/release_note_t.png&quot; alt=&quot;release-note&quot; /&gt;
We are thrilled to introduce a range of enhancements to GraphScope, with the GraphScope 0.23.0 release. This release encompasses significant features and improvements in Graph Interactive Engine (GIE), GraphScope Flex, and Deployment.&lt;/p&gt;

&lt;p&gt;We highlight the following improvements included in this release:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. GraphScope Flex Technical Preview&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;GraphScope Flex represents the ongoing evolution of GraphScope. In this release, we’re excited to introduce a technical preview of GraphScope Flex. It highlights a modular design that reduces resource and cost requirements while providing a seamless, user-friendly experience for flexible deployment. It’s currently under active development, and we look forward to your feedback.&lt;/p&gt;

&lt;p&gt;Key Features:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Modular Design&lt;/strong&gt;: Assemble your stack much like LEGO blocks to customize your graph computing deployments.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Three-Layer Architecture&lt;/strong&gt;: Components are organized into an application layer, execution layer, and storage layer.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Flexible Builds and Deployments&lt;/strong&gt;: Use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;flexbuild&lt;/code&gt; script to build a custom deployment tailored for your specific use case.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You can explore GraphScope Flex in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;flex/&lt;/code&gt; directory or through the released artifacts&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;graphscope_flex_db_cppsp_hiactor_mcsr&lt;/code&gt;,&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;graphscope_flex_olap_builtin_grape-cpu&lt;/code&gt;, and&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;graphscope_flex_gnn_gnnmodels_graphlearn_tensorflow_vineyard.so&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;packages for high-QPS interactive queries, graph analytics, and graph learning task use cases, respectively. Dive in and discover what GraphScope Flex has to offer!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2. Enhancements for GIE&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Support the recording of both vertices and edges during path expansion. In the past, path expansion had the option to yield either all vertices or the end vertex of the path. However, due to the requirements of both Gremlin and our users, it’s essential to also retrieve the edges of the path, besides the vertices. To activate this feature, use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;with(&apos;RESULT_OPT&apos;, &apos;ALL_V_E&apos;)&lt;/code&gt; in the path expansion syntactic sugar. Here is an example:
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;gremlin&amp;gt; g.V().out(&quot;1..3&quot;, &quot;knows&quot;).with(&apos;RESULT_OPT&apos;, &apos;ALL_V_E&apos;)
     ==&amp;gt;[v[1], e[0][1-knows-&amp;gt;2], v[2]]
     ==&amp;gt;[v[1], e[2][1-knows-&amp;gt;4], v[4]]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;We are now happy to introduce the capability of querying Cypher in GIE, by integrating Neo4j’s bolt service in our system. Please follow the &lt;a href=&quot;https://graphscope.io/docs/latest/interactive_engine/neo4j/cypher_sdk&quot;&gt;guide&lt;/a&gt; to enable bolt service (only on local) for querying with Cypher. We also attempt to make the syntax of Cypher as close as &lt;a href=&quot;https://opencypher.org/&quot;&gt;openCypher&lt;/a&gt;, and the details of our support for Cypher can be found &lt;a href=&quot;https://graphscope.io/docs/latest/interactive_engine/neo4j/supported_cypher&quot;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;3. Other enhancements and bug fixes&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;GAE Java
    &lt;ul&gt;
      &lt;li&gt;Fix VertexSet’s problem of supporting vertex_id in java long.&lt;/li&gt;
      &lt;li&gt;Add Grape-GraphX performance report
 	- Fix the problem of installing &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;grape-jdk&lt;/code&gt; locally.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For more detailed improvements that have been made in this release, please refer to the complete &lt;a href=&quot;https://github.com/alibaba/GraphScope/releases/tag/v0.23.0&quot;&gt;changelog&lt;/a&gt;.&lt;/p&gt;
</description>
        <pubDate>Fri, 07 Jul 2023 03:33:20 +0000</pubDate>
        <link>https://graphscope.io/blog/releasenotes/2023/07/07/release-notes-0.23.0.html</link>
        <guid isPermaLink="true">https://graphscope.io/blog/releasenotes/2023/07/07/release-notes-0.23.0.html</guid>
        
        
        <category>ReleaseNotes</category>
        
      </item>
    
      <item>
        <title>Visualizing Insights from Large Graphs: A Comprehensive Guide to Using G6VP and GraphScope</title>
        <description>&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-07-05-g6vp.jpg&quot; alt=&quot;G6VP&quot; /&gt;
GraphScope now supports serving as the backend engine for &lt;a href=&quot;https://insight.antv.antgroup.com/&quot;&gt;G6VP&lt;/a&gt;, an open-sourced graph visualization and analysis platform. With G6VP and GraphScope, users can import graph data and analyze graph data easily. This article mainly introduces how to deploy G6VP and GraphScope and perform data analysis.&lt;/p&gt;

&lt;h3 id=&quot;what-is-g6vp&quot;&gt;What is G6VP&lt;/h3&gt;

&lt;p&gt;G6VP is a graph visualization and analysis platform developed by AntV Graph Visualization team of Ant Group. Users can connect their own data in G6VP, including local file uploads or various graph databases, and assemble the rich graph visualization and analysis assets provided by G6VP to perform data analysis, or design and develop their own graph visualization and analysis products, embedding them into their own systems.
&lt;img src=&quot;/blog/assets/images/2023-07-05-g6vp-01.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;deployment-of-g6vp-and-graphscope&quot;&gt;Deployment of G6VP and GraphScope&lt;/h3&gt;

&lt;p&gt;Currently, G6VP supports GraphScope as a backend service. As G6VP does not have an available online server, the integration and deployment with GraphScope need to be based on Docker images. Currently, G6VP only supports the persistent graph storage (Groot) and graph interactive engine (GIE) in GraphScope. In the future, the docking of other storage and computation engines in GraphScope will be continuously completed, providing an efficient one-stop solution.&lt;/p&gt;

&lt;h4 id=&quot;image-deployment&quot;&gt;Image Deployment&lt;/h4&gt;

&lt;p&gt;In this step, you need to deploy the GraphScope service and G6VP HTTP service through docker images. It should be noted that the machine networks where the two services are located can be connected.&lt;/p&gt;

&lt;p&gt;We first need to pull and start the image:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker pull registry.cn-hongkong.aliyuncs.com/graphscope/graphscope-store:httpserver
&lt;span class=&quot;c&quot;&gt;# Start the Image, the port should be mapped in this procedure to ensure the availability of the service&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 12312 is the Gremlin&apos;s query port &lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 9527 is the server port&lt;/span&gt;
docker run &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; 12312:12312 &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; 9527:9527 registry.cn-hongkong.aliyuncs.com/graphscope/graphscope-store:httpserver
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After the GraphScope persistent storage (Groot) container is successfully started, the default dataset will be loaded. If you want to import your own dataset, please refer to the &lt;a href=&quot;https://graphscope.io/docs/latest/storage_engine/groot&quot;&gt;Groot documentation&lt;/a&gt;. You can execute the following command to check whether the container is running normally:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Note that when the server is running the container, replace the localhost address with the server IP&lt;/span&gt;
curl http://localhost:9527/api/v1/graph
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After successful deployment, the address of the GraphScope engine is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;http://localhost:9527&lt;/code&gt;, which will be used in the “Access GraphScope Service in G6VP” step later.&lt;/p&gt;

&lt;h4 id=&quot;start-g6vp-http-service&quot;&gt;Start G6VP HTTP Service&lt;/h4&gt;

&lt;p&gt;There are two ways to start G6VP HTTP service:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Start directly using the binary installation package&lt;/strong&gt;&lt;br /&gt;
You need to download &lt;a href=&quot;https://github.com/antvis/G6VP/blob/master/release/gi-httpservice.tgz&quot;&gt;gi-httpservices.tgz file&lt;/a&gt;, unzip gi-httpservice.tgz and enter the file folder to start the service. Before doing that, make sure the NodeJS environment is available on your computer.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;gi-httpservice
&lt;span class=&quot;c&quot;&gt;# make sure port 7001 is available&lt;/span&gt;
lsof &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt;:7001
npm run start
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Install and start from source code&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;You need to clone the source code of G6VP from GitHub, enter the folder &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;G6VP/packages/gi-httpservice&lt;/code&gt;, install the dependencies, and start the service:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git clone https://github.com/antvis/G6VP.git
&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;G6VP/packages/gi-httpservice
npm &lt;span class=&quot;nb&quot;&gt;install
&lt;/span&gt;npm run dev
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now, G6VP http service is running, visit &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;http://localhost:7001/&lt;/code&gt; (7001 is the default port), you will see the tips in the console of browser:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-07-05-g6vp-02.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;access-graphscope-service-in-g6vp&quot;&gt;Access GraphScope Service in G6VP&lt;/h3&gt;

&lt;p&gt;To connect GraphScope service, you need to fill the address of services from previous steps：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Platform address: The address of G6VP HTTP service, it was &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;http://localhost:7001&lt;/code&gt; from the previous step&lt;/li&gt;
  &lt;li&gt;Engine address: The address of GS service, it was &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;http://localhost:9527&lt;/code&gt; from the previous step&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-07-05-g6vp-03.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Click “Connect” button and you will see the tip if it is success, and the subgraph select panel will be shown at below:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-07-05-g6vp-04.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Next you can select a subgraph from “Select Subgraph”. This select dropdown has listed all the graphs in the GraphScope service you started. If there is no option, please checkout if the data importing step is failed. When you click “Analyze”, the page will jump to the list of the datasets, and you will find the dataset you just created:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-07-05-g6vp-05.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Now you can click the blue computer icon on the right of the dataset record in the list to create a workbook with the dataset. You will see the page below and the dataset field is already filled and please name the workbook and then click “Create Canvas”:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-07-05-g6vp-06.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;After that, a workbook is successfully created and you will see an empty canvas with configuration panel like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-07-05-g6vp-07.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;analyze-the-data&quot;&gt;Analyze the Data&lt;/h3&gt;

&lt;p&gt;After the above steps, you have completed the connection to GraphScope and the creation of data and workbook. Then, you can perform data analysis in the newly created workbook. Now you can configure Gremlin query asset in the workbook, enter the Gremlin query statement, such as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;g.V().limit(10)&lt;/code&gt; in the figure below, to successfully query the data:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-07-05-g6vp-08.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;If you are not satisfy with the nodes and edges’ styles, configuring it on the style panel on the left:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-07-05-g6vp-09.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Select one or brush multiple nodes and right click to expand the neighbors:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-07-05-g6vp-10.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;You can configure the neighbor querying asset on the left if it does not meet the requirement:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-07-05-g6vp-11.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In addition, you can use the filter to analyze the statistical info, and there will be an intelligent recommend:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-07-05-g6vp-12.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The introduction above is only about the basic functions. Plenty of fancy graph analysis assets will be found at the assets center.&lt;/p&gt;

&lt;p&gt;Last but not least, do not forget to save your workbook after the above operations. Next time you visit G6VP, you will found your workbook at the workbook list. Don’t be worry, the datasets info, workbooks are all cached at your computer. G6VP will not record any user information!&lt;/p&gt;

&lt;p&gt;If you want to embed the workbook into your system, export it at the right top “Open”. There will be 3 ways to export:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-07-05-g6vp-13.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;More usage and docs can be referred to &lt;a href=&quot;https://www.yuque.com/antv/gi&quot;&gt;G6VP documentation&lt;/a&gt; and &lt;a href=&quot;http://github.com/antvis/g6vp&quot;&gt;G6VP GitHub repo&lt;/a&gt;.&lt;/p&gt;
</description>
        <pubDate>Wed, 05 Jul 2023 10:00:00 +0000</pubDate>
        <link>https://graphscope.io/blog/tech/2023/07/05/Visualizing-Insights-from-Large-Graphs.html</link>
        <guid isPermaLink="true">https://graphscope.io/blog/tech/2023/07/05/Visualizing-Insights-from-Large-Graphs.html</guid>
        
        
        <category>Tech</category>
        
      </item>
    
      <item>
        <title>GAIA-IR: Graph Interactive Query Engine in GraphScope</title>
        <description>&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-06-28-title-picture.jpg&quot; alt=&quot;GAIA-IR&quot; /&gt;
In this blog, we introduce &lt;a href=&quot;https://github.com/alibaba/GraphScope/tree/main/interactive_engine&quot;&gt;&lt;strong&gt;GAIA-IR&lt;/strong&gt;&lt;/a&gt;, an interactive graph query engine for GraphScope. 
GAIA-IR not only showcases exceptional efficiency in handling Gremlin queries within a distributed framework but also present a unified intermediate representation layer that offers remarkable adaptability for incorporating additional query languages.
This feature makes the engine scalable, efficient, and user-friendly, rendering it an invaluable tool for individuals engaged in graph databases.&lt;/p&gt;

&lt;h3 id=&quot;background-and-challenges-in-graph-query&quot;&gt;Background and Challenges in Graph Query&lt;/h3&gt;
&lt;p&gt;Graph querying is an pivotal tool in the analysis of massive data. &lt;a href=&quot;http://tink[label](vscode-file://vscode-app/Applications/Visual%2520Studio%2520Code.app/Contents/Resources/app/out/vs/code/electron-sandbox/workbench/workbench.html)erpop.apache.org/&quot;&gt;Gremlin&lt;/a&gt;, which is an industry-standard graph query language proposed and maintained by Apache Tinkerpop, is widely used in popular graph databases such as &lt;a href=&quot;https://www.orientdb.org/&quot;&gt;OrientDB&lt;/a&gt;, &lt;a href=&quot;https://janusgraph.org/&quot;&gt;JanusGraph&lt;/a&gt;, &lt;a href=&quot;https://azure.microsoft.com/en-us/services/cosmos-db/&quot;&gt;Microsoft Cosmos DB&lt;/a&gt;, and &lt;a href=&quot;https://aws.amazon.com/neptune/&quot;&gt;Amazon Neptune&lt;/a&gt;. The graph query engine &lt;a href=&quot;https://graphscope.io/blog/tech/2021/08/05/GAIA-Deep-Dive-Bounded-Memory-Execution-and-Early-Stop-Optimization-for-Efficient-Graph-Traversal-at-Scale&quot;&gt;GAIA&lt;/a&gt; in GraphScope is the pioneering system that embrace Gremlin for large-scale distributed environment in the industry. While the versatility exhibited by Gremlin remains its standout advantage, our exploration during GAIA’s design and implementation to support Gremlin has uncovered certain challenges.&lt;/p&gt;

&lt;h4 id=&quot;drawbacks-in-gaia-system&quot;&gt;Drawbacks in GAIA System&lt;/h4&gt;
&lt;p&gt;The GAIA system has the following drawbacks:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;D1&lt;/strong&gt;: There are a large number of Gremlin operators, and there are also many different ways of expressing the same semantics in graph queries by Gremlin operators. For example, if we want to project entries’ properties, we can get similar results using different operators in Gremlin, such as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;elementMap()&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;valueMap()&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;values()&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;select().valueMap()&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;project().valueMap()&lt;/code&gt;, etc. An example is shown below:&lt;/p&gt;
&lt;div class=&quot;language-groovy highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;gremlin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;elementMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;==&amp;gt;[&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;id:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;label:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;person&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;name:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;marko&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;age:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;29&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;==&amp;gt;[&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;id:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;label:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;person&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;name:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vadas&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;age:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;27&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;gremlin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;valueMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;name&apos;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;age&apos;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;==&amp;gt;[&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;name:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;marko&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;age:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;29&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;==&amp;gt;[&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;name:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vadas&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;age:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;27&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;gremlin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;as&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;a&apos;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;select&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;a&apos;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;by&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;valueMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;name&apos;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;age&apos;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;==&amp;gt;[&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;name:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;marko&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;age:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;29&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;==&amp;gt;[&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;name:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vadas&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;age:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;27&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;gremlin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;as&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;a&apos;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;project&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;a&apos;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;by&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;valueMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;name&apos;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;age&apos;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;==&amp;gt;[&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;a:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;name:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;marko&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;age:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;29&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]]]&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;==&amp;gt;[&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;a:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;name:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vadas&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;age:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;27&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]]]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This leads to the redundancy implementations in GAIA to support such Gremlin operators, which is not developer-friendly and has poor scalability.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;D2&lt;/strong&gt;: GAIA has poor language extensibility. GAIA is a customized implementation of parallel Gremlin queries, while there are now many other commonly used graph querying languages, such as Cypher, GSQL, and the upcoming graph query standard language GQL. If we need to further integrate more querying languages in the future, it is almost impossible to achieve this by extending GAIA.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;D3&lt;/strong&gt;: Gremlin language has poor support for complex expressions. For example, we may want to find people in the two-degree neighborhood of person &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&apos;a&apos;&lt;/code&gt; that meet certain &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&apos;age&apos;&lt;/code&gt; property conditions through the following Gremlin query statement:&lt;/p&gt;
&lt;div class=&quot;language-groovy highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;as&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;a&apos;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;as&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;b&apos;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;as&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;c&apos;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;where&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;c&apos;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;lt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;a&apos;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;or&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;gt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;a&apos;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;and&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;gt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;b&apos;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)))).&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;by&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;age&apos;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Complex nested conditional filtering, like in where(), is not intuitive and user-friendly.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;D4&lt;/strong&gt;: GAIA lacks well-defined Gremlin syntax specifications and it is difficult to define the scope of support for Gremlin operators and operator combinations in the current system, which is not user-friendly.&lt;/p&gt;

&lt;h4 id=&quot;solutions-in-gaia-ir-system&quot;&gt;Solutions in GAIA-IR System&lt;/h4&gt;
&lt;p&gt;To address the above issues, we further proposed the language-independent and more general intermediate representation layer GAIA-IR (IR in short) to describe the common semantics in graph queries. The operators we abstracted can be divided into two categories: relational operators and graph-related operators. Relational operators mainly correspond to operations on traditional relational databases, such as Projection, Selection, GroupBy, OrderBy, etc., while graph-related operators correspond to operations on graph data, such as queries on graph vertices, graph edges, etc. Through this query language-independent intermediate representation layer, we can solve the problems in GAIA as follows:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;A1&lt;/strong&gt;. GAIA-IR uses a unified intermediate representation to express operators of similar semantics in Gremlin. For example, we abstract the Project operator to unify the various property acquisition operations in Gremlin mentioned in D1.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;A2&lt;/strong&gt;. GAIA-IR is independent of the graph query language, which makes it easier to integrate more languages. We only need to translate the operators in different languages to the unified IR operators to naturally support the parallelized implementations, without the need to design for each query language.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;A3&lt;/strong&gt;. GAIA-IR also provides rich expression support to meet user needs. For example, compared with the example in D3, adding expression support in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;where()&lt;/code&gt; operator would be much more intuitive:&lt;/p&gt;
&lt;div class=&quot;language-groovy highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;as&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;a&apos;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;as&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;b&apos;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;as&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;c&apos;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;where&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;@c.age &amp;lt; @a.age || (@c.age &amp;gt; @a.age &amp;amp;&amp;amp; @a.age &amp;gt; @b.age)&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;A4&lt;/strong&gt;: GAIA-IR introduces the &lt;a href=&quot;https://www.antlr.org/&quot;&gt;Antlr&lt;/a&gt; tool to support Gremlin syntax checking and clarifies the system’s support scope for Gremlin operators and combinations, which is more user-friendly.&lt;/p&gt;

&lt;h3 id=&quot;design-of-gaia-ir&quot;&gt;Design of GAIA-IR&lt;/h3&gt;
&lt;p&gt;Next, we will introduce the overall design of GAIA-IR.&lt;/p&gt;
&lt;h4 id=&quot;concepts-in-gaia-ir&quot;&gt;Concepts in GAIA-IR&lt;/h4&gt;
&lt;p&gt;First, we introduce some basic concepts in GAIA-IR. GAIA-IR abstracts the basic computations on graph data, providing a unified, concise, and language-independent intermediate representation layer.&lt;/p&gt;
&lt;h5 id=&quot;ir-operators&quot;&gt;IR Operators&lt;/h5&gt;
&lt;p&gt;Currently, we abstract operators (Graph-Relational Algebra) into two categories: relational operators and graph-related operators:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Relational operators include: Projection, Selection, Join, GroupBy, OrderBy, DeDup, Limit, etc., which are consistent with operations on traditional relational databases.&lt;/li&gt;
  &lt;li&gt;Graph-related operators include: GetV, E(dge)-Join, P(ath)-Join, for searching for vertex properties, neighbors (edges), and paths on the graph respectively.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Through these operator abstractions, we can support most graph query scenarios. At the same time, these operator abstractions are not limited by the querying language, making it easy to extend to other query languages.&lt;/p&gt;
&lt;h5 id=&quot;ir-data-structure&quot;&gt;IR Data Structure&lt;/h5&gt;
&lt;p&gt;In GAIA-IR, we defined the data structure GRecord to represent the input and output of each IR Operator. GRecord is a multi-column structure, and each column has its own alias and value:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Alias, which is similar to the alias by &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;As&lt;/code&gt; in SQL. Specifically, to adapt to Gremlin, we provide an additional unique alias – &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;HEAD&quot;&lt;/code&gt; as an anonymous alias, referring to the output of the previous operator, which is also the input of the current operator.&lt;/li&gt;
  &lt;li&gt;Value, which is of data types includes: 1) Simple data type CommonObject (including int/string/intArray/stringArray, etc.) and 2) Graph data type GraphObject (including Vertex, Edge, and Path).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Next, we give an example to elaborate how to execute a gremlin query in GAIA-IR.&lt;/p&gt;
&lt;h5 id=&quot;gremlin-query-example&quot;&gt;Gremlin Query Example&lt;/h5&gt;
&lt;p&gt;We support Gremlin by translating Gremlin queries into a series of IR Operators on GRecord. An example is shown below:&lt;/p&gt;
&lt;div class=&quot;language-groovy highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;as&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;a&apos;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;select&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;a&apos;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;by&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;valueMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;name&apos;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;age&apos;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;First, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;g.V().as(&apos;a&apos;)&lt;/code&gt; will produce the following intermediate results, with the alias &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&apos;a&apos;&lt;/code&gt; and data type Vertex:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;GR1&lt;/th&gt;
      &lt;th&gt;Vertex { name:[marko], age:[29] }, Alias: ‘a’&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;GR2&lt;/td&gt;
      &lt;td&gt;Vertex { name:[vadas], age:[27] }, Alias: ‘a’&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Then &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;select(&apos;a&apos;).by(valueMap(&apos;name&apos;,&apos;age&apos;))&lt;/code&gt; would be translated into &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Project(&apos;{a.name,a.age}&apos;)&lt;/code&gt;. With &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GR1&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GR2&lt;/code&gt; as the input of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Project&lt;/code&gt;, we can get the output &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GR1&apos;&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GR2&apos;&lt;/code&gt;, which are the properties we need:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;GR1’&lt;/th&gt;
      &lt;th&gt;CommonObject { a.name:[marko], a.age:[29] }&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;GR2’&lt;/td&gt;
      &lt;td&gt;CommonObject { a.name:[vadas], a.age:[27] }&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Similarly, for the Gremlin query &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;g.V().valueMap(&apos;name&apos;,&apos;age&apos;)&lt;/code&gt;, we only need to change the aliases of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GR1&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GR2&lt;/code&gt; to the anonymous alias &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;HEAD&quot;&lt;/code&gt; and translate &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;valueMap(&apos;name&apos;,&apos;age&apos;)&lt;/code&gt; into &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Project(&quot;{HEAD.name,HEAD.age}&quot;)&lt;/code&gt;, which gives the same result. 
Thus, we can translate Gremlin queries with similar semantics but different operators into a unified intermediate representation. Moreover, for other languages, such as retrieving properties in SQL, we can also translate into the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Project&lt;/code&gt; operator in GAIA-IR. This shows that GAIA-IR abstracts a more concise, general, and language-independent intermediate representation layer.&lt;/p&gt;

&lt;h3 id=&quot;gaia-ir-system-architecture&quot;&gt;GAIA-IR System Architecture&lt;/h3&gt;
&lt;p&gt;Next, we present the parallel computing architecture of GAIA-IR for Gremlin, as shown in the following figure:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-06-28-gaia-arch.jpg&quot; alt=&quot;GAIA-IR-SYSTEM-ARCH&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Overall, we are compatible with both the official Gremlin Console and Gremlin SDK. After the user submits a Gremlin query:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;The frontend IR Compiler is responsible for syntax checking of the query. For a valid query, the IR Compiler compiles the query syntax tree into a logical plan consisting of IR Operators through the IR Library API, and further calls the IR Library API to generate a physical plan, which is then sent to the distributed backend engine servers.&lt;/li&gt;
  &lt;li&gt;The backend engine servers pre-launch the distributed graph partitions during the service start-up phase. Upon receiving the physical plan sent by the IR Compiler, the IR Runtime is responsible for parsing the physical plan and constructing an engine-executable execution plan. Specifically, for each IR Operator, the IR Runtime is responsible for generating the corresponding engine-understandable UDF to implement the specific query semantics of the IR Operator. After the calculation is completed, the IR Runtime returns the results back to the IR Compiler, which will be further parsed and returned to the client.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;how-to-use-gaia-ir&quot;&gt;How to Use GAIA-IR&lt;/h3&gt;
&lt;p&gt;After introducing the overall design of GAIA-IR, we will now explain how to use the GAIA-IR for graph querying.&lt;/p&gt;
&lt;h4 id=&quot;deployment&quot;&gt;Deployment&lt;/h4&gt;
&lt;p&gt;In our previous &lt;a href=&quot;https://graphscope.io/blog/tech/2023/06/11/How-to-Deploy-GraphScope-by-Helm-on-Kubernetes&quot;&gt;blogs&lt;/a&gt;, we introduced how to deploy GraphScope. As an important implementation of GIE in GraphScope, the overall launch method of GAIA-IR is consistent with GraphScope. Taking Helm deployment as an example, the installation command is as follows:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;helm repo add graphscope https://graphscope.oss-cn-beijing.aliyuncs.com/charts/
helm install [RELEASE_NAME] graphscope/graphscope-store
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;More detailed deployment options can be found in the &lt;a href=&quot;https://graphscope.io/docs/&quot;&gt;official document&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&quot;gremlin-query&quot;&gt;Gremlin Query&lt;/h4&gt;
&lt;p&gt;After successfully launching the service, we can query through the Gremlin Server host and port. Taking Gremlin Console as an example, after the service is successfully launched and the data is imported (the specific data import steps can be found in the &lt;a href=&quot;https://graphscope.io/docs/storage_engine/groot&quot;&gt;official document&lt;/a&gt;), we can query by configuring the Gremlin Console. An example is as follows:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;First, we modify the host and port in the conf/remote.yaml configuration file of the Gremlin Console.&lt;/li&gt;
  &lt;li&gt;Open the Gremlin Console, input the configuration of remote.yaml, and then you can start querying.&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;language-groovy highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;gremlin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;remote&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;connect&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tinkerpop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;remote&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;yaml&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;==&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Configured&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;localhost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;127.0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8182&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;gremlin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;remote&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;console&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;==&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;All&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scripts&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;will&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;now&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;be&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sent&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Gremlin&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Server&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;localhost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;127.0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8182&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;:remote console&apos;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;local&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;gremlin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;valueMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;name&apos;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;age&apos;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;==&amp;gt;[&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;name:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;marko&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;age:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;29&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;==&amp;gt;[&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;name:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vadas&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;age:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;27&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;This article describes the design intention and overall architecture of GAIA-IR, as well as how to use the GAIA-IR engine for graph querying. You can find the current release version on &lt;a href=&quot;https://github.com/alibaba/GraphScope/tree/main/interactive_engine&quot;&gt;GitHub&lt;/a&gt;. As the interactive graph query engine of GraphScope, GAIA-IR provides an efficient implementation of parallel Gremlin queries. At the same time, based on the unified intermediate representation of IR, we are supporting more graph query languages, e.g., Cypher. Besides, we also introduce optimization techniques in supporting important scenarios such as pattern matching in graph queries. In future articles, we will introduce more technical details. We will continue to optimize the GAIA-IR system, and we warmly welcome feedback and contributions from the community.&lt;/p&gt;
</description>
        <pubDate>Wed, 28 Jun 2023 11:00:00 +0000</pubDate>
        <link>https://graphscope.io/blog/tech/2023/06/28/GAIA-IR-Graph-Interactive-Query-Engine-in-GraphScope.html</link>
        <guid isPermaLink="true">https://graphscope.io/blog/tech/2023/06/28/GAIA-IR-Graph-Interactive-Query-Engine-in-GraphScope.html</guid>
        
        
        <category>Tech</category>
        
      </item>
    
      <item>
        <title>Breaking the Language Barrier in Large Scale Graph Computing</title>
        <description>&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-06-19-title-picture.jpg&quot; alt=&quot;Grape-JDK&quot; /&gt;
In this blog, we present &lt;a href=&quot;https://github.com/alibaba/GraphScope/tree/main/analytical_engine/java&quot;&gt;&lt;strong&gt;GRAPE-JDK&lt;/strong&gt;&lt;/a&gt;,
an efficient cross-language graph analysis development kit of GraphScope. &lt;strong&gt;GRAPE-JDK&lt;/strong&gt; enables users to write customized graph algorithms in Java and run them efficiently on GraphScope by addressing various challenges in cross-language graph computation.
In this way, Java algorithms developed based on &lt;strong&gt;GRAPE-JDK&lt;/strong&gt; can achieve performance similar to C++ algorithms.&lt;/p&gt;

&lt;h3 id=&quot;the-demand-and-challenges-of-cross-language-graph-analysis&quot;&gt;The Demand and Challenges of Cross-language Graph Analysis&lt;/h3&gt;

&lt;p&gt;Graph analytics is a critical aspect of processing tasks involving graphs. 
One notable example of a graph analysis algorithm is the widely used single-source shortest path (SSSP) algorithm. 
The graph analytical engine in GraphScope is derived from &lt;a href=&quot;https://dl.acm.org/doi/abs/10.1145/3282488&quot;&gt;GRAPE&lt;/a&gt;, as documented in the research paper available at GRAPE. This engine incorporates various pre-built graph analysis algorithms, including SSSP and PageRank, among others, which users can readily invoke for their analytical needs.&lt;/p&gt;

&lt;p&gt;In real-world production scenarios, customization of general algorithms is often required to accommodate specific business logic. 
As a result, developers frequently need to develop their own algorithms tailored to their needs. 
Java is widely adopted as the predominant language within big data ecosystems, making it an ideal choice for implementing these algorithms.
However, when utilizing GraphScope’s graph analytical engine, relying solely on the C++ interface can present significant obstacles for developers. 
Directly implementing algorithms in Java would be more seamless and efficient for them. 
Therefore, there exists a demand for enabling users to leverage Java for implementing customized graph algorithms and seamlessly executing them on the GraphScope graph analytical engine. 
This approach would address practical requirements while facilitating a smoother integration of user-developed algorithms into the system.&lt;/p&gt;

&lt;p&gt;To meet the user’s requirement for conducting cross-language graph analysis, we have developed a Java SDK that builds upon the graph analysis engine GRAPE, which is primarily implemented in C++.
In such scenarios, a natural solution is to employ the &lt;a href=&quot;https://docs.oracle.com/javase/8/docs/technotes/guides/jni/&quot;&gt;Java Native Interface (JNI)&lt;/a&gt;, which serves as the standard framework for Foreign Function Interface (FFI) on the Java Virtual Machine (JVM). 
By utilizing JNI, we can overcome the limitations of Java by accessing system hardware resources at a lower level, similar to C++.
To leverage JNI effectively, it requires writing wrapper code in C++ and compiling it into a dynamic library, granting us the ability to seamlessly utilize its functionalities. 
This approach facilitates the seamless integration of Java and C++ components, enabling developers to harness the full potential of both languages within the graph analysis process.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-06-19-jni.jpg&quot; alt=&quot;JNI：Briding Java and C++&quot; height=&quot;36px&quot; width=&quot;36px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Therefore, we can find a straightforward and intuitive solution: employing the raw JNI to create wrapper code that bridges Java and C++. 
This approach allows us to encapsulate the C++ interface of the graph computing engine as a Java interface, making it accessible to users.
However, this native solution has inherent limitations that render it inadequate for meeting the demands of large-scale graph computing. 
It confronts several challenges in following three aspects:&lt;/p&gt;

&lt;h4 id=&quot;challenge-1-difficulty-in-jni-programming&quot;&gt;Challenge 1: Difficulty in JNI Programming&lt;/h4&gt;
&lt;p&gt;Directly using JNI for cross-language programming poses challenges in development, debugging, and maintenance.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Development&lt;/strong&gt;: In order to enable Java to interact/communicate with C++, programmers need to write 
a large amount of error-prone and boilerplate code, as shown in the code block. 
And JNI code often involves pointer conversion, which increases the risk of errors.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-c++ highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;JNIEXPORT&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;JNICALL&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;Java_com_alibaba_graphscope_stdcxx_StdVector_1cxx_10x8cbe72bf_nativeClear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;JNIEnv&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jclass&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jlong&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;reinterpret_cast&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;VertexArrayDefault&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;double&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;*&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;clear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Debugging&lt;/strong&gt;: The written JNI code needs to be compiled into a dynamic library by a C++/C compiler
for the JVM to load and invoke the functions defined in it. The compilation and debugging of JNI code is also a painful process.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Maintenance&lt;/strong&gt;: The cost of maintaining JNI code is also high. As JNI code is highly dependent on C++ native code, 
when the C++ interface and implementation of the graph computing engine change, programmers must manually modify the JNI implementation to adapt.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;challenge-2-huge-overhead-of-cross-language-access&quot;&gt;Challenge 2: Huge Overhead of Cross-language Access&lt;/h4&gt;
&lt;p&gt;Although JNI provides sufficient APIs for communication between Java and C++, the overhead it brings 
due to its cross-language nature is huge. According to our research, the overhead that JNI may introduce in actual 
large-scale graph computing scenarios mainly comes from the following call overheads.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;The overhead of JNI function calls&lt;/strong&gt;. There is already a considerable overhead in calling the JNI function itself,
 including accessing Java Objects in the JNI code implementation, which is a very &lt;a href=&quot;http://www.mastercorp.free.fr/Ing1/Cours/Java/java_lesson1/doc/Tutorial/performance/JPNativeCode_fm.htm&quot;&gt;time-consuming operation&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Java native methods cannot be inlined by the JVM&lt;/strong&gt;. In Java, optimization of code is mainly done by the JVM. For frequently called Java methods,
the JVM can avoid the overhead of function calls by inlining them. However, for native methods implemented by JNI, the JVM cannot optimize them. 
In data-intensive scenarios such as graph computing, accessing data stored in C++ memory through JNI from Java is a frequent operation. Therefore, native methods that cannot be inlined will be a significant overhead during program execution.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Java native methods cannot be optimized by JIT&lt;/strong&gt;. Native methods have already been compiled into binary code by C++/C compiler, so it is not possible for the JVM to optimize them through JIT.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;challenge-3-support-for-user-defined-data-structures&quot;&gt;Challenge 3: Support for User-defined Data Structures&lt;/h4&gt;

&lt;p&gt;In some complex real-world production scenarios,Users often have a great demand for customizing vertex data type,
edge data type, and even message types. Relying solely on JNI cannot achieve this because every time a user defines a new data type,
we need to implement it in C++ and then write JNI methods to map it to Java.&lt;/p&gt;

&lt;h3 id=&quot;design-and-implementation&quot;&gt;Design and Implementation&lt;/h3&gt;

&lt;p&gt;To overcome these challenges, the GraphScope team worked closely with the JVM team at Alibaba Cloud Programming Language and Compiler 
to design and implement a high-performance and user-friendly cross-language graph computing solution.
At the same time, the development of &lt;strong&gt;GRAPE-JDK&lt;/strong&gt; also led to a modern and advanced FFI (Foreign Function Interface) framework: 
&lt;strong&gt;FastFFI&lt;/strong&gt; (open-sourced on GitHub: &lt;a href=&quot;https://github.com/alibaba/fastFFI&quot;&gt;alibaba/fastFFI&lt;/a&gt;. 
The position of GRAPE-SDK in the GraphScope system is shown below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-06-19-grape-jdk-pos.jpg&quot; alt=&quot;GRAPE-JDK in GraphScope&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;fastffi&quot;&gt;FastFFI&lt;/h4&gt;

&lt;p&gt;The functionality of &lt;strong&gt;GRAPE-JDK&lt;/strong&gt; depends on &lt;strong&gt;FastFFI&lt;/strong&gt;. &lt;strong&gt;FastFFI&lt;/strong&gt; is a modern, advanced, and efficient Java FFI framework
whose features are derived from our exploration of cross-language programming between Java and C++ in GRAPE-JDK. 
&lt;strong&gt;FastFFI&lt;/strong&gt; successfully overcomes the three challenges mentioned above.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Challenge&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Solution&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;The difficulty of JNI programming&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;FastFFI’s code generation framework&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Huge overhead of cross-language access&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;FastFFI’s LLVM4JNI: Converting LLVM bitcode to Java Bytecode.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Support for user-defined data structures&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;FastFFI’s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;@FFIMirror&lt;/code&gt; technique&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;FastFFI&lt;/strong&gt; can be divided into two parts, FFI-SDK and LLVM4JNI-SDK. FFI-SDK provides comprehensive JNI development support, reducing the complexity of programming. LLVM4JNI-SDK provides JNI code optimization support to improve runtime performance. For more information about FastFFI, please refer to &lt;a href=&quot;https://github.com/alibaba/fastFFI&quot;&gt;FastFFI&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&quot;grape-jdk&quot;&gt;GRAPE-JDK&lt;/h4&gt;

&lt;p&gt;Based on the JNI support provided by FastFFI, we developed the Java PIE SDK for GRAPE: &lt;strong&gt;GRAPE-JDK&lt;/strong&gt;. 
Taking Vertex as an example, we will introduce how &lt;strong&gt;FastFFI&lt;/strong&gt; reduces the complexity of JNI development and improves performance.&lt;/p&gt;

&lt;h3 id=&quot;the-mapping-between-c-and-java-classes&quot;&gt;The Mapping between C++ and Java Classes&lt;/h3&gt;
&lt;p&gt;As the most basic abstraction in the graph, Vertex often has a unique ID and attribute (vertex data). For example, in GRAPE, the interface abstraction of a vertex is as follows&lt;/p&gt;

&lt;div class=&quot;language-c++ highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;template&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;typename&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Vertex&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
 &lt;span class=&quot;nl&quot;&gt;public:&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Vertex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Vertex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;//Other code fragments are omitted here, see full code at&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;// https://github.com/alibaba/libgrape-lite/blob/master/grape/utils/vertex_array.h#L36&lt;/span&gt;
  
  &lt;span class=&quot;c1&quot;&gt;// Get the id bound with this vertex.&lt;/span&gt;
  &lt;span class=&quot;kr&quot;&gt;inline&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GetValue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;c1&quot;&gt;// Set the id bound with this vertex.&lt;/span&gt;
  &lt;span class=&quot;kr&quot;&gt;inline&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;SetValue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

 &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In order to map the C++ Vertex class to Java, all we need to do is to write the following code in Java.&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nd&quot;&gt;@FFIGen&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;grape-jni&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nd&quot;&gt;@CXXHead&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;grape/utils/vertex_array.h&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nd&quot;&gt;@FFITypeAlias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;grape::Vertex&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nd&quot;&gt;@CXXTemplate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cxx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;uint64_t&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;},&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Long&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;})&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;interface&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Vertex&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;VID_T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;FFIPointer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;VID_T&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;GetValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;

    &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;SetValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;VID_T&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;@FFIGen&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;@CXXHead&lt;/code&gt; are both Java annotations. By providing additional information through annotations, we can generate code
during the compilation of Java code. For example, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;@CXXHead(&quot;grape/utils/vertex_array.h&quot;)&lt;/code&gt; specifies that the generated 
C++ code needs to include the header file &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;grape/utils/vertex_array.h&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;After compilation, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Vertex.java&lt;/code&gt; will generate two sets of code, one of which is the implementation 
class of the Java Vertex interface, which defines the corresponding native methods.&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Vertex_cxx_0xaccf3424&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;FFIPointerImpl&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;implements&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Vertex&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;

  &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;Vertex_cxx_0xaccf3424&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;address&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;address&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Long&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;GetValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nativeGetValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;address&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;//The actual working native method.&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;native&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;nativeGetValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;

  &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;SetValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arg0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;nativeSetValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;address&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arg0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;// The actual working native method.&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;native&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;nativeSetValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arg00&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Also, there will be a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.cc&lt;/code&gt; file containing the implementation of the native methods after compilation&lt;/p&gt;

&lt;div class=&quot;language-c++ highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;// headers are omitted.&lt;/span&gt;
&lt;span class=&quot;cp&quot;&gt;#ifdef __cplusplus
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;extern&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;C&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;cp&quot;&gt;#endif
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;JNIEXPORT&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;jlong&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;JNICALL&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Java_com_alibaba_graphscope_ds_Vertex_1cxx_10xaccf3424_nativeGetValue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;JNIEnv&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jclass&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jlong&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jlong&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;reinterpret_cast&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Vertex&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;uint64_t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;*&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GetValue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;JNIEXPORT&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;JNICALL&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;Java_com_alibaba_graphscope_ds_Vertex_1cxx_10xaccf3424_nativeSetValue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;JNIEnv&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jclass&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jlong&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jlong&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arg0&lt;/span&gt; &lt;span class=&quot;cm&quot;&gt;/* arg00 */&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;reinterpret_cast&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Vertex&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;uint64_t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;*&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SetValue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arg0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;cp&quot;&gt;#ifdef __cplusplus
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;cp&quot;&gt;#endif
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Similarly, we can map any C++ class to a Java class.&lt;/p&gt;

&lt;h4 id=&quot;ffimirroruser-defined-data-structures&quot;&gt;FFIMirror：User-defined Data Structures&lt;/h4&gt;

&lt;p&gt;In GRAPE-JDK, we support users to create a customized data structure that has no corresponding C++ implementation, and use it as the data type for vertex ID, vertex or edge. You only need to use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;@FFIMirror&lt;/code&gt; annotation to decorate your own defined interface. For example, we can define a simple data structure containing only &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;long&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;double&lt;/code&gt; fields. During compilation, the corresponding C++ code, JNI code, and Java implementation class code will be automatically generated.&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nd&quot;&gt;@FFIMirror&lt;/span&gt;
&lt;span class=&quot;nd&quot;&gt;@FFINameSpace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sample&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nd&quot;&gt;@FFITypeAlias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;MyData&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;interface&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MyData&lt;/span&gt;  &lt;span class=&quot;kd&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;CXXPointer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;//Get the long field.&lt;/span&gt;
    &lt;span class=&quot;nd&quot;&gt;@FFIGetter&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;longField&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
     &lt;span class=&quot;c1&quot;&gt;//Set the long field.&lt;/span&gt;
    &lt;span class=&quot;nd&quot;&gt;@FFISetter&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;longField&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    
    &lt;span class=&quot;nd&quot;&gt;@FFIGetter&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;double&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;doubleField&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;nd&quot;&gt;@FFISetter&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;doubleField&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;double&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;//Create MyData with this factory&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;MyData&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Factory&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;factory&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;FFITypeFactory&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getFactory&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;MyData&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;nd&quot;&gt;@FFIFactory&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;interface&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Factory&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;MyData&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;create&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Next, similar to regular JNI projects, after compiling the obtained &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.cc&lt;/code&gt; files and linking them into a dynamic library,
we can load them into Java through &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;System.loadLibrary()&lt;/code&gt; and access C++ objects and methods in Java&lt;/p&gt;

&lt;p&gt;As we can see, the implementation of &lt;strong&gt;GRAPE-JDK&lt;/strong&gt; based on &lt;strong&gt;FastFFI&lt;/strong&gt; perfectly solves the difficulties in development,
debugging, and maintenance in cross-language programming with JNI, and meets the needs of users for customized data types&lt;/p&gt;

&lt;h3 id=&quot;optimizing-jni&quot;&gt;Optimizing JNI&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/alibaba/fastFFI/tree/main/llvm4jni&quot;&gt;LLVM4JNI-SDK&lt;/a&gt; is a “BitCode to ByteCode” conversion tool implemented entirely in Java. The working principle of LLVM4JNI 
is to analyze LLVM-IR (JNI code is embedded in the dynamic library binary by using option &lt;a href=&quot;https://reviews.llvm.org/D68213&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-mllvm=-lto-embed-bitcode&lt;/code&gt;&lt;/a&gt;
when compiling with LLVM11), select the code that can be converted to Java bytecode (not all LLVM IR can be converted to bytecode), 
generate bytecode, and finally replace the corresponding Java native methods.&lt;/p&gt;

&lt;p&gt;For example, for the Vertex defined earlier, when running LLVM4JNI for optimization, we will replace the native methods in the Vertex implementation class:&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Vertex_cxx_0xaccf3424&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;FFIPointerImpl&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;implements&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Vertex&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;//Notice that this a no longer a native method now!&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;nativeGetValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;){&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;JavaRuntime&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getLong&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;nativeSetValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arg00&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;){&lt;/span&gt;
       &lt;span class=&quot;nc&quot;&gt;JavaRuntime&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;putLong&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arg00&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As we can see in lines 3 and 7, the original native methods are replaced with normal Java methods,
and the implementation in the methods uses JavaRuntime, which is a wrapper for Java
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNSAFE&lt;/code&gt; in LLVM4JNI-runtime and essentially still uses UNSAFE to access off-heap memory.
By replacing native methods with Java methods, we avoid significant overhead in JNI calls&lt;/p&gt;

&lt;h3 id=&quot;user-interface&quot;&gt;User Interface&lt;/h3&gt;

&lt;p&gt;By exposing only a simple programming model interface, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ParallelAppBase&lt;/code&gt;, we can hide the complex implementation of GRAPE-JDK.
Users do not need to know anything about the underlying implementation. They only need to inherit the interface and implement 
the two methods, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PEval&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;IncEval&lt;/code&gt;, to run the algorithm on the GraphScope graph analysis engine. 
For more tutorials, please refer to &lt;a href=&quot;https://graphscope.io/docs/analytics_engine.html#run-algorithm-in-java&quot;&gt;GAE-java-tutorial&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Traverse&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;implements&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ParallelAppBase&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Double&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TraverseContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;,&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;ParallelEngine&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nd&quot;&gt;@Override&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;PEval&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;IFragment&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Double&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fragment&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;ParallelContextBase&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Double&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;ParallelMessageManager&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;messageManager&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
           
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;nd&quot;&gt;@Override&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;IncEval&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;IFragment&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Double&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fragment&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;ParallelContextBase&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Double&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;ParallelMessageManager&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;messageManager&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;

    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TraverseContext&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;extends&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;VertexDataContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;IFragment&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Double&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;implements&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ParallelContextBase&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Double&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nd&quot;&gt;@Override&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;Init&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;IFragment&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Double&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;frag&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;ParallelMessageManager&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;messageManager&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;JSONObject&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jsonObject&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;

    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;nd&quot;&gt;@Override&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;Output&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;IFragment&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Double&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;frag&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;

    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;performance&quot;&gt;Performance&lt;/h3&gt;

&lt;p&gt;To verify the running performance of &lt;strong&gt;GRAPE-JDK&lt;/strong&gt; in large-scale graph computing scenarios, 
we conducted tests on datasets with hundreds of millions of vertices and billions of edges provided by &lt;a href=&quot;https://graphalytics.org/&quot;&gt;LDBC Graphalytics&lt;/a&gt;
for various common algorithms.
The test configuration was 4 clusters with 400GB of memory and 96 cores, and 4 GraphScope workers. 
For specific performance test report results, please refer to &lt;a href=&quot;https://github.com/alibaba/GraphScope/blob/main/analytical_engine/java/performance.md&quot;&gt;GRAPE-JDK performance report&lt;/a&gt;.
Here we take the SSSP and PageRank algorithms as examples to show the experimental results.&lt;/p&gt;

&lt;h4 id=&quot;java-app-vs-c-app&quot;&gt;Java App vs C++ App&lt;/h4&gt;

&lt;p&gt;First, we compare the performance gap between the Java-SSSP algorithm based on &lt;strong&gt;GRAPE-JDK&lt;/strong&gt; and the CPP-SSSP algorithm based on libgrape-lite on the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;com-fiendster&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Datagen-9_0-fb&lt;/code&gt; datasets. We can see that the overall performance gap between the Java app and the C++ app is about 2 times.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/2023-06-19-perf-datagen.jpg&quot; alt=&quot;SSSP on Dategen-9_0-fb&quot; /&gt;
&lt;img src=&quot;/blog/assets/images/2023-06-19-perf-com.jpg&quot; alt=&quot;SSSP on ccom-friendster&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;performance-improvement-brought-by-llvm4jni&quot;&gt;Performance Improvement Brought by LLVM4JNI&lt;/h4&gt;

&lt;p&gt;LLVM4JNI has brought significant performance improvements to &lt;strong&gt;GRAPE-JDK&lt;/strong&gt;. As shown in the table below, the Java-PageRank algorithm 
implemented using &lt;strong&gt;GRAPE-JDK&lt;/strong&gt; is now approaching the performance of CPP-PageRank. In cases with high concurrency, 
the time is very close to C++ (such as the column with a concurrency of 32 in the second table).&lt;/p&gt;

&lt;p&gt;Performance result is shown in the following two tables.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt; &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;threads&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;1&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;2&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;4&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;8&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;16&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;32&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;64&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Com-friendster&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;C++ time&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;567&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;325&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;149&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;78&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;39&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;37&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;43&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Com-friendster&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Java time&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3166&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1651&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;621&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;373&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;197&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;107&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;147&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Com-friendster&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Java(+LLVM4JNI) time&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;743&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;377&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;202&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;99&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;53&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;38&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;48&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt; &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;threads&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;1&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;2&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;4&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;8&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;16&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;32&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;64&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;datagen-9_0-fb&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;C++ time&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;253&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;113&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;65&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;33&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;22&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;17&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;17&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;datagen-9_0-fb&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Java time&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1439&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;770&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;358&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;162&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;85&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;64&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;74&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;datagen-9_0-fb&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Java(+LLVM4JNI) time&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;393&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;172&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;85&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;41&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;26&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;23&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;22&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;In this blog, we briefly introduce GRAPE-JDK, a cross-language graph analysis toolkit foe GraphScope.
With the help of the modern FFI framework &lt;strong&gt;FastFFI&lt;/strong&gt;, &lt;strong&gt;GRAPE-JDK&lt;/strong&gt; not only provides a friendly user interface
for Java users but also has efficient graph query performance.
We welcome everyone to try &lt;a href=&quot;https://graphscope.io/docs/latest/analytical_engine/tutorial_dev_algo_java&quot;&gt;&lt;strong&gt;GRAPE-JDK tutorial&lt;/strong&gt;&lt;/a&gt; and provide valuable feedback on usage suggestions.&lt;/p&gt;
</description>
        <pubDate>Mon, 19 Jun 2023 11:00:00 +0000</pubDate>
        <link>https://graphscope.io/blog/tech/2023/06/19/Breaking-the-Language-Barrier-in-Large-Scale-Graph-Computing.html</link>
        <guid isPermaLink="true">https://graphscope.io/blog/tech/2023/06/19/Breaking-the-Language-Barrier-in-Large-Scale-Graph-Computing.html</guid>
        
        
        <category>Tech</category>
        
      </item>
    
  </channel>
</rss>
