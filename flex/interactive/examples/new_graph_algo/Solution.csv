id|name|description
7dd64307-dbd4-533f-a2d1-b94e2cd2d36b|On-Demand Shuffling Technique|The on-demand shuffling technique is a method for efficient graph dynamics processing that stores the edges of the data graph in a distributed database and queries the database as needed during enumeration, thereby avoiding the need to shuffle the entire data graph before processing. This technique is different from existing approaches in that it only queries the necessary parts of the data graph, reducing the amount of data that needs to be shuffled and processed. This is achieved through the use of a distributed key-value database that allows for efficient querying of the data graph. The paper does not provide specific results for this solution, but it is mentioned as a key component of the BENU framework.
9c3094af-612a-5054-95bf-4eeb16fa4b15|Triangle Cache Technique|The triangle cache technique is a method for reducing the redundancy in the enumeration process by caching the results of frequent subgraph queries, such as triangles. This technique is different from existing approaches in that it uses a cache to store the results of frequent subgraph queries, reducing the need to recompute these results during the enumeration process. The paper reports that the triangle cache technique can significantly reduce the communication cost and execution time of the BENU framework.
32545439-d5a9-533d-9b41-fa0fc5274da1|Task Splitting Technique|The task splitting technique is a method for balancing the workloads of local search tasks by splitting heavy tasks into smaller subtasks. This technique is different from existing approaches in that it uses a threshold-based approach to split tasks into smaller subtasks, reducing the skewness of the workloads and improving the overall performance of the BENU framework. The paper reports that the task splitting technique can improve the execution time of the BENU framework by up to 10 times.
a015b20e-d63c-56c2-a6f0-fad0c8eb9abf|Local Database Cache Technique|The local database cache technique is a method for reducing the communication cost of the BENU framework by caching the adjacency sets of the data graph on each machine. This technique is different from existing approaches in that it uses a cache to store the adjacency sets of the data graph, reducing the need to query the distributed database during the enumeration process. The paper reports that the local database cache technique can significantly reduce the communication cost and execution time of the BENU framework.
d9a3aa25-e33b-5dad-ba54-29d43f6924e9|Local Database Cache|The authors propose a local database cache to store the adjacency sets fetched from the distributed database. This cache captures the intra-task locality by storing frequently accessed adjacency sets, reducing the need for repeated queries and minimizing communication costs.
69546870-eaf0-54dd-827c-3427105a8a83|Task Splitting|The authors propose a task splitting technique to handle the skewed workloads of local search tasks brought by the power-law degree distribution in real-world data graphs. This technique splits tasks into smaller subtasks, reducing the workload imbalance and minimizing communication costs.
667214b7-11c5-514f-837c-139e4a5b7b4b|Triangle Cache|The authors propose a triangle cache to store the results of triangle enumeration, reducing the number of database queries and minimizing communication costs.
bbd127b3-e323-50dc-96d7-ac6e826a9228|On-Demand Shuffling|The authors propose an on-demand shuffling technique, which stores the edges of the data graph in a distributed database and queries the database as needed during enumeration. This approach minimizes communication costs by only querying necessary parts of the data graph.
251cf2d8-5e82-5809-9ee1-eeaad0043eb5|Execution Plan Optimization|The execution plan optimization is proposed to reduce the execution cost by optimizing the execution plan.
9552912a-4059-512a-b763-a63ac86316e2|Symmetric Rectilinear Partitioning|The authors propose a symmetric rectilinear partitioning strategy to optimize GPU memory access for graph processing. This approach partitions the graph into blocks with matching source and destination vertex IDs, reducing unnecessary data movement and improving memory utilization.
d2b73443-d559-5022-a6b4-6d425a64da01|Block-Based Task Composition|The authors propose a block-based task composition approach to optimize GPU memory access for graph processing. This approach divides the computation into tasks, each depending on three blocks where edges of a triangle can appear, allowing for more efficient memory access patterns.
5bb12fa2-b5b1-5093-b515-8eecec120a31|Dynamic Task Scheduling|The authors propose a dynamic task scheduling approach to optimize GPU memory access for graph processing. This approach schedules tasks on multi-core CPUs and multiple streams on multiple GPUs, allowing for more efficient memory access patterns.
317e8fe8-898e-5cb5-89ab-8651224274f5|Estimation-Based Task Ordering|The authors propose an estimation-based task ordering approach to optimize GPU memory access for graph processing. This approach orders tasks based on their estimated execution time, allowing for more efficient memory access patterns.
1d9085bb-fc34-53f0-b9e2-6a3b5b93c43b|Block-Based Triangle Counting Algorithm|The authors propose a block-based triangle counting algorithm to reduce data movement during both sequential and parallel execution. This algorithm partitions the graph into smaller blocks, allowing for more efficient processing and minimizing the need for accessing the entire graph for each block. The algorithm uses a symmetric rectilinear partitioning strategy to divide the graph into blocks, ensuring that each block can fit into memory. It also employs a block variant of the Compressed Sparse Row (CSR) format to store the graph, reducing memory usage. The algorithm then processes each block in parallel, using a combination of CPU and GPU resources to count triangles. The authors report that their algorithm achieves a speedup of up to 18x on large graphs and up to 22x on smaller instances compared to existing algorithms.
011dae16-b037-5e48-a11e-cdef597709fb|Task-Based Execution Model|The authors propose a task-based execution model for heterogeneous environments, which allows for the efficient distribution of tasks among different CPUs and GPUs. The model uses a lightweight scheduler to schedule tasks on available devices, taking into account the workload of each task and the available resources. The scheduler also handles the movement of data blocks needed for task execution. The authors report that their task-based execution model achieves better scalability and performance compared to existing approaches, with a speedup of up to 5.6x on the Friendster graph.
441c4d72-967a-5349-874a-529595cea3ab|Dynamic Scheduling Technique|The authors propose a dynamic scheduling technique for block-based execution on heterogeneous environments, which avoids the long tail problem by scheduling bottleneck tasks to CPUs. The technique uses a heuristic-based ordering of tasks, which separates bottleneck tasks from lightweight tasks. It then schedules tasks on available devices, taking into account the workload of each task and the available resources. The authors report that their dynamic scheduling technique achieves better performance and scalability compared to existing approaches, with a speedup of up to 2.7x on the Twitter graph.
8b15027f-5bc5-5ca9-9684-feefa7016ba5|Hybrid Execution and Cut-Off Technique|The authors propose a hybrid execution technique that combines CPU and GPU processing, using a cut-off technique to determine the optimal distribution of tasks between CPUs and GPUs. The technique uses a cut-off value to determine the number of tasks to be executed on CPUs and GPUs, taking into account the workload of each task and the available resources. The authors report that their hybrid execution technique achieves better performance and scalability compared to existing approaches, with a speedup of up to 18x on large graphs and up to 22x on smaller instances.
707e9589-1f83-5e70-b6be-a300ecbde672|Task-Based Execution with Dynamic Scheduling|The authors propose a task-based execution approach with dynamic scheduling to optimize communication efficiency in distributed algorithms. This approach involves dividing the computation into tasks and scheduling them dynamically to minimize communication overhead and maximize memory utilization.
416b5f6e-b194-5b99-a071-028d4d258516|Hybrid Intersection Approach|The authors propose a hybrid intersection approach to optimize communication efficiency in distributed algorithms. This approach involves combining list-based and hashmap-based intersection methods to minimize communication overhead and maximize memory utilization.
2217580f-f6ac-5071-93f3-3ac2e28a1ed5|Overlapping Communication and Computation|The authors propose an approach to overlap communication and computation to optimize communication efficiency in distributed algorithms. This approach involves using multiple streams on multiple GPUs to execute tasks simultaneously and move data asynchronously.
4130bcbe-d6ed-5ee1-8eea-641cb873ac98|Dynamic Task Scheduling Scheme|The authors propose a dynamic task scheduling scheme that schedules tasks on multi-core CPUs and multiple streams on multiple GPUs to effectively utilize the massive computing capabilities on the GPUs and overlap communication with computation. The scheme involves assigning computationally heavy tasks to GPUs and lighter tasks to CPUs, and using a cut-off point to separate bottleneck tasks from lightweight tasks. This approach allows for efficient utilization of GPU resources and minimizes the long tail problem. The authors report that their dynamic task scheduling scheme achieves better performance than a fully dynamic scheduling approach, with speedups ranging from 1.4 to 3.8.
fea4238d-4c50-5226-90dc-3b01e4ccbc94|Task Workload Estimation|The authors propose a task workload estimation technique to estimate the workload of tasks and assign them to GPUs or CPUs accordingly. The technique involves estimating the workload of tasks using a heuristic-based approach, which takes into account the average degree of blocks in a task and the maximum degree of vertices in the blocks. The authors report that their task workload estimation technique achieves better performance than other estimation functions, with speedups ranging from 1.4 to 2.6.
04fc1ddc-1e60-5bd5-b7d4-d68dc65536d9|Hybrid Execution and Cut-Off|The authors propose a hybrid execution approach that combines CPU and GPU execution, and uses a cut-off point to separate bottleneck tasks from lightweight tasks. The approach involves assigning computationally heavy tasks to GPUs and lighter tasks to CPUs, and using a cut-off point to separate bottleneck tasks from lightweight tasks. The authors report that their hybrid execution approach achieves better performance than a fully dynamic scheduling approach, with speedups ranging from 1.4 to 3.8.
438fb8b6-f632-5231-a763-e3f49cec1eca|PruneJuice|PruneJuice is a pruning-based solution that limits the exponential growth of the state space, scales to massive graphs and distributed memory machines with large number of processors, and supports arbitrary search templates.
c7feab00-8b4e-5fe0-9119-00e3490a8dc6|Template-Driven Search (TDS)|TDS is a distributed algorithm that applies to the solution subgraph to verify non-local constraints, ensuring that all non-matching vertices are eliminated.
cae35700-09fb-5b79-8e75-23d7901f14df|Load Balancing and Checkpointing|Load balancing and checkpointing are used to rebalance the workload and resume processing on a smaller deployment, reducing the overall runtime.
32c0d292-aed3-52c1-a4e0-0b8dbf75ede5|Edge Elimination|Edge elimination is used to reduce the number of edges in the graph, improving the overall efficiency of the system.
15399c3e-65ba-5f23-9584-2e9e1fd66504|Asynchronous NLCC|Asynchronous NLCC is a solution that addresses the challenge of optimizing communication efficiency in distributed algorithms by leveraging asynchronous communication to reduce the number of communication rounds.
771e5d2a-4b26-5633-b051-c75f22120075|Work Aggregation|Work Aggregation is a solution that addresses the challenge of optimizing communication efficiency in distributed algorithms by reducing the number of messages sent over eliminated edges.
15eecaa9-6df5-562b-b39a-c873ea28b5e1|Load Balancing|Load Balancing is a solution that addresses the challenge of optimizing communication efficiency in distributed algorithms by rebalancing the workload to evenly distribute vertices and edges across processing cores.
48b7423f-33aa-5d83-a776-0e4c7b9a2497|Pseudo-Dynamic Load Balancing Strategy|The authors propose a pseudo-dynamic load balancing strategy to address the challenge of load imbalance in distributed systems. This strategy involves checkpointing the current state of execution, reshuffling vertex to processor assignment to evenly distribute vertices and edges across processing cores, and then resuming processing on the rebalanced workload.
46242e57-894b-5fc3-94b8-de58adc59c51|Asynchronous Communication|The authors propose the use of asynchronous communication to improve load balance in distributed systems. This approach allows for efficient communication between nodes without requiring synchronization overheads.
d196d25f-e7a8-5ddc-9974-1b2c0afab294|Distributed Maximal Matching Algorithm|The authors propose a distributed algorithm for finding a maximal matching in a graph, which is a key component in efficient graph dynamics processing. The algorithm is designed to work in a radio network model, where nodes can communicate with each other through broadcasts. The algorithm uses a distributed and low-energy approach, where nodes wake up at random times and try to recruit one of their neighbors to pair with them. The algorithm also uses a three-step handshake protocol to ensure that both endpoints of the edge agree about who they are paired with. The authors show that the algorithm always terminates in O(log n) timesteps, and with high probability, each node uses energy at most O(log n log) and the matching is maximal.
a753bf0c-0711-5dbd-9028-e286ffb6e54c|Neighbor Assignment Function (NAF) Algorithm|The authors propose an algorithm for finding a Neighbor Assignment Function (NAF) in a graph, which is a key component in efficient graph dynamics processing. The algorithm is designed to work in a radio network model, where nodes can communicate with each other through broadcasts. The algorithm uses a distributed and low-energy approach, where nodes wake up at random times and try to recruit one of their neighbors to pair with them. The algorithm also uses a three-step handshake protocol to ensure that both endpoints of the edge agree about who they are paired with. The authors show that the algorithm always terminates in O(log n) timesteps, and with high probability, each node uses energy at most O(log n log) and the NAF is optimal.
5f420ded-7122-50f4-bdbd-28f3663b8859|Matching Cover Algorithm|The authors propose an algorithm for finding a matching cover in a graph, which is a key component in efficient graph dynamics processing. The algorithm is designed to work in a radio network model, where nodes can communicate with each other through broadcasts. The algorithm uses a distributed and low-energy approach, where nodes wake up at random times and try to recruit one of their neighbors to pair with them. The algorithm also uses a three-step handshake protocol to ensure that both endpoints of the edge agree about who they are paired with. The authors show that the algorithm always terminates in O(log n) timesteps, and with high probability, each node uses energy at most O(log n log) and the matching cover is optimal.
b1f7fa58-8ef9-58d1-b884-f103f9b94f25|Exponential Backoff with Limited Participation Rate|The authors propose a solution that combines exponential backoff with a limited participation rate to optimize communication efficiency in distributed algorithms. This approach aims to minimize the number of communication rounds by reducing the likelihood of collisions and increasing the chances of successful message transmission.
932bf4ba-5473-5eb6-8c53-df2050dbdb29|Three-Step Handshake Protocol|The authors propose a three-step handshake protocol to ensure that both endpoints of an edge agree on the formation of an edge. This protocol aims to minimize the number of communication rounds by reducing the likelihood of collisions and increasing the chances of successful message transmission.
303cf6fb-97bf-56c7-9504-27fc8e30f9ed|Adaptive Participation Rate|The authors propose an adaptive participation rate mechanism that adjusts the participation rate of nodes based on the number of rounds that have passed. This approach aims to minimize the number of communication rounds by reducing the likelihood of collisions and increasing the chances of successful message transmission.
b8014f33-9cf6-573a-bdab-a6f2d0e9f6a4|Neighbor Assignment Function (NAF) Load Balancing|The authors propose a method to optimize load balance in distributed systems by utilizing Neighbor Assignment Functions (NAFs). NAFs are used to assign each node to a neighbor, ensuring that each node has a backup device to store its data in case of failure. The goal is to minimize the maximum load, defined as the number of nodes assigned to a single node.
8d9bf607-ab83-5cbb-bb4a-84c8f53f3bfd|Partial NAF Load Balancing|The authors propose a method to optimize load balance in distributed systems by utilizing partial NAFs. Partial NAFs are used to assign a subset of nodes to their neighbors, ensuring that each node has a backup device to store its data in case of failure.
e670bbdf-1dc1-5ea6-8c30-3ccc19cbb6ab|Low Arb Deterministic Coloring Algorithm|This solution addresses the challenge of efficient graph dynamics processing by proposing a deterministic distributed algorithm that computes an O(2) coloring of any n-node graph G with arboricity α, in O(log n) rounds. The algorithm uses a low out-degree orientation of the edges, which is computed in O(log n) rounds, and then applies a variation of Linial's algorithm to color the graph.
adeb4d35-b632-5ce6-9ffc-5cc1fbdc64e0|Randomized O(log) Partial Coloring Algorithm|This solution addresses the challenge of efficient graph dynamics processing by proposing a randomized distributed algorithm that partially colors any n-node graph G with arboricity α, using O(log) colors, in a manner that the remaining graph has no path longer than O(log n), with high probability.
8e9d5ea8-1560-597e-8428-a214d767c54a|Tradeo Low Arb Coloring Algorithm|This solution addresses the challenge of efficient graph dynamics processing by proposing a randomized distributed algorithm that partially colors any n-node graph G with arboricity α, using 2 colors, for a small constant 0 < 1, in a manner that the remaining graph has no path longer than O(log n), with high probability.
62bbf885-1bf6-5b8c-aade-6546a0c137e3|Deterministic Coloring After Partial Coloring|This solution addresses the challenge of efficient graph dynamics processing by proposing a deterministic distributed algorithm that colors the remaining graph after partial coloring, using O(log n) rounds.
7bb9f83c-c187-57ae-bf9d-068e4dd0b1b5|H Partition with Degree d and Size log 2 2 n|This solution specifically addresses the challenge of optimizing communication efficiency in distributed algorithms by proposing an H partition method that partitions the nodes into log 2 2 n disjoint subsets, such that every node v Hj with j 1, 2, ..., l, has at most 2 neighbors in subsets y jHj. This approach enables the computation of an acyclic orientation of the edges in O log n rounds, such that each node has out degree at most O, which is crucial for minimizing round complexity.
cfcdeb8c-da12-5449-bffc-31662baba123|Low Out Degree Orientation via H Partition|This solution specifically addresses the challenge of optimizing communication efficiency in distributed algorithms by proposing a deterministic distributed algorithm that computes an acyclic orientation of the edges in O log1 2 n rounds, such that each node has out degree at most 2, for a given parameter 0.
2c0bcd4c-c0b2-5345-babc-6c99ed575716|Randomized Distributed Algorithm for Partial Coloring|This solution specifically addresses the challenge of optimizing communication efficiency in distributed algorithms by proposing a randomized distributed algorithm that partially colors the graph with O log colors, in a manner that the remaining graph has no path longer than O log n, with high probability.
baec4540-11e7-5e4d-82ff-e3c59781fa97|Local Ratio Technique for Distributed Vertex Cover|The authors propose a distributed algorithm for the minimum weight vertex cover problem using the local ratio technique. This technique involves iteratively reducing the weights of vertices and their neighbors while ensuring that the reduced weights do not become negative. The algorithm uses a local ratio framework, which is a novel adaptation of the sequential local ratio technique to the distributed setting. The key mechanism is the division of each vertex's weight into two parts: a vault and a bank. The vault is used to initiate requests for weight reductions with neighbors, while the bank is used to respond to requests from neighbors. This approach allows for efficient weight reductions while ensuring that no weight goes below zero. The algorithm achieves a 2-approximation for the minimum weight vertex cover problem in O(log log log) rounds, where is the maximum degree in the graph.
c75785cd-2899-5c71-9f01-37cd43fbe6e9|Distributed 2-Approximation Algorithm for MWVC|The authors present a distributed algorithm for the minimum weight vertex cover problem that achieves a 2-approximation in O(log log log) rounds. The algorithm uses a distributed implementation of the local ratio technique, which involves iteratively reducing the weights of vertices and their neighbors while ensuring that the reduced weights do not become negative. The algorithm also uses a novel approach to handle the vault and bank of each vertex, allowing for efficient weight reductions. The algorithm achieves a 2-approximation for the minimum weight vertex cover problem in O(log log log) rounds, where is the maximum degree in the graph.
f51ce5ef-a060-5829-8342-890b944f7c5a|Adaptation to the CONGEST Model|The authors propose an adaptation of their distributed algorithm to the CONGEST model, where the message size is limited to O(log n) bits. The adaptation involves modifying the request and budget messages to accommodate the limited message size. The authors also propose a novel approach to handle the vault and bank of each vertex, allowing for efficient weight reductions. The adapted algorithm achieves a 2-approximation for the minimum weight vertex cover problem in O(log log log) rounds, where is the maximum degree in the graph.
13f01285-dbbc-5061-90aa-50192ea707ff|Distributed Implementation of Local Ratio Technique|The authors provide a distributed implementation of the local ratio technique, which allows for efficient computation of the vertex cover in a distributed setting.
8b1d0731-077e-5114-8dde-96182d0372aa|Adaptation to CONGEST Model|The authors adapt their algorithm to the CONGEST model, which has limited message size.
0df8bfa4-01b3-5589-890f-86c9f6bf8181|Locality-Aware Memory Hierarchy|The authors propose a novel memory hierarchy that exploits the extension locality in graph mining to optimize GPU memory access. This hierarchy consists of a high-priority memory and a low-priority memory, which are used to store frequently accessed data and less frequently accessed data, respectively.
69c64f2d-130e-5fc2-8532-1591c0eba379|Pipelined Processing Units (PPUs)|The authors design pipelined processing units (PPUs) that minimize off-chip memory accesses and maximize computational parallelism. Each PPU consists of a slot buffer, a stealing buffer, and ancestor buffers, which work together to process embeddings in a pipelined manner.
aec8a945-6a14-5d0b-926d-ad5147e93b1e|Work Stealing Mechanism|The authors propose a work stealing mechanism that reduces load imbalance among processing units. This mechanism allows each processing unit to steal work from other units when it becomes idle.
0c0387de-cf92-55f0-aebf-c96c264e4200|Graph Reordering|The authors propose a graph reordering technique that enables fast computation of the rank of each data at runtime. This technique uses the vertex ID to represent the rank for each data.
d26c14e5-797e-512d-ac0e-db051e8450e8|Locality Aware On-Chip Memory Hierarchy|The authors propose a novel on-chip memory hierarchy that exploits the extension locality in graph mining applications to reduce off-chip communication overheads. This hierarchy consists of a high-priority memory and a low-priority memory, where the high-priority memory permanently stores frequently accessed data, and the low-priority memory dynamically maintains less frequently accessed data using a new replacement policy.
f7771377-ffea-5835-883c-76b391dc5e7d|Pipelined Processing Units (PPUs) with Work Stealing|The authors propose a pipelined processing unit (PPU) architecture that maximizes computational parallelism and reduces load imbalance in graph mining applications. Each PPU has a slot buffer, a stealing buffer, and ancestor buffers, which enable the simultaneous processing of multiple initial embeddings and the efficient reuse of intermediate results.
e3a734b1-154d-5f04-a42e-101d86d7a2cd|Graph Reordering for Fast Computation of Rank ON1|The authors propose a graph reordering technique that enables fast computation of the rank ON1 value at runtime. This technique uses the vertex ID to represent the rank for each data and reorders the vertex IDs to be consistent with their rank order.
fe34f752-7ecf-539c-ab29-62f3e313306b|Locality-Preserved Replacement Policy|The authors propose a locality-preserved replacement policy that integrates the cost-efficient heuristic with hardware implementations. This policy uses a linear function of the ON1 and the recency to replace low-priority data in the low-priority memory.
c86c28bf-93d3-510b-a277-f016a64efdc0|Adaptive Dispatching of Initial Embeddings|The authors propose an adaptive dispatching mechanism for initial embeddings to balance the parallel executions of workloads across processing units (PUs).
6bc1fbee-a703-5e5e-8695-f24311d7ada5|Dynamic Slack Allocation Algorithm|This solution specifically addresses the challenge of optimizing load balance in distributed systems by dynamically allocating slack to tasks based on their execution time and dependencies. The algorithm aims to minimize energy consumption while meeting performance constraints.
0b47d76c-fffc-5887-a2c7-b5c1df5e2eec|Energy-Aware Scheduling Algorithm|This solution addresses the challenge of optimizing load balance in distributed systems by scheduling tasks based on their energy consumption and performance requirements. The algorithm aims to minimize energy consumption while meeting performance constraints.
0a1f8420-293a-538d-8ad9-13d371ec5b8a|Virtual Machine Migration|This solution addresses the challenge of optimizing load balance in distributed systems by migrating virtual machines (VMs) based on their workload and resource utilization. The algorithm aims to minimize energy consumption and improve system performance.
1e1ecc46-93dc-5646-be6f-0d9e9bb6b57e|Workload Consolidation|This solution addresses the challenge of optimizing load balance in distributed systems by consolidating workloads onto fewer nodes. The algorithm aims to minimize energy consumption and improve system performance.
4a4c8c25-7372-5f7f-9921-e9acdaa36fde|Thermal-Aware Load Balancing|This solution addresses the challenge of optimizing load balance in distributed systems by taking into account thermal constraints. The algorithm aims to minimize energy consumption and improve system performance while meeting thermal constraints.
6c994ec5-6f1c-5a62-aae8-5cb86eba170e|Dynamic Voltage and Frequency Scaling (DVFS)|This solution addresses the challenge of optimizing load balance in distributed systems by dynamically adjusting voltage and frequency levels based on workload conditions. The algorithm aims to minimize energy consumption while meeting performance constraints.
68ebffd5-9277-5965-a535-5ac0c15123b9|Energy-Efficient Routing|This solution addresses the challenge of optimizing load balance in distributed systems by using energy-efficient routing protocols. The algorithm aims to minimize energy consumption while meeting performance constraints.
7f4257be-f969-5c22-a0f2-a10da562ae7c|Power-Aware Task Scheduling|This solution addresses the challenge of optimizing load balance in distributed systems by scheduling tasks based on their power consumption and performance requirements. The algorithm aims to minimize energy consumption while meeting performance constraints.
2716b0a1-b03a-556e-8728-8b292bcdce0e|Load Balancing with Performance Constraints|This solution addresses the challenge of optimizing load balance in distributed systems by taking into account performance constraints. The algorithm aims to minimize energy consumption while meeting performance constraints.
fea357b9-eaec-58d3-8a99-b31c9f29771a|Energy-Aware Resource Allocation|This solution addresses the challenge of optimizing load balance in distributed systems by allocating resources based on energy consumption and performance requirements. The algorithm aims to minimize energy consumption while meeting performance constraints.
3c421f4c-46ed-5be0-918d-19eab28468ee|Late Projection|Late projection is a technique used to reduce the size of messages sent between vertices in a distributed graph processing system. By delaying the projection of data until later in the computation, the system can reduce the amount of data that needs to be sent, resulting in improved communication efficiency.
c85fcf44-cceb-50a4-bc2a-c7a4c7031fd1|Pipeline Operators|Pipeline operators are a technique used to improve the scalability of the system by partitioning the messages processed by a vertex in one superstep. This allows the system to keep a limited number of messages in memory, reducing the memory requirements and improving communication efficiency.
9f241666-daea-53cd-81da-157a24682dd5|Temporary Tables|Temporary tables are a technique used to store partial solutions in memory, allowing the system to reduce the amount of data that needs to be sent between vertices. By storing partial solutions in memory, the system can reduce the number of messages sent between vertices, resulting in improved communication efficiency.
8ea98dbb-1a94-5baf-9955-63c66c8ff805|Combiners|Combiners are a technique used to reduce the number of messages sent between vertices by combining multiple messages into a single message. By combining multiple messages, the system can reduce the number of messages sent between vertices, resulting in improved communication efficiency.
c95a4c35-b7ec-5c24-a87a-1b669ad5fc11|Aggregators|Aggregators are a technique used to reduce the number of messages sent between vertices by aggregating multiple messages into a single message. By aggregating multiple messages, the system can reduce the number of messages sent between vertices, resulting in improved communication efficiency.
c786d3e3-7a48-50d3-93ec-8497bdccd773|Sharded Aggregators|Sharded aggregators are a technique used to reduce the number of messages sent between vertices by aggregating multiple messages into a single message, and then sharding the aggregated message across multiple machines. By sharding the aggregated message, the system can reduce the number of messages sent between vertices, resulting in improved communication efficiency.
9414fe94-9f3f-5817-a520-5b53e0d0adcb|Out-of-Core Capabilities|Out-of-core capabilities are a technique used to reduce the memory requirements of the system by storing data on disk instead of in memory. By storing data on disk, the system can reduce the memory requirements, resulting in improved communication efficiency.
9588ccdf-beda-563e-a70a-b297a588295b|ZooKeeper|ZooKeeper is a technique used to reduce the number of messages sent between vertices by providing a centralized coordination system. By providing a centralized coordination system, the system can reduce the number of messages sent between vertices, resulting in improved communication efficiency.
682586ac-8815-57bf-8df6-d53458fa28c4|Distributed Sketching for Maximal Matching and Maximal Independent Set|The authors propose a distributed sketching model for solving the maximal matching and maximal independent set problems in large graphs. They develop a protocol that allows each vertex to send a single message to a referee, who then computes the final output. The protocol uses a combination of public and private randomness to enable the referee to compute the final output. The authors also introduce a new distribution, DMM, which is used to prove lower bounds for the problems. The authors show that any algorithm for maximal matching or maximal independent set that errs with a small constant probability requires sketches of size n1 2 for any constant 0.
bd72dd1a-c104-53a3-acd3-bf16876bbdf4|Distributed Sketching Model|The authors propose a distributed sketching model to optimize communication efficiency in distributed algorithms. This model allows each vertex to send a message, called a sketch, to a referee, who then outputs a solution to a combinatorial problem on the graph.
1ecde26b-1122-5b37-92ff-c85cfcff0386|Ruzsa-Szemerédi Graphs|The authors use Ruzsa-Szemerédi graphs to prove communication complexity lower bounds for approximate matching algorithms. These graphs are incompressible in the context of the matching problem and require players to communicate almost their entire graph to the referee.
6c980e0a-7abe-5276-920e-a415afb6452d|Information Theoretic Analysis|The authors use information theoretic tools to analyze the lower bound for the distributed sketching model. They decompose the information revealed by messages into the information revealed by public players and the sum of the informations revealed by each group of unique players.
1ca9e14f-baf7-53d3-9d68-41a7441093c8|Relaxed Greed and Memory-based Algorithm (RGMA)|The RGMA is a distributed learning algorithm that addresses the challenge of efficient graph dynamics processing by proposing a novel approach to the minimal weighted vertex cover (MWVC) problem in distributed networking systems. The algorithm views each vertex as a self-conscious player interacting with neighbors along edges to maximize payoffs based on local information.
ad612ab2-0d99-5f96-a4b7-38c11a2eafad|Potential Game Theoretic Learning|The authors propose a potential game theoretic learning approach to address the challenge of efficient graph dynamics processing. This approach formulates the MWVC problem as a spatial potential game on the given graph, where each vertex is viewed as a rational player interacting with neighbors to maximize payoffs.
69951e8d-26f3-5f60-a297-6b8381486c0c|Distributed Algorithm for MWVC|The authors propose a distributed algorithm for the MWVC problem, which addresses the challenge of efficient graph dynamics processing. The algorithm is designed to work in a distributed manner, where each vertex updates its strategy concurrently.
05a7e143-42d6-5618-9a4e-80fd92b4c7c5|Distributed Two-Level Path (DTLP) Index|The DTLP index is a novel solution proposed by the authors to address the challenge of efficient graph dynamics processing. It is designed to facilitate the efficient identification of relevant subgraphs in a dynamic graph, which is crucial for processing k-shortest path queries.
0ef81d81-a170-5d1b-8464-44cac88d2a60|K-Shortest Paths in Dynamic Graphs (KSP DG) Algorithm|The KSP DG algorithm is a distributed algorithm proposed by the authors to process k-shortest path queries in dynamic graphs. It is designed to work in conjunction with the DTLP index to efficiently identify k-shortest paths in a dynamic graph.
dadfecad-5136-5556-98c9-2e4aeb1450f4|Edge Path Index (EP Index)|The EP Index is a data structure proposed by the authors to efficiently manage the large number of bounding paths in each subgraph. It is designed to support the maintenance of bounding paths in the DTLP index.
41791362-d7bc-54d2-9ccc-5af4bf8ff5f7|Distributed Two-Level Path Index (DTLP)|The authors propose a Distributed Two-Level Path Index (DTLP) to optimize communication efficiency in distributed algorithms for identifying k shortest paths in dynamic road networks. DTLP is designed to facilitate distributed query processing over dynamic graphs by partitioning the graph into smaller subgraphs and indexing each subgraph by maintaining a list of bounding paths between any pair of boundary vertices.
355184f7-da94-5256-b08b-d0845d54f891|KSP DG Algorithm|The authors propose the KSP DG algorithm, which is designed to run in a distributed fashion on a cluster of servers. KSP DG decomposes the problem of identifying k shortest paths in the entire graph into searching for partial k shortest paths in different subgraphs in parallel.
6087afed-9bd7-5c48-92a7-9ed1f68afbd4|Distributed Expander Decomposition|The authors propose a distributed expander decomposition algorithm to efficiently process dynamic updates in large graphs. This algorithm decomposes the graph into smaller clusters with good expansion properties, allowing for faster computation of graph structures and centrality measures.
368dc401-9ef6-5390-afcb-152288295e91|Parallelized ApproximateNibble|The authors propose a parallelized version of the ApproximateNibble algorithm to efficiently compute sparse cuts in large graphs. This algorithm is designed to work in a distributed setting, allowing for faster computation of sparse cuts even in the presence of dynamic updates.
59d5844d-dcc5-5616-8c0f-48bb3c2d4a4b|Low-Diameter Decomposition|The authors propose a low-diameter decomposition algorithm to efficiently process dynamic updates in large graphs. This algorithm decomposes the graph into smaller clusters with low diameter, allowing for faster computation of graph structures and centrality measures.
e559aa31-29f8-5718-8ff5-ccfe1632b985|Hierarchical Routing Structure|The authors propose a hierarchical routing structure to efficiently process dynamic updates in large graphs. This structure allows for faster computation of graph structures and centrality measures, even in the presence of dynamic updates.
371c00f4-d035-5c98-a2ee-ba432a6f4840|Distributed Expander Decomposition Algorithm|The authors propose a distributed expander decomposition algorithm that efficiently partitions the graph into clusters with low conductance and diameter. This algorithm is designed to optimize communication efficiency in distributed algorithms by reducing the number of communication rounds required for various graph problems.
4400b731-94a8-5f72-b5fb-9968075bb2a3|Parallelized Nibble Algorithm|The authors propose a parallelized version of the Nibble algorithm, which is a key component of the distributed expander decomposition algorithm. This parallelized algorithm enables the efficient execution of multiple Nibble instances simultaneously, reducing the overall round complexity.
0fe9c2ec-50e0-58f4-9985-3764bbbaa18b|Low-Diameter Decomposition Algorithm|The authors propose a low-diameter decomposition algorithm that efficiently partitions the graph into clusters with low diameter. This algorithm is designed to optimize communication efficiency in distributed algorithms by reducing the number of communication rounds required for various graph problems.
9ef467f5-957f-58d4-bf68-c6c967f216e0|Routing Algorithm|The authors propose a routing algorithm that efficiently routes messages between vertices in the graph. This algorithm is designed to optimize communication efficiency in distributed algorithms by reducing the number of communication rounds required for message delivery.
326f4641-359f-5880-ab4e-4267517452a4|Parallel Nibble|The authors propose a parallel version of the Nibble algorithm, called ParallelNibble, which involves a simultaneous execution of a moderate number of ApproximateNibble instances. This algorithm is designed to optimize load balance in distributed systems by reducing the number of iterations required to achieve a nearly most balanced sparse cut.
c2b8f558-4e75-51eb-9d41-cf0e45d2ee0e|Random Nibble|The authors propose a randomized version of the Nibble algorithm, called RandomNibble, which executes ApproximateNibble with a random starting vertex. This algorithm is designed to optimize load balance in distributed systems by reducing the number of iterations required to achieve a nearly most balanced sparse cut.
506cdf14-7992-5569-bf2a-164b3b9db61b|Distributed Triangle Enumeration|The authors propose a distributed algorithm for triangle enumeration, which is designed to optimize load balance in distributed systems. The algorithm uses a combination of techniques, including a distributed expander decomposition algorithm, a variant of the multi-commodity routing scheme, and an adaptation of the CONGESTED CLIQUE Triangle Enumeration algorithm.
fe158fd6-30c8-5487-8ed7-d8387f3c80dd|Distributed Vertex Hashing TRI EST BASE (DVHT b)|DVHT b is a distributed improvement of the streaming algorithm TRI EST BASE, which uses the Master Worker Aggregator architecture to efficiently process graph streams. It assigns edges from the graph stream to different workers by comparing the mapping values of the two vertices of each edge, reducing the variance of estimates by dividing the graph into multiple subgraphs stored in different workers and reducing the number of shared edge triangles in each worker.
7591cec7-22d2-52f4-b92c-6a8836eb9e5f|Distributed Edge Hashing TRI EST IMPR (DEHT i)|DEHT i is a distributed improvement of the streaming algorithm TRI EST IMPR, which uses the improved Master Worker Aggregator architecture with grouped and hierarchical aggregators. It assigns edges to workers with a fixed probability p, and workers execute TRI EST IMPR algorithm, which is more accurate than TRI EST BASE.
3322a035-aec0-5739-8b82-753262369af4|Distributed Vertex Hashing (DVHT) Algorithm|The DVHT algorithm is a distributed improvement of the streaming algorithm TRI EST BASE, which uses a hash function to assign edges from the graph stream to different workers by comparing the mapping values of the two vertices of each edge. This approach optimizes communication efficiency by reducing the number of edges sent to each worker, thereby minimizing the communication overhead.
9403df8d-ad72-5933-b219-9a547da29b0c|Distributed Edge Hashing (DEHT) Algorithm|The DEHT algorithm is a distributed improvement of the streaming algorithm TRI EST IMPR, which uses a hash function to map edges to workers with a fixed probability. This approach optimizes communication efficiency by reducing the number of edges sent to each worker and minimizing the communication overhead.
c2f2c21e-5dde-598a-8437-f2416c558822|Grouped and Hierarchical Aggregators|The grouped and hierarchical aggregators approach is used in the DEHT algorithm to optimize communication efficiency. This approach involves dividing workers into different communication groups, each with an aggregator, and using a main aggregator to aggregate the values of all secondary aggregators.
f68f65ab-e70d-5d2c-bd37-d6cc9ddcef6f|Fine-grained Framework for Distributed Clustering|The authors propose a fine-grained framework for distributed clustering that divides the local vertices into batches and processes each batch separately. This approach reduces the memory consumption and communication overhead by only fetching and storing the remote adjacency lists for each batch of vertices.
05bedcd2-574f-544a-b32c-7b86e57580af|Dynamic Work Stealing Mechanism|The authors propose a dynamic work stealing mechanism to handle unbalanced workloads in the distributed clustering process. This mechanism allows idle workers to steal unprocessed workload from busy workers, which helps to accelerate the overall process.
64c6a20d-d7ab-565c-9e74-0c7122bf8378|Pruning Technique for Core Checking|The authors propose a pruning technique for core checking that reduces the number of similarity computations required. This technique uses the similar and effective degrees of vertices to early terminate the core checking process.
9a6d99d2-18e2-55d6-b7c0-be6e6095f4cb|Fine-Grained Clustering Framework|The authors propose a fine-grained clustering framework for distributed SCAN algorithms, which divides the local vertices in each machine into batches and processes each batch separately. This approach reduces the communication overhead by minimizing the number of remote adjacency lists that need to be fetched and stored in each machine.
b5c69898-02ac-58a6-b96f-9f140454a1a1|CoreCluster Algorithm|The authors propose the CoreCluster algorithm, which clusters a list of local vertices and their neighbors. The algorithm fetches the cluster IDs of the neighbors of every vertex in the batch, and then merges the clusters of similar vertices.
f249fc7f-e01c-5d9c-a462-e704a1fda3ea|Dynamic Work-Stealing Mechanism|The authors propose a dynamic work-stealing mechanism to handle unbalanced workloads in the distributed system. The mechanism allows idle machines to steal unprocessed batches from busy machines, reducing the overall processing time.
d89559ea-5010-593d-8ce2-13d8a344b5c2|Weighted Memory-based Algorithm (WMA)|The WMA is a distributed algorithm designed to optimize the minimum weighted vertex cover (MWVC) problem in graph processing. It introduces a weighted memory-based heuristic into the framework of learning in games, where each element in the memory vector is randomly chosen with a non-uniform probability determined by local information, including node degrees and weights.
b7757d41-451d-5f30-8e48-f07361469ee4|Potential Game Model|The potential game model is a theoretical framework used to analyze the convergence of the WMA. It establishes a potential function that aligns with the changes in the utility function, ensuring that the WMA converges to Nash equilibria.
ca3e8535-87cf-5155-b356-06eb558641f7|Restricted Greedy Algorithm (RGA)|The RGA is a distributed algorithm designed to optimize the MWVC problem. It employs a relaxed greedy rule, which updates actions based on the regret value and the best response.
2087f9ea-14d3-57d4-875b-860dda5fde65|Feedback-based Rule (FBR)|The FBR is a distributed algorithm designed to optimize the MWVC problem. It employs a feedback-based rule, which updates actions based on the feedback from the neighbors.
841c4a5d-c126-510d-8118-4f62c37498d6|Restricted Best Response (RBR)|The RBR is a technique used in the WMA to update the actions of players in the game. It addresses the challenge of efficient graph dynamics processing by providing a more efficient way to compute the best response of players.
d4c69e36-c88e-57fa-970a-a026741fe39b|Distributed Hybrid Algorithm for Graph Coloring Problem (DH GCP)|The DH GCP algorithm is designed to efficiently solve the graph coloring problem by utilizing a distributed hybrid approach that combines tabu search, crossover operators, and perturbation techniques. This algorithm is specifically tailored to address the challenge of efficient graph dynamics processing by adapting to changes in the graph structure and minimizing computational costs.
11d72b26-ebd0-5fff-8442-e1f760f9d945|Reinforcement Learning-based Weight Matrix|The authors propose a reinforcement learning-based weight matrix to optimize communication efficiency in distributed algorithms. This solution specifically addresses the challenge by dynamically adjusting the application probability of a particular action under a specific condition, allowing the algorithm to adapt to the search progress and make informed decisions about which agents to trigger.
641c6699-ea8c-5ba1-aaaa-55f8b90907a7|Vertex-Cut Partition Based Graph Coloring (VColor)|VColor is a novel approach to graph coloring that partitions a large graph into smaller connected components (CCs) by removing a vertex cut component (VCC). This allows for efficient coloring of the CCs and the VCC separately, reducing computational costs.
c709d030-ca3d-5a39-bf40-ce2fe7d61ffc|Multi-Graph Coloring using Vertex-Cut Partition Hierarchy (MGColor)|MGColor is an extension of VColor that optimizes the coloring of a set of graphs by extracting common subgraphs and using them as common CCs of the vertex-cut partitions (VPs) of the graphs.
707b324a-a413-50db-b30c-4c98f9effa0a|Cost Model for Coloring Time Estimation|A cost model is proposed to estimate the coloring time of VColor in terms of certain parameters, allowing for the optimization of the coloring process.
e6080524-2418-5d1b-b2e8-003cc095b274|VColor|VColor is a vertex cut based coloring technique that optimizes communication efficiency in distributed algorithms by partitioning the graph into smaller connected components (CCs) and coloring them independently.
eb0af5eb-2ea5-5e86-a34c-4ee2b402bded|MGColor|MGColor is a multi-graph coloring technique that optimizes communication efficiency in distributed algorithms by constructing a vertex cut partition hierarchy (VPH) to represent the common subgraphs of the graphs as common CCs.
b797e1fb-7098-5a9c-bca2-a0b8acade46a|Cost Model|The cost model is a mathematical framework that optimizes communication efficiency in distributed algorithms by estimating the optimal values of the parameters that minimize the running time on a given set of graphs.
0d5b95d9-4e03-57aa-986e-c3ea0605c232|P-Match Graph Computation|The authors propose a novel approach to compute a small intermediate result called p-match graph, which over-approximates strong simulation. This solution specifically addresses the challenge of efficient graph dynamics processing by reducing the computational cost of strong simulation in large graphs.
683a3334-56a8-574f-b9cf-fe00493aa5d6|Distributed Algorithm for Strong Simulation|The authors propose a distributed algorithm for strong simulation, which is designed to work in conjunction with the p-match graph computation. This solution specifically addresses the challenge of efficient graph dynamics processing by enabling the parallel processing of strong simulation in large graphs.
adfe7742-029b-5cdb-af7e-240e7ff49e55|Partition Tree Computation|The authors propose a method to compute partition trees, which are used to construct the p-match graph. This solution specifically addresses the challenge of efficient graph dynamics processing by providing an efficient method for computing partition trees.
da5646b0-21c8-546c-9320-df2798b8a02a|Locally Determinable Data Graph Redistribution|The authors propose a method to redistribute the data graph to make it locally determinable, which is used in conjunction with the distributed algorithm for strong simulation. This solution specifically addresses the challenge of efficient graph dynamics processing by enabling the parallel processing of strong simulation in large graphs.
2d057eee-838f-5d33-be14-dd3b5544cd94|P-Match Graph Redistribution|The authors propose a novel approach to optimize communication efficiency in distributed algorithms by redistributing the data graph to make it locally determinable. This approach involves computing a p-match graph, which overapproximates strong simulation, and then conducting strong simulation on this p-match graph. The redistribution process is designed to minimize data shipment and ensure that each node in the data graph can be determined locally.
0ce500d8-356d-51c1-8ae7-25834da1a757|Online Parallel Matching|The authors propose an online parallel matching algorithm, PMatchStrSim, which computes the p-match graph in parallel across multiple machines. The algorithm involves computing local p-match graphs, merging them, and conducting strong simulation on the resulting p-match graph.
d6fd536c-0847-57c2-871c-5e8a22d51e25|Coalesced Memory Access Pattern Optimization|The authors propose a novel memory access pattern optimization technique that ensures coalesced memory access for graph processing on GPUs. This technique involves reordering the graph data to minimize non-coalesced memory accesses, thereby reducing memory access latency and improving memory bandwidth utilization.
ab3fceb8-780b-50cc-a95a-c183715e7399|Synchronization-Aware Memory Access Optimization|The authors propose a synchronization-aware memory access optimization technique that minimizes synchronization overhead for graph processing on GPUs. This technique involves optimizing memory access patterns to reduce synchronization latency, thereby improving overall performance.
7e564fd3-29cb-5267-a02f-3ffad0f3486b|Memory Bandwidth-Aware Graph Partitioning|The authors propose a memory bandwidth-aware graph partitioning technique that optimizes graph partitioning to leverage memory bandwidth effectively. This technique involves partitioning the graph into smaller subgraphs that can be processed efficiently within the available memory bandwidth.
d9d4cf7a-bde3-5df2-b8d9-39f5a3935d11|Adaptive Trussness Recomputation|This solution addresses the challenge of efficient graph dynamics processing by proposing an adaptive approach to recomputing trussness values in response to edge and vertex updates. The method involves maintaining a set of affected vertices and edges, and iteratively updating the trussness values based on the changes. The approach is designed to minimize the number of iterations required to maintain the graph structure.
4a5ece42-95a0-55e3-8878-ed2531252a00|Incremental Betweenness Centrality|This solution addresses the challenge of efficient graph dynamics processing by proposing an incremental approach to updating betweenness centrality measures in response to edge modifications. The method involves maintaining a set of affected vertices and edges, and iteratively updating the betweenness centrality values based on the changes.
947f71b0-6ba5-50de-aa2e-bfce14cd89c5|Batch Processing of Vertex and Edge Updates|This solution addresses the challenge of efficient graph dynamics processing by proposing a batch processing approach to handling vertex and edge updates. The method involves grouping multiple updates into a single batch, and processing the batch in a single iteration.
64f71a94-903c-5744-ae12-db9c83533238|Hierarchical Clustering-Based Communication Reduction|This solution proposes a hierarchical clustering approach to reduce communication overhead in distributed algorithms. By grouping nodes into clusters based on their proximity, the algorithm minimizes the number of inter-cluster communications, thereby reducing the overall round complexity.
3ee594e1-bc13-54c6-a8e7-fedbb512ed2a|Asynchronous Gradient Descent with Adaptive Learning Rates|This solution introduces an asynchronous gradient descent algorithm with adaptive learning rates to optimize communication efficiency in distributed optimization problems. By allowing nodes to update their parameters asynchronously and adaptively adjusting learning rates, the algorithm reduces the number of communication rounds required for convergence.
714b3173-751b-5c5c-90a4-51c5e9e21775|Distributed k-Means with Quantized Communication|This solution proposes a distributed k-means algorithm that employs quantized communication to reduce the communication overhead. By quantizing the data points and transmitting only the quantized values, the algorithm minimizes the amount of data exchanged between nodes.
62f3e909-cf0a-500d-8f3d-56f965e5188b|Dynamic Load Balancing using Work-Stealing|This solution proposes a dynamic load balancing approach that utilizes work-stealing to optimize load balance in distributed systems. The approach involves each node maintaining a queue of tasks and periodically checking neighboring nodes for available tasks to steal. This technique ensures that nodes with lighter workloads can assist nodes with heavier workloads, thereby achieving a more balanced distribution of tasks.
09888f10-a9f8-5f79-b38e-48c6d024bfa2|Load Balancing using Machine Learning-based Predictive Modeling|This solution proposes a load balancing approach that leverages machine learning-based predictive modeling to forecast workload patterns and optimize task allocation. The approach involves training a machine learning model on historical workload data to predict future workload patterns, and then using these predictions to allocate tasks to nodes in a way that minimizes workload imbalance.
42492534-c2c0-584a-b657-0e35532a1e9d|Hierarchical Load Balancing using Graph Partitioning|This solution proposes a hierarchical load balancing approach that uses graph partitioning to optimize task allocation and minimize workload imbalance. The approach involves partitioning the graph of tasks and nodes into smaller sub-graphs, and then allocating tasks to nodes within each sub-graph in a way that minimizes workload imbalance.
22659e4f-3157-5995-9f55-1d5e296a0e16|Neighborhood-based Transition Rule Attachment|This solution involves attaching message transition rules to data vertices based on their neighborhood structural requirements, rather than simply attaching rules based on vertex labels. This approach aims to reduce the number of unnecessary messages and minimize memory consumption.
46427866-8a83-5b9d-a345-3734830c9508|Incremental Evaluation over Dynamic Graphs|This solution involves maintaining intermediate results incrementally when the graph is updated, rather than re-computing from scratch. This approach aims to reduce the response time and message cost.
95bbe6eb-e602-5a8d-81f9-0907640cdbb5|Single Sink DAG (SSD) Evaluation Plan|This solution involves converting a query pattern into a Single Sink DAG (SSD) and proposing an evaluation plan with message transitions on the SSD to detect the pattern in a large dynamic graph. This approach aims to reduce the message transfer cost and response time.
dcb5a9b6-7605-56e6-9c78-50207af0558b|Encoding Identifiers in Messages|This solution involves encoding the identifiers of data vertices into messages to overcome the limitation of not being able to distinguish between vertices with the same label. This approach aims to improve the precision of pattern detection.
4c4a3815-bfa9-5e05-88f8-ef796ef9c6f8|Join Operations on Partial Vertices|This solution involves conducting join operations on partial vertices during graph exploration to improve the precision of pattern detection. This approach aims to reduce false positives and improve the accuracy of pattern detection.
3cc6e9ee-d6c2-5dde-b958-0c532f814a7c|Neighborhood-Based Optimized Rule Attachment|The neighborhood-based optimized rule attachment is a technique that optimizes the attachment of message transition rules to data vertices based on their neighborhood structural requirements. This technique reduces the number of attached rules and prunes the search space, leading to improved efficiency and precision.
4a08e183-78e1-5097-bebb-a09ac7c19e73|Incremental Evaluation of Pattern Detection|The incremental evaluation of pattern detection is a method that refines the previously discovered results incrementally based on the changes in the graph, instead of re-detecting the pattern on the current graph instance in each super step. This approach reduces the computational cost and improves the efficiency of pattern detection in dynamic graphs.
11163110-7443-52da-b062-cb3caa5357d4|Triangle Complete Subgraph (TC Subgraph) Construction|The authors propose constructing a triangle complete subgraph (TC subgraph) for each computing node to efficiently process graph dynamics. This approach enables the detection of local maximal k-trusses in parallel, reducing the number of iterations and computational costs.
f3ead103-76c9-5a21-bbfa-4a392cae48fd|Seamless Detection Technique|The authors introduce a seamless detection technique that enables the detection of local maximal k-trusses without restarting the computation from scratch. This approach reduces the number of iterations and computational costs by reusing previously computed results.
80004dda-a1db-5f73-98be-d489120e5555|Edge Support Law|The authors propose the edge support law, which states that the frequency distribution of initial edge supports in real-world graphs satisfies the power law. This law enables the estimation of the space cost of the algorithm and ensures that the algorithm achieves an appropriate space cost in practice.
52d16220-03c1-5c93-9759-b61b9945da80|Subgraph Oriented Model|The authors propose a subgraph oriented model that relaxes the vertex constraints of the vertex-centric model, allowing for more flexible and efficient graph processing. This approach enables the expression of more complicated graph algorithms and improves the performance of the algorithm.
6458e243-17f1-5cbc-b29e-0df53d443ae0|Edge Support Law-based Partitioning|The authors propose a novel partitioning strategy based on the Edge Support Law, which ensures that the parallel algorithm achieves a low space cost for graphs in the real world. This approach reduces the number of edges that need to be replicated, resulting in improved communication efficiency.
36cc4e87-b826-57db-b143-c31626ea28a2|Seamless Detection without Restart|The authors propose a seamless detection approach that avoids the need for repeated triangle counting and restarts between successive iterations. This approach enables the algorithm to detect local maximal k-trusses in parallel, reducing communication overhead.
6db65bb6-98f3-56d8-9324-03e4010abd07|Subgraph-oriented Model|The authors propose a subgraph-oriented model that allows for more flexible and efficient expression of local graph algorithms. This model enables the algorithm to access vertices and edges on demand, reducing communication overhead.
95ad6301-b5b0-5598-8c02-2652b20436a5|Edge Balanced Partition Scheme|The authors propose an edge balanced partition scheme to optimize load balance in distributed systems. This scheme aims to balance the core edges with a small edge cut ratio, which can help decrease the communication cost and improve the overall performance of the system.
0a5660cb-018e-5a96-9a93-038469e9a62d|Triangle Complete Subgraph|The authors propose a triangle complete subgraph to optimize load balance in distributed systems. This subgraph includes all the edges that belong to the same triangle, which can help reduce the communication cost and improve the overall performance.
9f1fd26c-2f44-5e87-8d73-589554f3888e|Edge-Centric Processing with Concatenated Edge List (CEL)|The authors propose an edge-centric processing approach that iterates over the edges rather than vertices, which helps to mitigate irregular memory access and load imbalance in GPU. They also introduce a data structure called Concatenated Edge List (CEL) to store and process a graph, which enables coalesced memory access and reduces synchronization overhead.
66262688-54a2-58e0-bdb9-76a5b7e061b6|Two-Level GPU Processing and Memory Access Pattern|The authors propose a two-level execution mode that reduces random access and synchronization overhead in global memory. They use a shared memory to cache data access and synchronization, which improves performance when the degree of synchronization is less than a threshold.
eb2b045a-14a9-5462-bf5d-5cd3eeaa0750|Minimizing Preprocessing Time with Edge List Representation|The authors propose an edge list representation to store and process a graph, which minimizes preprocessing time and enables coalesced memory access.
54100216-f5cd-5ffb-a210-4ca90aac1aac|Optimizing Memory Access Pattern with Shared Memory|The authors propose using shared memory to cache data access and synchronization, which improves performance when the degree of synchronization is less than a threshold.
017e7810-5fe8-5977-89c7-78b6aa94d9b7|Batching of Communication Rounds|The authors propose batching of communication rounds to reduce the communication pressure by aggregating the outgoing data and implementing a policy that trades off computation with communication. The solution involves storing the vertices for e.g., 7, 9, 11, 14, 17, and demarcating vertex boundaries such that the remote side can translate the sequence of vertex IDs in its incoming message buffer into the correct combination of vertices as edges. Since the sequence of vertices in the outgoing communication buffer can supersede the integer range, the authors internally batch communications if the data count is beyond the integer range allowed by MPI.
3516eebd-0a2a-5589-8431-d7509e92b3e7|Adaptive Routing Schemes|The authors experiment with different adaptive routing schemes for MPI Alltoallv to optimize communication efficiency. The solution involves using the MPICH GNI A2A ROUTING MODE environment variable to select different routing schemes, such as A0, A1, A2, and A3, to optimize the performance of MPI Alltoallv.
aeaa01d8-4fcf-57de-b84a-c4f86f4fbf80|Batching and Asynchronous Communication|The authors propose using batching and asynchronous communication to alleviate the issue of load imbalance in distributed systems. This approach involves aggregating outgoing data and implementing a policy that trades off computation with communication.
82f946db-ed40-5da0-8d11-89e3ffbc4b77|Subgraph-Centric Data Model|The authors propose a subgraph-centric data model to reduce network traffic and optimize GPU memory access for graph processing. This approach involves partitioning the data graph into disjoint subgraphs, each mapped to a single vertex in the GPS system. The messages from a subgraph are merged and encapsulated before transmission, reducing network traffic and memory access overhead.
af381f14-3968-55d1-90af-12b2e1bf66bf|Incremental Graph Pattern Matching Algorithm|The authors propose an incremental graph pattern matching algorithm to efficiently process dynamic updates in large graphs. This algorithm is designed to minimize computational costs and iterations by only triggering computations on the vertices whose matching status is changed by the graph update events.
a3678a12-368d-54f2-95c3-671c2219ed88|Vertex-Centric Incremental Algorithm|The authors propose a vertex-centric incremental algorithm to handle graph updates. This algorithm involves three phases: update, checking, and propagation.
bb0038eb-391c-58bc-b2cd-43a9d900d648|Incremental Pattern Matching Algorithm|The authors propose an incremental pattern matching algorithm that only triggers computations on the vertices whose matching status is changed by the graph update events. This approach aims to reduce the number of communication rounds by minimizing the number of vertices that need to be updated.
84bed4c7-ca51-545d-8b9d-a0c4e9dea544|Dynamic Subgraph Sizing|The authors propose dynamically adjusting the size of subgraphs to optimize load balance in distributed systems. This approach involves finding the optimal subgraph size that balances the trade-off between network traffic reduction and workload imbalance.
19db3b4e-ae1e-5c55-bdd2-895fdf28add9|CentLocal Algorithm for Approximate Maximum Cardinality Matching|The CentLocal algorithm is designed to approximate maximum cardinality matching in bounded degree graphs. It works by recursively applying a local improvement technique to find augmenting paths and update the matching.
73ca5839-5cd7-5001-828f-f46e92df3aa8|CentLocal Algorithm for Approximate Maximum Weighted Matching|The CentLocal algorithm is designed to approximate maximum weighted matching in bounded degree graphs. It works by recursively applying a local improvement technique to find augmenting paths and update the matching.
e51e57ae-abe8-5d0f-afa8-2f09cddff4aa|Distributed Algorithm for Approximate Maximum Cardinality Matching|The distributed algorithm is designed to approximate maximum cardinality matching in bounded degree graphs. It works by simulating the CentLocal algorithm for approximate maximum cardinality matching.
0f0ed33f-31a0-592f-b531-24c9bf18f737|Distributed Algorithm for Approximate Maximum Weighted Matching|The distributed algorithm is designed to approximate maximum weighted matching in bounded degree graphs. It works by simulating the CentLocal algorithm for approximate maximum weighted matching.
085ba730-664f-544f-b124-cc0dd82f662e|CentLocal Algorithm for Efficient Graph Dynamics Processing|The authors propose a CentLocal algorithm that efficiently processes dynamic updates in large graphs by minimizing computational costs and iterations. This algorithm is designed to maintain graph structures such as maximal k-trusses under updates, efficiently adjust centrality measures like betweenness in response to edge modifications, and batch process vertex and edge updates while preserving structural integrity.
42456c88-5156-5eba-8579-cb1befd78e57|Distributed Local Algorithm for Efficient Graph Dynamics Processing|The authors also propose a Distributed Local algorithm that builds upon the CentLocal algorithm to efficiently process dynamic updates in large graphs. This algorithm is designed to work in a distributed setting, where each vertex in the graph can only access its local neighborhood.
a3a6b998-6d38-5723-8826-f4ea7ac819f7|Probe Simulation Technique|The authors propose a probe simulation technique that enables the efficient processing of dynamic updates in large graphs. This technique involves simulating probes to auxiliary graphs to reduce computational costs.
16de1ce3-c606-5452-b359-57313be01bf0|Recursive Oracle for Membership in Matching|The authors propose a recursive oracle for determining membership in the matching, which enables efficient processing of dynamic updates in large graphs.
fedfa017-e597-5c28-8b92-e42557452572|Simulation of CentLocal by DistLocal|The authors propose a simulation technique that transforms a CentLocal algorithm into a DistLocal algorithm. This solution specifically addresses the challenge of optimizing communication efficiency in distributed algorithms by minimizing the number of communication rounds.
dd1d06d2-48b3-5476-bf76-9b1ceddda36d|Matrix Algebraic Primitives for Maximal Cardinality Matching|The authors propose using matrix algebraic primitives to develop distributed memory parallel algorithms for computing maximal cardinality matching in bipartite graphs. This approach enables efficient graph dynamics processing by leveraging fast parallel implementations of matrix algebraic primitives.
f39cab8a-9c68-5452-8da5-49e28ca000d6|Matrix Algebraic Primitives for Distributed Memory Parallel Algorithms|The authors propose using matrix algebraic primitives to develop distributed memory parallel algorithms for computing maximal cardinality matching in bipartite graphs. This approach enables the exposure of a higher degree of parallelism on distributed memory platforms, leading to improved communication efficiency. The authors utilize matrix algebra building blocks, such as sparse matrix-vector multiplication (SpMV) and vector manipulations, to update the current matching. This approach allows for the efficient traversal of the bipartite graph from both sides without storing the transpose of the matrix, reducing communication overhead. The authors report achieving up to 300 speedup on 1024 cores of a Cray XC30 supercomputer, demonstrating the effectiveness of their approach in optimizing communication efficiency.
8fbc553b-bae1-576c-8aff-b24793e339fb|Combinatorial BLAS (CombBLAS) Framework|The authors employ the CombBLAS framework to distribute sparse matrices on a 2D processor grid, enabling the efficient storage and manipulation of large bipartite graphs. The CombBLAS framework uses a doubly compressed sparse columns (DCSC) format to store local submatrices, allowing for scalable storage and efficient SpMV operations. The authors report achieving good scaling on up to 16,384 processors, demonstrating the effectiveness of the CombBLAS framework in optimizing communication efficiency.
8a90d203-7905-551b-b549-8c16e1e2eaf1|Select2nd, Min Semiring for SpMV|The authors propose using the select2nd, min semiring for SpMV operations to efficiently explore row vertices from unmatched column vertices. The select2nd, min semiring operates on a set of binary numbers and a set of pairs of integers, allowing for the efficient selection of minimum products from the selected columns. The authors report achieving good performance on various input graphs, demonstrating the effectiveness of the select2nd, min semiring in optimizing communication efficiency.
b88352c2-6de9-5cee-ad8b-be02e67c98e2|Invert Function for Vector Manipulation|The authors propose using the INVERT function to efficiently update the mates of column vertices by selecting a unique child for each column vertex. The INVERT function swaps the indices and values of nonzero entries in a sparse vector, allowing for efficient vector manipulation. The authors report achieving good performance on various input graphs, demonstrating the effectiveness of the INVERT function in optimizing communication efficiency.
c56015b8-02de-5353-9e62-e3da5819a6b5|Random Permutation of Input Matrices|The authors propose a solution to optimize load balance in distributed systems by randomly permuting the input matrix A before running the matching algorithms. This approach aims to balance the load across processors by distributing the nonzeros of A and x evenly.
c5c27b3a-8411-5385-a73b-5c84e982f542|2D Processor Grid Distribution|The authors propose a solution to optimize load balance in distributed systems by distributing the sparse matrix A on a 2D processor grid. This approach aims to balance the load across processors by dividing the matrix into smaller submatrices and assigning them to different processors.
b715c976-f909-5875-874b-0dbb065f84ed|Compressed Sparse Blocks (CSB) Data Structure|The authors propose a solution to optimize load balance in distributed systems by using a Compressed Sparse Blocks (CSB) data structure to store the sparse matrix A. This approach aims to reduce the storage requirements and improve the performance of the algorithms.
88705621-9b36-5780-8de1-6016580e2414|Semiring-based Matrix Algebra|The authors propose a solution to optimize load balance in distributed systems by using a semiring-based matrix algebra to perform the matching algorithms. This approach aims to reduce the communication overhead and improve the performance of the algorithms.
0c1610ec-1cd1-5f73-9c5a-05ef808699d9|Quantum Distributed Algorithm for Triangle Finding|The authors propose a quantum distributed algorithm for triangle finding in the CONGEST model, which addresses the challenge of efficient graph dynamics processing by utilizing quantum techniques to speed up the computation.
6a7a6654-6969-59b6-8219-ac4601b3e2c2|Expander Decomposition|The authors use an expander decomposition of the graph to reduce the triangle finding problem to a set of smaller sub-problems, each of which can be solved more efficiently.
c1b56d1b-2d10-5648-8f23-9411cdfac2a8|Classical Routing Techniques|The authors use classical routing techniques to gather information about the edges of the graph, which is necessary for the triangle finding problem.
7f5c5910-d9a0-5ac6-afa8-153a43b6e586|Distributed Quantum Search|The authors use a distributed quantum search framework to find a triple of vertices that form a triangle.
09ddc003-c2dc-55ba-9c9c-11f7121319db|Quantum Distributed Search Framework|The authors propose a quantum distributed search framework to optimize communication efficiency in distributed algorithms. This framework enables the detection of a triangle in a graph with high probability in O(n^{1/4}) rounds, which is more efficient than the best known classical algorithms.
c495ad49-a120-50ef-bf3c-bbf6358dc742|Classical Distributed Algorithm for Triangle Finding|The authors propose a classical distributed algorithm for triangle finding that uses a combination of expander decomposition and routing techniques. This algorithm can detect triangles in a graph with high probability in O(n^{1/3}) rounds.
194aa487-7a98-5ded-a08c-241955a5a7e8|Quantum Algorithm for Triangle Finding|The authors propose a quantum algorithm for triangle finding that uses a combination of quantum distributed search and expander decomposition. This algorithm can detect triangles in a graph with high probability in O(n^{1/4}) rounds.
cfeab062-8f2c-5afa-b84d-5e427e7c4e08|Classical Distributed Algorithm|The authors propose a classical distributed algorithm to optimize load balance in distributed systems. This algorithm is specifically designed to address the challenge of load balance optimization by enabling efficient search and detection of triangles in a distributed graph. The classical distributed algorithm leverages classical computing principles to achieve faster search times and improved load balancing.
07452e68-e8ea-5ebd-b0a1-e46b3bbf0ffb|Quantum Distributed Algorithm|The authors propose a quantum distributed algorithm to optimize load balance in distributed systems. This algorithm is specifically designed to address the challenge of load balance optimization by enabling efficient search and detection of triangles in a distributed graph. The quantum distributed algorithm leverages quantum computing principles to achieve faster search times and improved load balancing.
01139d78-e556-58f7-8cfa-80ee8fe4736b|Hybrid Parallel Triangle Counting Algorithm|The authors propose a hybrid parallel triangle counting algorithm that uses MPI on distributed memory compute nodes and Cilk for shared memory parallelism. This solution specifically addresses the challenge of efficient graph dynamics processing by providing a scalable and efficient algorithm for triangle counting, which is a fundamental graph analysis problem.
6e89eb1e-b6a1-5f9f-99ea-37bb12651315|2D Cartesian Partitioning Scheme|The authors use a 2D Cartesian partitioning scheme to distribute the graph among MPI processes. This solution specifically addresses the challenge of efficient graph dynamics processing by reducing communication overheads and allowing for efficient computation.
85c90b0a-8c2c-5c26-9d1a-fd1c3bd99634|Cilk-based Shared Memory Parallelism|The authors use Cilk for shared memory parallelism within each MPI process. This solution specifically addresses the challenge of efficient graph dynamics processing by providing a efficient and scalable approach for parallel computation.
cef4f878-3fb5-587a-bb75-07318ba482cd|Hybrid Parallelization using MPI and Cilk|The authors propose a hybrid parallelization approach that combines MPI for inter-process communication with Cilk for shared-memory parallelism. This approach allows for efficient communication and computation in distributed algorithms.
6eed1e1a-bc21-5fa9-b054-48f68801ba64|Over-Partitioning of Row Blocks|The authors propose an over-partitioning approach for row blocks, where each row block is divided into smaller blocks to balance the number of nonzeros in each block.
ea6c1d4e-e327-51ff-95ce-136897f4ecf2|Compressed Row Storage (CRS) Format|The authors propose using the Compressed Row Storage (CRS) format to store and communicate matrix blocks.
7ad61583-378a-5049-99f2-c0571c855770|Bulk Deletion and Local Exploration|This solution addresses the challenge of efficient graph dynamics processing by proposing a greedy algorithm that uses bulk deletion and local exploration to quickly find the closest truss community in the local neighborhood of query vertices. The algorithm uses a greedy strategy to delete vertices far away from query vertices, which speeds up the pruning process and achieves quick termination while sacrificing some approximation ratio. Additionally, it uses a heuristic strategy of local exploration to quickly find the closest truss community in the local neighborhood of query vertices. The algorithm achieves a 2-approximation to the optimal solution, which is essentially matching the lower bound.
ef41d9ac-6a83-5695-8359-754fed13129f|Truss Decomposition|This solution addresses the challenge of efficient graph dynamics processing by proposing an algorithm for truss decomposition in massive networks. The algorithm uses a peeling framework to iteratively remove vertices with the minimum degree, which allows for efficient computation of trussness values and adjustment to graph topology changes. The algorithm takes O(m1.5) time and O(m+n) space, making it efficient for large graphs.
4a456d3d-cddf-5c32-be44-334289b28e30|EquiTruss Index|This solution addresses the challenge of efficient graph dynamics processing by proposing an indexing technique called EquiTruss, which represents the k-truss equivalence classes of edges in a graph. The EquiTruss index preserves the truss number and triangle connectivity across different communities, allowing for efficient query processing and community search. The EquiTruss index can be constructed in O(u,v E min(deg_G(u), deg_G(v))) time and stored in O(m) space, making it efficient for large graphs.
6158cc91-8579-53b3-a291-c854897364f6|ATindex|This solution addresses the challenge of efficient graph dynamics processing by proposing an indexing technique called ATindex, which consists of two components: structural trussness and attribute trussness. The ATindex allows for efficient detection of a small neighborhood subgraph around query vertices, which tends to be densely connected and have similar attributes. The ATindex can quickly identify a good candidate of k, d-truss to the answer, making it efficient for community search in attributed graphs.
2d779c85-1ffa-5a72-8461-7b68966a73fc|Incremental k-Truss Maintenance|This solution addresses the challenge of efficient graph dynamics processing by proposing an algorithm for incremental k-truss maintenance in evolving networks. The algorithm uses a combination of graph decomposition and random contraction to efficiently update the k-truss structure in response to edge insertions and deletions. The algorithm takes O(h*l*E) time if the first k-ECC enumeration algorithm is adopted, or O(V*t*E) time if the second one is used, where h and l are bounded by small constants for real graphs, and t=O(log2(V)).
d190ba35-3d46-5aea-a533-62287f15f375|Mixed Structure-Based Truss Maintenance|This solution addresses the challenge of efficient graph dynamics processing by proposing a novel approach to truss maintenance in fully dynamic graphs. The authors introduce the concept of a 
e493371e-11a7-50e1-a2aa-90d480d77671|Parallelized Truss Maintenance Algorithm|The authors propose a parallelized truss maintenance algorithm to optimize communication efficiency in distributed algorithms. This solution specifically addresses the challenge by allowing multiple edges to be processed simultaneously, reducing the number of communication rounds required.
b8e62987-a520-5dd9-95ba-ce558f4a2f6c|2D Partitioning for BFS|The authors propose a 2D partitioning approach for Breadth-First Search (BFS) to efficiently process large-scale graphs. This solution specifically addresses the challenge of efficient graph dynamics processing by reducing the computational costs and iterations required for BFS.
b2e6b4ca-0c60-5f85-96bd-4340aec30270|Hybrid Parallel BFS with Vertex Partitioning|The authors propose a hybrid parallel BFS approach that combines vertex partitioning with shared-memory traversal parallelism. This solution specifically addresses the challenge of efficient graph dynamics processing by minimizing the computational costs and iterations required for BFS.
57896132-383f-549a-a545-11da680a7bdb|2D Distributed Graph Partitioning|The authors propose a 2D distributed graph partitioning approach to optimize communication efficiency in distributed algorithms. This method involves partitioning the graph into smaller subgraphs and distributing them across multiple processors, reducing the need for inter-processor communication.
9720583b-5daf-5d18-b464-1a8647704055|Hybrid Parallel BFS Algorithm|The authors propose a hybrid parallel BFS algorithm that combines the benefits of 1D and 2D partitioning approaches. This algorithm uses a 1D partitioning approach for the initial stages of the BFS traversal and switches to a 2D partitioning approach for the later stages.
c0d5a425-7168-5088-b2de-29ace2e2bbd9|2D Vector Distribution|The authors propose a 2D vector distribution approach to optimize load balance in distributed systems. This method involves distributing the vertices and edges of a graph among processors in a two-dimensional manner, allowing each processor to have approximately the same number of vertices. This approach aims to mitigate the load imbalance issue by ensuring that each processor has a similar workload.
c1b66cc7-adc8-53b0-97ec-5e25db18cc4f|Random Shuffling of Vertex Identifiers|The authors propose a simple yet effective method to optimize load balance by randomly shuffling the vertex identifiers prior to partitioning the graph. This approach aims to reduce the likelihood of load imbalance by ensuring that each processor has a similar workload.
b247b6bd-4b3e-5470-8f24-173fda6ddab1|Parallel Dendrogram Algorithm|The authors propose a parallel dendrogram algorithm to efficiently process dynamic updates in large graphs. This algorithm is designed to minimize computational costs and iterations by leveraging parallel processing techniques.
41092733-5fac-5fa8-ba84-83fb52ec15a5|MemoGFK Optimization|The authors propose a memory optimization technique called MemoGFK to reduce the space usage and improve the running time of their EMST algorithm. This technique is designed to minimize the number of well-separated pairs generated during the algorithm's execution.
de00136b-6318-5009-9a79-500b90c603be|Parallel HDBSCAN Algorithm|The authors propose a parallel HDBSCAN algorithm to efficiently process dynamic updates in large graphs. This algorithm is designed to minimize computational costs and iterations by leveraging parallel processing techniques.
ed841343-d7b2-5add-aef3-341754de52a7|Parallel WSPD Construction|The authors propose a parallel algorithm for constructing the Well-Separated Pair Decomposition (WSPD), which is a crucial step in computing the EMST and HDBSCAN. The parallel algorithm uses a d-tree to partition the points and recursively constructs the WSPD in parallel.
f5025f93-4ce5-5049-9dd5-f16c1357d688|New Definition of Well Separation|The authors propose a new definition of well separation that includes the mutual unreachability of points, in addition to the geometric separation. This new definition allows for earlier termination of the WSPD construction and reduces the number of pairs generated.
9ff4a4af-d06b-5656-99b2-0d1c32240ec3|Parallel Dendrogram Construction|The authors propose a parallel algorithm for constructing the dendrogram, which is a crucial step in computing the HDBSCAN. The parallel algorithm uses a d-tree to partition the points and recursively constructs the dendrogram in parallel.
223435b3-6ecc-5d73-9618-1469f1feff17|Parallel GFK Algorithm|The parallel GFK algorithm is a parallelization of the GFK algorithm for EMST and HDBSCAN. It uses Kruskal's MST algorithm as a subroutine and passes batches of edges to it, where each batch has edges with weights no less than those in the previous batch.
5aa82bee-7813-50cf-9bbd-d5d4c5f8147b|On-Chip Sorting with RMA (OCS RMA)|OCS RMA is a novel on-chip sorting algorithm designed to optimize GPU memory access for graph processing. It leverages the Remote Memory Access (RMA) mechanism to enable efficient sorting of random messages into buckets. OCS RMA utilizes the RMA mechanism to send batched messages from producers and consumers, allowing for efficient sorting and minimizing memory access overhead. The algorithm divides cores into producers and consumers, with each consumer responsible for a group of buckets. This approach enables OCS RMA to achieve high memory bandwidth utilization and outperform existing on-chip sorting algorithms. OCS RMA achieves 47.0% memory bandwidth utilization, outperforming the previous on-chip sorting algorithm on SW26010, which had a utilization of 33.7%. This results in a significant improvement in graph processing performance.
16f96279-c7de-56ea-98fe-cb7ecd571919|3-Level Degree-Aware 1.5D Graph Partitioning|This solution addresses the challenge of efficient graph dynamics processing by proposing a novel graph partitioning method that divides vertices into three levels of degree. The method delegates extremely heavy vertices globally, heavy vertices on columns and rows, and light vertices on individual processes, reducing communication and load imbalance.
5d8637b6-029d-5415-a91d-a2b45e4c4226|Sub-Iteration Direction Optimization|This solution addresses the challenge of efficient graph dynamics processing by proposing a direction optimization technique that applies different directions to different degree-aware subgraphs. It allows for efficient visitation of heavy vertices in early iterations while preventing unnecessary visits from light vertices in late iterations.
a1d90420-b249-58ce-9cd2-629cc8d38d0f|CG-Aware Core Subgraph Segmenting|This solution addresses the challenge of efficient graph dynamics processing by proposing a core subgraph segmenting technique that divides the core subgraph into six segments and processes them in parallel. It reduces the time consumption of pulling the core subgraph and improves the overall performance.
dd416a32-85b0-5f14-a88c-db04dd506b58|On-Chip Sorting with RMA|This solution addresses the challenge of efficient graph dynamics processing by proposing an on-chip sorting technique that utilizes RMA to sort messages by destination. It reduces the time consumption of messaging and improves the overall performance.
ffabec79-026b-5db8-9668-b39eaf32f00b|Edge-Aware Vertex Cut Load Balancing|This solution addresses the challenge of optimizing load balance in distributed systems by proposing an edge-aware vertex cut load balancing method. This method calculates the prefix sum of locally available frontier vertices' degree at each EH2EH top-down traversal and divides the frontier by accumulated degrees, generating a balanced workload for each CPE.
86969c2a-b42d-5730-a9a8-bb65af241dd4|Vertex Marking Functional Block (VMFB)|The VMFB is a novel functional block-based approach that breaks down complex graph processing functions into simpler, similar blocks to reduce redundant computation and optimize GPU memory access. The VMFB allocates parallel CUDA threads for each element of the operand array, allowing each thread to perform a user-defined function and alter flag values in a shared array. This approach minimizes the use of atomic operations, reducing synchronization overhead and promoting coalesced memory access. The paper demonstrates that the VMFB-based implementation achieves up to 5.6x speedup compared to the Gunrock SSSP implementation on static networks.
df315d7c-1420-56f0-a237-d354b319cbbb|Compressed Sparse Row (CSR) Data Structure|The CSR data structure is used to store input graphs, allowing for efficient memory access and reducing memory bandwidth usage. The CSR format stores the graph in a compressed manner, reducing memory usage and enabling faster memory access. This approach is particularly effective for sparse graphs, which are common in large-scale graph processing applications. The paper does not provide specific results for the CSR data structure, but it is mentioned as a suitable data structure for storing input graphs.
aa40b499-e356-5db5-b336-e0ffb3240ab7|Iterative Vertex Marking Functional Block (VMFB) Approach|The authors propose an iterative VMFB approach to efficiently update the Single Source Shortest Path (SSSP) in large-scale dynamic networks. This solution specifically addresses the challenge of efficient graph dynamics processing by identifying the subgraphs affected by changes and updating only these subgraphs.
ddf0c596-5d03-5823-9485-eecbb35e768a|Asynchronous Update of SSSP|The authors propose an asynchronous update of SSSP to reduce synchronization overhead. This solution specifically addresses the challenge of efficient graph dynamics processing by allowing threads to synchronize less frequently.
8150d76b-412b-54bf-aa5b-7c76b0c5f2d6|Batch Processing of Changed Edges|The authors propose batch processing of changed edges to improve performance. This solution specifically addresses the challenge of efficient graph dynamics processing by processing changed edges in batches.
d522cead-7211-5920-b465-2db3285bfed4|Shared Memory Implementation|The authors propose a shared memory implementation to efficiently update SSSP in large-scale dynamic networks. This solution specifically addresses the challenge of efficient graph dynamics processing by leveraging shared memory parallelism.
a1adb038-6ac1-5532-b41c-971705ba6c3b|GPU Implementation|The authors propose a GPU implementation to efficiently update SSSP in large-scale dynamic networks. This solution specifically addresses the challenge of efficient graph dynamics processing by leveraging GPU parallelism.
fd7a4391-40d8-506b-88e3-e44e819faa17|Dynamic Scheduling|The authors propose a dynamic scheduling approach to optimize load balance in distributed systems. This approach involves processing changed edges in batches to improve load balancing and avoid memory hotspots.
4df6b6ac-5f2e-5ba1-a80e-3c3a3b78c1a3|Asynchronous Updates|The authors propose an asynchronous update approach to optimize load balance in distributed systems. This approach involves allowing threads to synchronize less frequently, reducing the overhead of synchronization constructs.
298ce0f9-e00c-5724-9c38-b12d9325cead|Color Selection Mechanism|The authors propose a color selection mechanism that allows each vertex to choose a color based on its degree and the degrees of its neighbors. This mechanism is designed to minimize the number of colors used while ensuring that no two adjacent vertices have the same color.
daf89092-9a9a-5b91-bf15-abf3f37da33d|Conflict Resolution Mechanism|The authors propose a conflict resolution mechanism that allows vertices to resolve conflicts by recomputing their orders within the set of neighboring vertices that have the same color.
8813e08a-6f36-598e-884d-548341b95fd4|Message Reduction Mechanism|The authors propose a message reduction mechanism that reduces the number of messages sent between vertices by only sending messages when necessary.
8d308d82-8cff-5983-a671-d3112fb0bc3b|Local Smallest Largest Degree First Algorithm|This solution proposes a distributed graph coloring algorithm that efficiently processes dynamic updates in large graphs by minimizing computational costs and iterations. The algorithm works by selecting the smallest and largest degree vertices in each superstep and coloring them with different colors, ensuring that no two adjacent vertices have the same color. The algorithm uses a greedy approach with a focus on vertex degree, which is different from existing approaches that rely on random numbers or vertex IDs. The use of vertex degree allows for more efficient coloring and reduces the number of iterations required. The paper presents experimental results showing that the Local Smallest Largest Degree First algorithm outperforms other heuristic-based algorithms in terms of runtime and number of colors used.
30effe25-75cb-5220-809e-5e6818a3bd7c|Local Largest Degree First Algorithm|This solution proposes a distributed graph coloring algorithm that efficiently processes dynamic updates in large graphs by minimizing computational costs and iterations. The algorithm works by selecting the largest degree vertices in each superstep and coloring them, ensuring that no two adjacent vertices have the same color. The algorithm uses a greedy approach with a focus on vertex degree, which is different from existing approaches that rely on random numbers or vertex IDs. The use of vertex degree allows for more efficient coloring and reduces the number of iterations required. The paper presents experimental results showing that the Local Largest Degree First algorithm performs better than other heuristic-based algorithms in terms of number of colors used, but takes more computation time.
8c458932-8ee0-5b09-b901-5f93cb98dee0|Local Minima Maxima First Algorithm|This solution proposes a distributed graph coloring algorithm that efficiently processes dynamic updates in large graphs by minimizing computational costs and iterations. The algorithm works by selecting the minimum and maximum degree vertices in each superstep and coloring them with different colors, ensuring that no two adjacent vertices have the same color. The algorithm uses a greedy approach with a focus on vertex degree, which is different from existing approaches that rely on random numbers or vertex IDs. The use of vertex degree allows for more efficient coloring and reduces the number of iterations required. The paper presents experimental results showing that the Local Minima Maxima First algorithm performs better than the Local Maxima First algorithm in terms of runtime, but uses a similar number of colors.
97e0b522-6b48-5ccf-a3c6-6fa7c7745609|Local Maxima First Algorithm|This solution proposes a distributed graph coloring algorithm that efficiently processes dynamic updates in large graphs by minimizing computational costs and iterations. The algorithm works by selecting the maximum degree vertices in each superstep and coloring them, ensuring that no two adjacent vertices have the same color. The algorithm uses a greedy approach with a focus on vertex degree, which is different from existing approaches that rely on random numbers or vertex IDs. The use of vertex degree allows for more efficient coloring and reduces the number of iterations required. The paper presents experimental results showing that the Local Maxima First algorithm performs poorly in terms of runtime and number of colors used compared to other heuristic-based algorithms.
5a24d746-1f64-55aa-8538-772369c63a57|2D Parallel Triangle Counting Algorithm|The authors propose a 2D parallel triangle counting algorithm for distributed memory architectures, which utilizes a 2D cyclic decomposition to balance computations and reduce communication overheads. This algorithm is designed to efficiently process large graphs in a distributed memory setting.
dffd07b7-1934-5b63-b35f-c50984000aa6|2D Cyclic Distribution of Adjacency Matrix|The authors propose a 2D cyclic distribution of the adjacency matrix to balance the computations and reduce the communication overheads. This approach structures the communication and computational steps to minimize memory overhead and leverage the sparsity of the graph.
6ed575ec-d66e-50ea-85ea-b7d3b1746134|Doubly Compressed Sparse Row (CSR) Structure|The authors use a doubly compressed sparse row structure to store the task matrix and the upper and lower triangular portions of the adjacency matrix. This approach reduces memory overhead and improves the efficiency of the set intersection operations.
5069ed0f-7b76-5335-952c-d0e8d767fcd8|Modifying Hashing Routine for Sparser Vertices|The authors modify the hashing routine to optimize the set intersection operations for sparser vertices. This approach reduces the number of unnecessary intersection operations and improves the overall efficiency of the algorithm.
7be4abb4-7de3-5286-9d42-913749af97aa|Reducing Overheads Associated with Communication|The authors reduce the overheads associated with communication by allocating memory for the adjacency lists and using a sequence of communication steps similar to those used by Cannon’s parallel matrix-matrix multiplication algorithm.
91426f79-8d87-5794-801b-c0abaaf4c1b5|2D Cyclic Distribution of C|The authors propose a 2D cyclic distribution of the task matrix C to balance the load among processors. This approach ensures that each processor has a similar number of non-zero tasks and a similar number of light and heavy tasks, reducing load imbalance.
84a07c43-c798-5f81-a61c-aa27cf3c7e41|Modifying the Hashing Routine for Sparser Vertices|The authors propose modifying the hashing routine to optimize the set intersection operation for sparser vertices. This approach reduces the number of unnecessary intersection operations and improves the overall performance.
47215345-2eb1-543e-b70a-0604e6f1be1c|PECO (Parallel Enumeration of Cliques using Ordering)|PECO is a parallel algorithm designed to efficiently enumerate maximal cliques in large graphs using the MapReduce framework. It addresses the challenge of efficient graph dynamics processing by utilizing a total ordering of vertices to eliminate redundant work and improve load balancing among processors.
70599828-2b87-5e5a-b099-f2693e6aa048|Vertex Ordering for Reduced Communication|The authors propose a solution that involves ordering the vertices in the graph to reduce the communication cost. Specifically, they use a vertex ordering that minimizes the number of edges that need to be transmitted between nodes.
4bce23e3-a2be-5802-97c0-7612f50fd54a|Subgraph Division for Load Balancing|The authors propose a solution that involves dividing the graph into subgraphs to achieve load balancing. Specifically, they divide the graph into subgraphs Gv, where each subgraph is induced by a vertex v and its neighbors.
aa13faef-30d0-52c1-8dbb-27d51588a259|Modified Tomita Algorithm for Reduced Redundant Work|The authors propose a solution that involves modifying the Tomita algorithm to reduce redundant work among nodes. Specifically, they add the entire set of vertices in Lv to the Fini set, which allows them to avoid searching for maximal cliques that contain a vertex from Lv.
327aa7ba-9b73-5865-87d9-04447ebb6476|PECO - Parallel Enumeration of Cliques using Ordering|PECO is a parallel algorithm designed to optimize load balance in distributed systems by utilizing a carefully chosen total ordering among all vertices in the graph. This ordering is used to eliminate redundant work among processors and to improve load balancing.
cfd007c9-b0a8-5426-b048-daeecb7f689b|Degree Ordering|Degree ordering is a technique used in PECO to optimize load balance by ordering vertices based on their degree. This approach helps to improve load balancing by assigning vertices with higher degrees to reduce tasks earlier.
70b7357e-48f5-5e0f-8530-bf146d53f812|Triangle Ordering|Triangle ordering is a technique used in PECO to optimize load balance by ordering vertices based on the number of triangles they are part of. This approach helps to improve load balancing by assigning vertices that are part of more triangles to reduce tasks earlier.
f1e491bc-6e72-5c88-9209-c44a7c6b221d|Subgraph Rank Algorithm|The Subgraph Rank algorithm is a novel approach to efficiently process graph dynamics by leveraging subgraph-centric programming abstractions. This algorithm is specifically designed to address the challenge of efficient graph dynamics processing by minimizing computational costs and iterations. The Subgraph Rank algorithm works by first computing local PageRank values for each subgraph, followed by a BlockRank phase that estimates the relative importance of each subgraph. The algorithm then combines these values to obtain the final PageRank values. This approach reduces the number of iterations required to maintain graph structures and centrality measures, making it more efficient than traditional PageRank algorithms. The unique mechanism involved in the Subgraph Rank algorithm is its use of subgraph-centric programming abstractions, which allows for more efficient processing of graph dynamics. This approach is different from existing approaches that rely on vertex-centric or edge-centric processing. Results: The paper presents experimental results that demonstrate the effectiveness of the Subgraph Rank algorithm. For example, the algorithm shows a performance gain of 23-74% for equivalent PageRank quality on various graphs, and it successfully exploits the subgraph structure of the graph to offer high-quality initial PageRank values.
668cac6f-b517-5fb9-8a16-b984d8cba650|BlockRank Algorithm Variations|The paper proposes variations of the BlockRank algorithm, including BlockRank with PageRank-like distribution logic (BRDL), BlockRank with SG by G initialization vector (BRIV), and BlockRank with PageRank-like distribution logic and SG by G initialization vector (BRDI). These variations aim to improve the performance of the BlockRank algorithm by leveraging subgraph-centric programming abstractions. The BlockRank algorithm variations work by modifying the initialization vector and distribution logic of the BlockRank algorithm to better suit subgraph-centric processing. These variations reduce the number of iterations required to maintain graph structures and centrality measures, making them more efficient than traditional BlockRank algorithms. The unique mechanism involved in the BlockRank algorithm variations is their use of subgraph-centric programming abstractions, which allows for more efficient processing of graph dynamics. This approach is different from existing approaches that rely on vertex-centric or edge-centric processing. Results: The paper presents experimental results that demonstrate the effectiveness of the BlockRank algorithm variations. For example, the BRDL variation shows a performance gain of 23-74% for equivalent PageRank quality on various graphs, and it successfully exploits the subgraph structure of the graph to offer high-quality initial PageRank values.
290b2126-466b-51b6-8cd8-94f591f1e833|Subgraph Rank (SGRK) Algorithm|The SGRK algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms. It leverages the subgraph structure of the graph to reduce the number of communication rounds required for PageRank computation.
6b0a5880-fd01-5c62-9612-c1cca03afecf|BlockRank with PageRank-like Distribution Logic and SG by G Initialization Vector (BRDI)|The BRDI algorithm is a variant of the BlockRank algorithm that uses a PageRank-like distribution logic and an SG by G initialization vector. This algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms.
089af030-e356-567f-ad7f-04563ceaa746|BlockRank with SG by G Initialization Vector (BRIV)|The BRIV algorithm is a variant of the BlockRank algorithm that uses an SG by G initialization vector. This algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms.
374e736d-832e-5bab-beb9-16122349dd50|BlockRank with PageRank-like Distribution Logic (BRDL)|The BRDL algorithm is a variant of the BlockRank algorithm that uses a PageRank-like distribution logic. This algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms.
08537aa2-f314-5689-a749-2cd4da9cf364|BlockRank with Native Distribution Logic (BRNA)|The BRNA algorithm is a variant of the BlockRank algorithm that uses a native distribution logic. This algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms.
8b5f9e21-3448-584a-a036-818b3fc83c59|BlockRank with No Initialization Vector (BRNO)|The BRNO algorithm is a variant of the BlockRank algorithm that does not use an initialization vector. This algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms.
08129ffa-e3d1-595d-8bf5-a7dd7f5fd28a|BlockRank with PageRank-like Distribution Logic and No Initialization Vector (BRDI_NO_IV)|The BRDI_NO_IV algorithm is a variant of the BlockRank algorithm that uses a PageRank-like distribution logic and does not use an initialization vector. This algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms.
5ca6a463-4dc9-5da6-8ec3-c6138150578d|BlockRank with SG by G Initialization Vector and No Initialization Vector (BRIV_NO_IV)|The BRIV_NO_IV algorithm is a variant of the BlockRank algorithm that uses an SG by G initialization vector and does not use an initialization vector. This algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms.
5296894b-7d3f-56b0-80b1-b4e475ca5423|BlockRank with PageRank-like Distribution Logic and SG by G Initialization Vector and No Initialization Vector (BRDI_BRIV_NO_IV)|The BRDI_BRIV_NO_IV algorithm is a variant of the BlockRank algorithm that uses a PageRank-like distribution logic, an SG by G initialization vector, and does not use an initialization vector. This algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms.
3333ae10-b32d-59d6-80d4-55a339e8bb21|Subgraph Centric PageRank (SGPR) Algorithm|The SGPR algorithm is a variant of the PageRank algorithm that uses a subgraph centric approach. This algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms.
14fa067c-1b2c-547c-8c90-0bb67c43e297|BlockRank Algorithm|The BlockRank algorithm is a variant of the PageRank algorithm that uses a block-based approach. This algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms.
c23af882-c830-591b-b120-86c4b97d3a13|PageRank Algorithm|The PageRank algorithm is a variant of the PageRank algorithm that uses a traditional approach. This algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms.
0416d552-b7ff-5ca9-af44-5017ce1c6132|Local PageRank (LPR) Algorithm|The LPR algorithm is a variant of the PageRank algorithm that uses a local approach. This algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms.
024631e6-4179-53e3-b72d-a99ef10b2e86|Global PageRank (GPR) Algorithm|The GPR algorithm is a variant of the PageRank algorithm that uses a global approach. This algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms.
0d3c6c64-c8eb-558a-ab2b-9f1ce1d99a54|Subgraph Centric BlockRank (SCBR) Algorithm|The SCBR algorithm is a variant of the BlockRank algorithm that uses a subgraph centric approach. This algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms.
e5d0fae2-ac4e-5cd0-8e84-a51debfdaade|Subgraph Centric Local PageRank (SCLPR) Algorithm|The SCLPR algorithm is a variant of the Local PageRank algorithm that uses a subgraph centric approach. This algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms.
f7f28433-3e94-5920-a303-4991f527045a|Subgraph Centric Global PageRank (SCGPR) Algorithm|The SCGPR algorithm is a variant of the Global PageRank algorithm that uses a subgraph centric approach. This algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms.
6aa184ce-a16c-5bc7-b0b4-803444d32fb0|Subgraph Centric BlockRank with PageRank-like Distribution Logic (SCBRDL) Algorithm|The SCBRDL algorithm is a variant of the BlockRank algorithm that uses a subgraph centric approach and a PageRank-like distribution logic. This algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms.
512ed015-a88b-5623-a0aa-bd02083b1b0d|Subgraph Centric BlockRank with SG by G Initialization Vector (SCBRIV) Algorithm|The SCBRIV algorithm is a variant of the BlockRank algorithm that uses a subgraph centric approach and an SG by G initialization vector. This algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms.
c45b83a7-abf3-52cb-9c70-355031c0c799|Subgraph Centric BlockRank with PageRank-like Distribution Logic and SG by G Initialization Vector (SCBRDLIV) Algorithm|The SCBRDLIV algorithm is a variant of the BlockRank algorithm that uses a subgraph centric approach, a PageRank-like distribution logic, and an SG by G initialization vector. This algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms.
57949991-b4eb-5725-9d54-c0b95048d6aa|Subgraph Centric BlockRank with PageRank-like Distribution Logic and No Initialization Vector (SCBRDL_NO_IV) Algorithm|The SCBRDL_NO_IV algorithm is a variant of the BlockRank algorithm that uses a subgraph centric approach, a PageRank-like distribution logic, and does not use an initialization vector. This algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms.
9839fc17-8fc6-5648-bc73-5418b1c7fe7a|Subgraph Centric BlockRank with SG by G Initialization Vector and No Initialization Vector (SCBRIV_NO_IV) Algorithm|The SCBRIV_NO_IV algorithm is a variant of the BlockRank algorithm that uses a subgraph centric approach, an SG by G initialization vector, and does not use an initialization vector. This algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms.
3985058c-45f2-5f7b-a061-d69ef18c376d|Subgraph Centric BlockRank with PageRank-like Distribution Logic and SG by G Initialization Vector and No Initialization Vector (SCBRDLIV_NO_IV) Algorithm|The SCBRDLIV_NO_IV algorithm is a variant of the BlockRank algorithm that uses a subgraph centric approach, a PageRank-like distribution logic, an SG by G initialization vector, and does not use an initialization vector. This algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms.
7317ca70-d49f-5f05-8962-853cce4a19e4|Subgraph Centric PageRank with PageRank-like Distribution Logic (SCPRDL) Algorithm|The SCPRDL algorithm is a variant of the PageRank algorithm that uses a subgraph centric approach and a PageRank-like distribution logic. This algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms.
d1cbb3b0-c668-5f34-9bc6-ae5047da1654|Subgraph Centric PageRank with SG by G Initialization Vector (SCPRIV) Algorithm|The SCPRIV algorithm is a variant of the PageRank algorithm that uses a subgraph centric approach and an SG by G initialization vector. This algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms.
db3b0950-c167-5537-95b4-0cf2810bb502|Subgraph Centric PageRank with PageRank-like Distribution Logic and SG by G Initialization Vector (SCPRDLIV) Algorithm|The SCPRDLIV algorithm is a variant of the PageRank algorithm that uses a subgraph centric approach, a PageRank-like distribution logic, and an SG by G initialization vector. This algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms.
75e3c9d3-6726-5ff7-ac56-c08dbf09c4ae|Subgraph Centric PageRank with PageRank-like Distribution Logic and No Initialization Vector (SCPRDL_NO_IV) Algorithm|The SCPRDL_NO_IV algorithm is a variant of the PageRank algorithm that uses a subgraph centric approach, a PageRank-like distribution logic, and does not use an initialization vector. This algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms.
48567d7d-7743-5cf1-b326-532255dc6e4a|Subgraph Centric PageRank with SG by G Initialization Vector and No Initialization Vector (SCPRIV_NO_IV) Algorithm|The SCPRIV_NO_IV algorithm is a variant of the PageRank algorithm that uses a subgraph centric approach, an SG by G initialization vector, and does not use an initialization vector. This algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms.
5329dab2-c1e0-545f-a05c-db4f946756af|Subgraph Centric PageRank with PageRank-like Distribution Logic and SG by G Initialization Vector and No Initialization Vector (SCPRDLIV_NO_IV) Algorithm|The SCPRDLIV_NO_IV algorithm is a variant of the PageRank algorithm that uses a subgraph centric approach, a PageRank-like distribution logic, an SG by G initialization vector, and does not use an initialization vector. This algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms.
81441ddf-f6e4-5c05-a187-b7645958b922|Subgraph Centric Local PageRank with PageRank-like Distribution Logic (SCLPRDL) Algorithm|The SCLPRDL algorithm is a variant of the Local PageRank algorithm that uses a subgraph centric approach and a PageRank-like distribution logic. This algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms.
8cef123e-8fa1-556c-b37a-46af2c00d840|Subgraph Centric Local PageRank with SG by G Initialization Vector (SCLPRIV) Algorithm|The SCLPRIV algorithm is a variant of the Local PageRank algorithm that uses a subgraph centric approach and an SG by G initialization vector. This algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms.
41afdc51-7512-57ac-be5d-090f41185b01|Subgraph Centric Local PageRank with PageRank-like Distribution Logic and SG by G Initialization Vector (SCLPRDLIV) Algorithm|The SCLPRDLIV algorithm is a variant of the Local PageRank algorithm that uses a subgraph centric approach, a PageRank-like distribution logic, and an SG by G initialization vector. This algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms.
a4b2a65c-c11f-54d3-b75c-e08c35cc79b2|Subgraph Centric Local PageRank with PageRank-like Distribution Logic and No Initialization Vector (SCLPRDL_NO_IV) Algorithm|The SCLPRDL_NO_IV algorithm is a variant of the Local PageRank algorithm that uses a subgraph centric approach, a PageRank-like distribution logic, and does not use an initialization vector. This algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms.
975d68f3-314d-546e-a11e-52d5cb6dde74|Subgraph Centric Local PageRank with SG by G Initialization Vector and No Initialization Vector (SCLPRIV_NO_IV) Algorithm|The SCLPRIV_NO_IV algorithm is a variant of the Local PageRank algorithm that uses a subgraph centric approach, an SG by G initialization vector, and does not use an initialization vector. This algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms.
c23bead2-1a84-5323-9f7b-20380547c7e2|Subgraph Centric Local PageRank with PageRank-like Distribution Logic and SG by G Initialization Vector and No Initialization Vector (SCLPRDLIV_NO_IV) Algorithm|The SCLPRDLIV_NO_IV algorithm is a variant of the Local PageRank algorithm that uses a subgraph centric approach, a PageRank-like distribution logic, an SG by G initialization vector, and does not use an initialization vector. This algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms.
36e93050-f7b7-50db-9bd3-d2c9b3c7df6d|Subgraph Centric Global PageRank with PageRank-like Distribution Logic (SCGPRDL) Algorithm|The SCGPRDL algorithm is a variant of the Global PageRank algorithm that uses a subgraph centric approach and a PageRank-like distribution logic. This algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms.
5e6f666d-78f1-5f49-8f43-f6e67969a5de|Subgraph Centric Global PageRank with SG by G Initialization Vector (SCGPRIV) Algorithm|The SCGPRIV algorithm is a variant of the Global PageRank algorithm that uses a subgraph centric approach and an SG by G initialization vector. This algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms.
6aa06394-7cd6-56ed-910b-024d0b6213f8|Subgraph Centric Global PageRank with PageRank-like Distribution Logic and SG by G Initialization Vector (SCGPRDLIV) Algorithm|The SCGPRDLIV algorithm is a variant of the Global PageRank algorithm that uses a subgraph centric approach, a PageRank-like distribution logic, and an SG by G initialization vector. This algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms.
704d7f1d-a294-5a1a-9d61-516625b3bdb9|Subgraph Centric Global PageRank with PageRank-like Distribution Logic and No Initialization Vector (SCGPRDL_NO_IV) Algorithm|The SCGPRDL_NO_IV algorithm is a variant of the Global PageRank algorithm that uses a subgraph centric approach, a PageRank-like distribution logic, and does not use an initialization vector. This algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms.
50d0852f-c9fd-51a2-885d-5674a9352f8a|Subgraph Centric Global PageRank with SG by G Initialization Vector and No Initialization Vector (SCGPRIV_NO_IV) Algorithm|The SCGPRIV_NO_IV algorithm is a variant of the Global PageRank algorithm that uses a subgraph centric approach, an SG by G initialization vector, and does not use an initialization vector. This algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms.
4580b0a1-123a-5976-b290-b66963259b11|Subgraph Centric Global PageRank with PageRank-like Distribution Logic and SG by G Initialization Vector and No Initialization Vector (SCGPRDLIV_NO_IV) Algorithm|The SCGPRDLIV_NO_IV algorithm is a variant of the Global PageRank algorithm that uses a subgraph centric approach, a PageRank-like distribution logic, an SG by G initialization vector, and does not use an initialization vector. This algorithm is proposed as a solution to optimize communication efficiency in distributed algorithms.
c3b6cf69-1e86-507e-8e6a-594f280aca0b|BlockRank with No BlockRank Phase (BRNO)|The BRNO solution modifies the native BlockRank algorithm to skip the BlockRank phase, aiming to improve the load balance by reducing the number of supersteps required for convergence.
aee9fd6e-909a-58a9-a56a-11fbc826d614|Tight Simulation|Tight simulation is a novel graph simulation model that optimizes communication efficiency in distributed algorithms by reducing the number of balls created during the simulation process. This solution specifically addresses the challenge of optimizing communication efficiency by minimizing the number of communication rounds required for ball creation.
3683ac8c-70ad-5a95-a722-0d196503dd5c|Distributed Dual Simulation|Distributed dual simulation is a distributed algorithm that optimizes communication efficiency by reducing the number of messages exchanged between vertices during the simulation process. This solution specifically addresses the challenge of optimizing communication efficiency by minimizing the number of communication rounds required for evaluating parent relationships.
232c2e51-0fb6-584a-b881-07f4e396737e|Vertex-Centric Distributed Algorithm|Vertex-centric distributed algorithm is a distributed algorithm that optimizes communication efficiency by reducing the number of communication rounds required for graph simulation. This solution specifically addresses the challenge of optimizing communication efficiency by minimizing the number of communication rounds required for evaluating child relationships.
e72e1995-e0ac-509f-add4-c0bfb21c67c8|FastSV Algorithm|The FastSV algorithm is a distributed memory algorithm designed to efficiently find connected components in an undirected graph. It simplifies the classic Shiloach-Vishkin algorithm and employs novel hooking strategies for faster convergence.
f4966039-c18f-51d5-b6da-87fff3e0286c|Optimized MPI Communication|The authors propose an optimized MPI communication approach to minimize communication bottlenecks in the distributed implementation of the FastSV algorithm. This solution specifically addresses the challenge of optimizing communication efficiency in distributed algorithms by reducing the number of communication rounds and improving overall efficiency.
5240adfd-2917-539c-aeaf-b205bdff2a13|Sparsity-Aware Matrix-Vector Multiplication|The authors propose a sparsity-aware matrix-vector multiplication approach to reduce the computational cost of the FastSV algorithm. This solution specifically addresses the challenge of optimizing communication efficiency in distributed algorithms by minimizing the number of communication rounds and improving overall efficiency.
e4bc19a5-286a-593a-92c9-fffbc7b54183|Early Termination|The authors propose an early termination approach to reduce the number of iterations in the FastSV algorithm. This solution specifically addresses the challenge of optimizing communication efficiency in distributed algorithms by minimizing the number of communication rounds and improving overall efficiency.
105885ed-aa9e-5bbb-876d-99235c77be11|Sparsity-based Optimization for Load Balancing|The authors propose using sparsity to optimize load balancing in distributed systems. They observe that in the last few iterations of the algorithm, only a small fraction of vertices participate in the computation, and thus, using sparse matrix-sparse vector multiplication (SpMSpV) instead of sparse matrix-dense vector multiplication (SpMV) can significantly reduce the computation and communication cost.
b812bdf5-a348-58b4-8150-d88d7759a470|Broadcasting-based Implementation for Load Balancing|The authors propose a broadcasting-based implementation for the extract and assign operations to optimize load balancing in distributed systems. They observe that these operations may cause a load balancing issue when there is too much access on a few locations, and thus, using a broadcasting-based approach can help alleviate this issue.
52f749d5-8838-5228-a712-95030386be44|Distributed Vertex Hashing TRI ST IMPR (DVHT i)|DVHT i is a distributed algorithm designed to efficiently process graph dynamics by utilizing a vertex hashing technique to distribute edges across multiple workers. This approach enables the algorithm to adapt to dynamic graph updates while minimizing computational costs and iterations.
96707817-cc1a-5a0f-8a4f-d391fa8430e4|Distributed Edge Hashing TRI ST BASE (DEHT b)|DEHT b is a distributed algorithm that utilizes an edge hashing technique to efficiently process graph dynamics. This approach enables the algorithm to minimize computational costs and iterations by optimizing edge distribution across multiple workers.
c04d6f12-b8aa-59fc-a8ac-899b5a4cc4c3|Distributed Edge Hashing TRI ST IMPR (DEHT i)|DEHT i is a distributed algorithm designed to efficiently process graph dynamics by utilizing an edge hashing technique to distribute edges across multiple workers. This approach enables the algorithm to adapt to dynamic graph updates while minimizing computational costs and iterations.
4eb70636-f427-5ece-ab5c-6fba457d6db0|Master Worker Aggregator Architecture|The Master Worker Aggregator Architecture is a distributed framework designed to efficiently process graph dynamics by utilizing a master node to distribute edges across multiple worker nodes. This approach enables the algorithm to adapt to dynamic graph updates while minimizing computational costs and iterations.
ef16f5b5-edaa-5bbe-8e6a-ddcaec8e5c4e|Edge Distribution Strategy|The Edge Distribution Strategy is a technique designed to efficiently distribute edges across multiple workers in a distributed graph processing system. This approach enables the algorithm to adapt to dynamic graph updates while minimizing computational costs and iterations.
6936d85e-e3a4-55b3-9052-322568bf82ab|Aggregation Method|The Aggregation Method is a technique designed to efficiently aggregate the results of multiple workers in a distributed graph processing system. This approach enables the algorithm to adapt to dynamic graph updates while minimizing computational costs and iterations.
caae8083-b495-5151-bed5-324111e512e6|Distributed Edge Hashing (DEHT) and Distributed Vertex Hashing (DVHT)|The authors propose two distributed algorithms, DEHT and DVHT, which utilize edge hashing and vertex hashing, respectively, to optimize communication efficiency in distributed triangle counting.
3c162770-edc9-5bb8-a892-9aebbed1f528|Improved Master-Worker-Aggregator Architecture|The authors propose an improved Master-Worker-Aggregator architecture with multiple masters and hierarchically grouped aggregators to further optimize communication efficiency.
08c1f669-9a41-5f37-945c-45dfe6ef1974|Adaptive Aggregation Method|The authors propose an adaptive aggregation method that dynamically adjusts the aggregation frequency based on the number of workers and the size of the sample set.
9644723b-fcd0-5fd5-8ab9-8198bcf8c157|Distributed Edge Hashing (DEH) Strategy|The authors propose a Distributed Edge Hashing (DEH) strategy to optimize load balance in distributed systems. This strategy involves using an edge hash function to map edges to workers directly, ensuring that each edge is distributed equally to workers. This approach enables good workload balance and reduces communication overhead on the master.
f7e2afae-2fec-57be-91a3-bfef4beca001|Hierarchically Grouped Aggregators (HGA) Architecture|The authors propose a Hierarchically Grouped Aggregators (HGA) architecture to optimize load balance in distributed systems. This architecture involves using multiple masters and hierarchically grouped aggregators to share the load, reducing the computation load on single master and aggregator.
81f323e9-aecd-5e70-b22d-a7db4190bb5d|Adaptive Aggregation Method (AAM)|The authors propose an Adaptive Aggregation Method (AAM) to optimize load balance in distributed systems. This method involves using a dynamic aggregation approach that adapts to different edge distribution strategies, ensuring efficient and balanced processing of edges.
b3870d9b-5a6f-521e-89a9-6be135609a32|Path-Based Holistic Detection Plan|The authors propose a path-based holistic detection plan for multiple pattern queries in distributed graph frameworks. This solution specifically addresses the challenge of optimizing GPU memory access for graph processing by designing a plan that enables cost sharing among multiple patterns in distributed graph processing frameworks. The plan is fully parallelizable, allowing each data vertex to perform necessary join operations independently during graph exploration.
0f2a96bc-76ef-5d49-87df-be572a16db7a|Query Set Aware Sink Vertex Selection|The authors propose a query set aware sink vertex selection strategy to further reduce the redundant cost in the holistic plan. This solution specifically addresses the challenge of optimizing GPU memory access for graph processing by selecting sink vertices that minimize the space reduction between union results of different queries.
edc68bb7-4635-5cbf-8b5c-8c6c522f3bdc|Rule Merging with Message Superset|The authors propose a rule merging strategy with a message superset to further reduce the redundant cost in the holistic plan. This solution specifically addresses the challenge of optimizing GPU memory access for graph processing by merging rules with message superset, which reduces the number of messages and evaluation time.
edc1e32e-1d1d-5473-88b6-1a25256f5dc8|Frequent Path Selection|The authors propose a frequent path selection strategy to select paths that can be shared by multiple queries. This solution specifically addresses the challenge of optimizing GPU memory access for graph processing by selecting paths that minimize the computation cost and maximize the sharing among queries.
b1f490a0-11c5-51bd-bd67-855e6a5d9449|Common Join Rule Sharing|The authors propose a common join rule sharing strategy to share common joins among rules. This solution specifically addresses the challenge of optimizing GPU memory access for graph processing by sharing common joins among rules, which reduces the number of joins and evaluation time.
52b65cc9-28d8-515f-9e29-06d74968d4e6|Relaxed Vertex Equivalence|The authors propose a relaxed vertex equivalence strategy, which relaxes the vertex equivalence to enable more rules to be reused.
0d3a2158-66e2-5d58-a13d-9b3458bb61fe|Query Set-Aware Sink Vertex Selection|The authors propose a query set-aware sink vertex selection strategy to optimize communication efficiency in distributed algorithms. This solution involves selecting the sink vertex for each query based on the maximum degree of the vertex, considering the query set as a whole.
fd0f0a45-3aaf-57a3-879e-3ccf10800d26|Rule Sharing with Common Join|The authors propose a rule sharing strategy with the common join to optimize load balance in distributed systems. This strategy involves sharing rules with the common join to reduce the redundant cost.
0bf46ec4-9dbc-5d5e-94d7-5ff69b993733|Distributed Graph Coloring Algorithm|"The authors propose a distributed graph coloring algorithm that efficiently colors graphs with an optimal number of colors in the LOCAL model of computation. The algorithm is designed to work for graphs with maximum degree Δ and chromatic number close to Δ. The algorithm uses a combination of techniques, including the Lovász Local Lemma, graph decomposition, and semi-random coloring. The authors also introduce the concept of ""c-reducers"" and ""hollow sets"" to reduce the graph size while preserving its colorability. The authors show that their algorithm can color graphs with maximum degree Δ and chromatic number close to Δ in O(log n log log n) rounds, which is a significant improvement over previous results."
84c9d317-3362-5fba-9b23-2f3ff968df7a|Distributed Lovász Local Lemma (DLLL)|The authors propose using the Distributed Lovász Local Lemma (DLLL) to optimize communication efficiency in distributed algorithms. Specifically, they utilize the DLLL to solve the k-coloring problem in a distributed setting. The DLLL is a distributed algorithm that uses a probabilistic approach to find a k-coloring of a graph. It works by iteratively applying a local lemma to a set of events, which are defined as the set of possible color assignments to a vertex. The algorithm uses a distributed approach to compute the probabilities of these events and to update the color assignments. The authors show that the DLLL can solve the k-coloring problem in O(log n) rounds, which is a significant improvement over previous algorithms. They also demonstrate that the DLLL can be used to solve other distributed problems, such as the maximum independent set problem.
5ad34173-0dfd-5dc0-9231-64d1fc0f265e|Deg-1 List Coloring|The authors propose using a deg-1 list coloring algorithm to optimize communication efficiency in distributed algorithms. Specifically, they utilize this algorithm to color the vertices of a graph with a limited number of colors. The deg-1 list coloring algorithm works by iteratively assigning colors to vertices based on their degree. The algorithm uses a distributed approach to compute the degree of each vertex and to update the color assignments. The authors show that the deg-1 list coloring algorithm can color a graph with a limited number of colors in O(log n) rounds. They also demonstrate that this algorithm can be used to solve other distributed problems, such as the maximum independent set problem.
074077a3-602e-59f9-b013-0c4d38cef1cc|D-Dense Decomposition|The authors propose using a d-dense decomposition algorithm to optimize communication efficiency in distributed algorithms. Specifically, they utilize this algorithm to decompose a graph into dense and sparse components. The d-dense decomposition algorithm works by iteratively identifying dense components in a graph and decomposing them into smaller subgraphs. The algorithm uses a distributed approach to compute the density of each component and to update the decomposition. The authors show that the d-dense decomposition algorithm can decompose a graph into dense and sparse components in O(1) rounds. They also demonstrate that this algorithm can be used to solve other distributed problems, such as the k-coloring problem.
504572a4-1c92-5f24-9e67-21bdeadf7d68|Local Lemma Application|The authors propose using a local lemma application to optimize communication efficiency in distributed algorithms. Specifically, they utilize this application to solve the k-coloring problem in a distributed setting. The local lemma application works by iteratively applying a local lemma to a set of events, which are defined as the set of possible color assignments to a vertex. The algorithm uses a distributed approach to compute the probabilities of these events and to update the color assignments. The authors show that the local lemma application can solve the k-coloring problem in O(log n) rounds. They also demonstrate that this application can be used to solve other distributed problems, such as the maximum independent set problem.
13341600-256f-5ad4-a52c-198183488442|Distributed Load Balancing via Randomized Coloring|This solution involves using a randomized coloring algorithm to distribute tasks across nodes in a distributed system, ensuring that each node has a balanced workload.
e3fcfebf-2607-5266-9deb-720e02d6cfa8|Buffered Distributed Memory Approach|The authors propose a buffered distributed memory approach to optimize GPU memory access for graph processing. This approach involves using a user-defined buffer size to control the amount of intermediate data generated during edge enumeration, which helps to reduce memory usage and improve performance.
fddbfead-95d9-5b55-88d9-ddb9357be12f|Bloom Filter-based Edge Query|The authors propose using Bloom Filters to optimize edge membership queries, which is a critical component of graph processing. By using Bloom Filters, the authors aim to reduce the number of edge lookups and improve memory access efficiency.
4d5a40bd-2aab-5d38-b0fa-8ae4bb59862a|Communication-Avoiding Bloom Filter Estimation|The authors propose a communication-avoiding Bloom Filter estimation approach to reduce the overall communication volume and improve memory access efficiency.
017b4d45-547f-5f66-a1f3-b058adb1b693|Bloom Filter-based Communication Avoidance|The authors propose using a Bloom Filter to reduce the overall communication volume by trading off performance with quality. This approach involves storing the remote edges in Bloom Filters and then exchanging the bit arrays of the underlying process-local Bloom Filters in a single round.
b013ee9b-3b6f-58d5-8c05-e8fe5b6ac54c|C Associative Containers|The authors propose using different C associative containers to store a partial list of edges, leading to a further 20-30 improvement in the overall execution times.
4b8dcd85-23be-5efe-ac7e-bb22f543d659|Communication-Avoiding Bloom Filter-based Estimation|The authors propose a communication-avoiding Bloom Filter-based estimation approach to reduce the overall communication volume. This approach involves storing remote edges in Bloom Filters and exchanging the bit arrays among process neighbors.
c73c51e7-fa43-5d54-921c-df12192c1152|Communication-Avoiding Bloom Filter|The authors propose a communication-avoiding Bloom Filter approach to optimize load balance in distributed systems. This approach reduces the overall communication volume by storing remote edges in Bloom Filters and exchanging the bit arrays among process neighbors.
fa0af304-4b94-547d-a980-6eab55503d97|Genetic Algorithm based on Label Propagation (GA LP)|GA LP is a local-based genetic algorithm that refines the results of the Label Propagation (LP) algorithm to detect communities in directed large-scale networks. GA LP uses a local-based strategy to propagate labels of the chosen pair of parents, and the crossover operator follows a local-based strategy to propagate the labels of the chosen pair of parents. The algorithm also uses a roulette wheel selection method for the selection process. The paper presents a comparative analysis between the results of GA LP and the state-of-the-art algorithms Infomap, LP, and Order Statistics Local Optimization Method (OSLOM). The results indicate that GA LP outperformed LP and was competitive with Infomap and OSLOM in detecting communities in dense and large networks.
f87530be-b472-51a8-8c74-c1171fd182d1|Local-based Genetic Algorithm (GA LP)|GA LP is a genetic algorithm that uses local information to generate offspring, aiming to optimize communication efficiency in distributed algorithms. It relies on the Label Propagation (LP) algorithm to detect communities in large-scale networks.
5253da09-fed8-55d7-aafe-2115e4f6673d|Re nement Phase|The Re nement Phase is a local search strategy that refines the results of GA LP, aiming to improve the quality of the solution.
06e8cafb-84e9-5ded-b7f9-48fe5c819e7e|Directed Modularity|Directed Modularity is a measure used to evaluate the quality of the communities in directed networks, aiming to optimize communication efficiency in distributed algorithms.
0a796385-6750-576b-8433-8a4ab35bc3eb|Roulette Wheel Selection|Roulette Wheel Selection is a selection algorithm used in GA LP to select individuals for the recombination process, aiming to optimize communication efficiency in distributed algorithms.
78259f6a-e485-54bb-99d9-2f77884b2c17|Crossover Operator|The Crossover Operator is a genetic operator used in GA LP to generate offspring, aiming to optimize communication efficiency in distributed algorithms.
eecb29ff-6078-56e3-af85-82105926ca8e|Iterative Trussness Update Algorithm|The authors propose an iterative algorithm to update trussness values in a graph after edge insertions or deletions. This algorithm aims to minimize the number of iterations required to maintain the maximal k-truss structure.
f515c156-eda4-5a78-984c-dfac7926b91c|Incremental Betweenness Centrality Update Algorithm|The authors propose an incremental algorithm to update betweenness centrality measures in response to edge modifications. This algorithm aims to minimize the computational cost of updating centrality measures.
d3433379-f4d7-5900-b99d-b9049e358c02|Batch Processing Algorithm for Vertex and Edge Updates|The authors propose a batch processing algorithm to process vertex and edge updates while preserving structural integrity. This algorithm aims to minimize the number of iterations required to maintain the graph structure.
e05550b7-7102-52e2-9d6c-b45c6fd11e04|Adaptive Trussness Update Algorithm|The authors propose an adaptive algorithm to update trussness values in a graph after edge insertions or deletions. This algorithm aims to minimize the number of iterations required to maintain the maximal k-truss structure.
29ad3a6c-31b3-56c3-b583-dab0d51136d7|Redundant Work Elimination|The authors propose a solution to eliminate redundant work in distributed algorithms by reusing the results of constraint checking to avoid duplicate checks. This is achieved by viewing the search template as specifying a set of constraints and leveraging key relationships between prototypes to reduce the search space and eliminate redundant work.
86687de7-52b5-52e9-bf8e-4f9b2ebb9563|Load Balancing through Reshuffling|The authors propose a load balancing technique that involves reshuffling the vertex to processor assignment to evenly distribute vertices and edges across processing cores. This is done to address load imbalance issues caused by the mutation of the workload during execution and non-uniform distribution of vertices and edges.
0b1a2e84-001d-53d8-bdf9-93f1a2d39a59|Parallel Prototype Search|The authors propose a solution to search multiple prototypes in parallel, leveraging the opportunity to replicate the pruned graph on smaller deployments and search multiple prototypes in parallel.
836a1f8d-2e47-5ea9-bfff-54684a9387b2|Search Space Reduction|The authors propose a solution to reduce the search space by aggressively pruning away the non-matching part of the background graph, both vertices and edges.
ef101b8a-b1fe-51ff-97db-f9db2fe02f09|Max Candidate Set Generation|The authors propose a solution to generate the maximum candidate set, which eliminates all the vertices and edges that do not have any chance to participate in a match, regardless of the distance to the search template.
93adf0de-a65d-5e72-97f1-f2497c239000|Load Balancing through Reloading on a Smaller Processor Set|This solution involves reloading the problem on a smaller set of nodes to reduce network traffic and improve overall solution efficiency. This approach is specifically designed to address load imbalance issues that arise during the execution of the pattern matching algorithm.
53dc234a-a6f4-5c5f-8b82-eb1cdd52e0c5|Multi-Level Parallelism|This solution involves exploiting multiple levels of parallelism, including vertex-level parallelism and searching prototypes in parallel. This approach is specifically designed to address load imbalance issues that arise during the execution of the pattern matching algorithm.
f1006dfa-5c2a-5708-be59-a6b32d90998d|Incremental Betweenness Centrality Computation within Biconnected Components|This solution addresses the challenge of efficient graph dynamics processing by proposing an incremental algorithm for updating betweenness centrality in evolving graphs. The algorithm, called iCENTRAL, decomposes the graph into biconnected components and proves that processing can be localized within the affected components. This approach avoids redundant recomputation within the affected component, making it more efficient than existing methods.
df796705-e47a-58e2-85b1-e381fb214900|Iterated Path Count Flows|This solution addresses the challenge of efficient graph dynamics processing by proposing a novel approach to computing length-constrained flows in dynamic graphs. The authors introduce the concept of iterated path count flows, which iteratively compute the path counts of all S-T paths in a capacitated h-layer S-T DAG.
8dc84807-112b-5122-83c9-40e06a98934e|Length-Weight Expanded DAG|This solution addresses the challenge of efficient graph dynamics processing by proposing a novel approach to representing all near-lightest h-length paths in a graph. The authors introduce the concept of length-weight expanded DAGs, which provide an approximate representation of all near-lightest h-length paths.
d9226d62-eeab-5011-b021-39808587fc3c|Deterministic Integral Blocking Flows|This solution addresses the challenge of efficient graph dynamics processing by proposing a novel approach to computing integral blocking flows in dynamic graphs. The authors introduce the concept of deterministic integral blocking flows, which can be computed in a more efficient manner than traditional methods.
e4038b4f-0e40-577b-a2e8-15f004f6744a|High-Girth Cycle Decompositions|This solution addresses the challenge of efficient graph dynamics processing by proposing a novel approach to computing high-girth cycle decompositions in dynamic graphs. The authors introduce the concept of high-girth cycle decompositions, which can be computed in a more efficient manner than traditional methods.
25739369-9f8b-53b3-9fc6-395792aa0edd|Deterministic CONGEST Algorithm for Maximum Independent Set|This solution addresses the challenge of efficient graph dynamics processing by proposing a novel approach to computing maximum independent sets in dynamic graphs. The authors introduce the concept of a deterministic CONGEST algorithm that computes a maximum independent set in a more efficient manner than traditional methods.
2b50953b-0746-5605-a732-836f97a6bf60|Batched Multiplicative Weights|This solution addresses the challenge of efficient graph dynamics processing by proposing a novel approach to computing length-constrained flows in dynamic graphs. The authors introduce the concept of batched multiplicative weights, which can be computed in a more efficient manner than traditional methods.
23c704eb-c73e-5621-aaf9-c76883d6c0a3|Length-Constrained Cutmatches|This solution addresses the challenge of efficient graph dynamics processing by proposing a novel approach to computing length-constrained cutmatches in dynamic graphs. The authors introduce the concept of length-constrained cutmatches, which can be computed in a more efficient manner than traditional methods.
f87716fd-8e42-5598-bb58-0de1bdf643c8|Multi-Commodity Length-Constrained Flows and Cutmatches|This solution addresses the challenge of efficient graph dynamics processing by proposing a novel approach to computing multi-commodity length-constrained flows and cutmatches in dynamic graphs. The authors introduce the concept of multi-commodity length-constrained flows and cutmatches, which can be computed in a more efficient manner than traditional methods.
d7165f2b-6b0f-5bf1-88ec-6a0d5db538f3|Deterministic Expander Decompositions|This solution addresses the challenge of efficient graph dynamics processing by proposing a novel approach to computing deterministic expander decompositions in dynamic graphs. The authors introduce the concept of deterministic expander decompositions, which can be computed in a more efficient manner than traditional methods.
15eab978-86cf-5595-9e5b-b544899cd4e6|1-Approximate Distributed Bipartite b-Matching|This solution addresses the challenge of efficient graph dynamics processing by proposing a novel approach to computing 1-approximate distributed bipartite b-matching in dynamic graphs. The authors introduce the concept of 1-approximate distributed bipartite b-matching, which can be computed in a more efficient manner than traditional methods.
1659aced-684d-584d-a8fd-22e9e76f7026|Batched Multiplicative Weights Framework|The authors propose a batched version of the multiplicative weights framework to optimize communication efficiency in distributed algorithms. This approach involves iteratively updating the weights of the arcs in the graph based on the flow values and capacities, allowing for more efficient communication and reducing the number of rounds required.
0b985d01-ce46-5ab9-b739-03de5f5f2daf|Lightest Path Blockers|The authors propose the use of lightest path blockers to optimize communication efficiency in distributed algorithms. This approach involves computing the lightest path blockers in the graph and using these blockers to update the flow values and capacities.
faea7e0e-4b19-55e8-8c66-1fe4a52a5c75|Distributed Expander Decompositions|The authors propose the use of distributed expander decompositions to optimize communication efficiency in distributed algorithms. This approach involves computing the expander decompositions of the graph and using these decompositions to update the flow values and capacities.
ea47cb7c-5ee9-56ee-a7db-b4e5342ccae1|Deterministic Integral Blocking Flows via Flow Rounding|This solution addresses the challenge of optimizing load balance in distributed systems by proposing a deterministic algorithm for computing integral blocking flows in a distributed setting. The algorithm uses a flow rounding technique to ensure that the computed flow is integral and feasible.
1c72d8ed-0dbe-540c-b5db-c1ce85c10c37|Two-Level Pattern Aggregation|This solution addresses the challenge of optimizing communication efficiency in distributed algorithms by introducing a two-level pattern aggregation technique. This technique reduces the number of communication rounds required for pattern-based aggregation, a common operation in graph mining algorithms.
32b27183-75e1-5f26-9274-cef7fd6fe738|Overapproximating Directed Acyclic Graph (ODAG)|This solution addresses the challenge of optimizing communication efficiency in distributed algorithms by introducing a compact data structure called Overapproximating Directed Acyclic Graph (ODAG). ODAG is used to store embeddings ef ciently, reducing the communication costs associated with transmitting embeddings across servers.
90ba74df-6b80-5b29-94ca-d3381c621464|Coordination-Free Exploration Strategy|This solution addresses the challenge of optimizing communication efficiency in distributed algorithms by introducing a coordination-free exploration strategy. This strategy enables workers to avoid redundant work and minimize communication costs by using a novel technique to identify blocks of embeddings ef ciently.
50e250a3-848d-5566-a112-2551d22bec70|Distributed Random Walk Algorithm|The authors propose a distributed algorithm to compute random walk betweenness centrality in linear time. The algorithm involves each node maintaining a parameter for each source, counting the number of times random walks starting at each source pass through it. The algorithm then computes the random walk betweenness using the counts and the node's neighbors' information.
3b1bad79-380e-5187-a81f-cba67f0cb0b8|Random Walk Simulation with Bounded Length Constraint|This solution addresses the challenge of optimizing communication efficiency in distributed algorithms by simulating random walks with a bounded length constraint. The authors propose imposing a bounded length constraint l on the random walks, which allows them to reduce the number of communication rounds required to compute the random walk betweenness centrality.
4ea3d3dc-162a-5deb-8a26-7ca97176cfcc|Distributed Random Walk Betweenness Algorithm with O(log n) Random Walks|This solution addresses the challenge of optimizing communication efficiency in distributed algorithms by proposing a distributed random walk betweenness algorithm that uses O(log n) random walks. The authors show that this algorithm can compute the random walk betweenness centrality with an approximation ratio of 1 - ε, where ε is an arbitrarily small constant.
b5fbba64-d5c1-5836-81d9-34236f226020|Hybridization Technique|The hybridization technique is a solution proposed by the authors to address the challenge of efficient graph dynamics processing. This technique involves dynamically adjusting the D parameter in the D-stepping algorithm to strike a balance between the number of relaxations and the number of phases. The algorithm starts with a fixed D value and then switches to the Bellman-Ford algorithm when the number of relaxations decreases.
54627825-8920-5b0c-a6ce-485776e04da3|Pruning Heuristic|The pruning heuristic is a solution proposed by the authors to address the challenge of efficient graph dynamics processing. This heuristic involves classifying edges into short and long edges and relaxing only the forward edges in the long edge phase.
bf7561c2-9af1-59d9-8083-e6737b0dbb73|Load Balancing Strategy|The load balancing strategy is a solution proposed by the authors to address the challenge of efficient graph dynamics processing. This strategy involves splitting the vertices having extreme degree and distributing their incident edges among other processing nodes.
c21075ea-078f-51b5-8c50-73f41ec6f486|Push-Pull Decision Heuristic|The push-pull decision heuristic is a solution proposed by the authors to address the challenge of efficient graph dynamics processing. This heuristic involves making a push-pull decision at the end of each bucket to determine whether to use the push model or the pull model.
e9dc18de-41eb-53e1-a703-c8377157e68e|Pruning Technique|The authors propose a pruning technique that reduces the number of relaxations in the D stepping algorithm to optimize communication efficiency. This technique involves classifying edges into short and long edges and relaxing only a fraction of the long edges.
4ff308f9-6353-59f4-9adf-a8d699f87f11|Load Balancing Technique|The authors propose a load balancing technique that distributes the load evenly among processors to optimize communication efficiency. This technique involves splitting the neighborhood of heavy degree vertices across processing nodes and distributing the load among threads within a processing node.
94174a9a-cfdf-5cc3-b7ad-19b7104fbacb|Intra-Node Thread-Level Load Balancing|This solution involves classifying vertices into two groups based on their degree and distributing the load evenly among threads within a node. The goal is to mitigate load imbalance caused by vertices with high degrees.
b5f119a0-2a68-5c8e-8632-dbe2d2fbe777|Inter-Node Load Balancing using Vertex Splitting|This solution involves splitting vertices with extreme degrees and distributing their incident edges among other processing nodes to achieve better load balance.
341d3e1b-c902-585c-87c2-64d9a70a27d3|Two-Tiered Load Balancing Strategy|This solution involves employing a combination of intra-node thread-level load balancing and inter-node load balancing using vertex splitting to achieve optimal load balance.
631b6ea8-dea6-53fc-8557-a76132548733|Modi edDCSC Algorithm|The Modi edDCSC algorithm is a parallel algorithm designed to find strongly connected components in distributed graphs. It addresses the challenge of efficient graph dynamics processing by minimizing computational costs and iterations through a divide-and-conquer approach. The algorithm uses a recursive partitioning approach, where each recursive step selects a random pivot vertex and partitions the graph into three disjoint subgraphs. The algorithm then recursively applies itself to each subgraph, reducing the problem size and minimizing iterations. The use of a trim step at the beginning of each iteration helps to eliminate portions of the graph without strongly connected components, further reducing computational costs. The paper presents experimental results demonstrating the effectiveness of the Modi edDCSC algorithm in finding strongly connected components in large graphs. The results show that the algorithm achieves good scalability and performance on thousands of processors, with execution times much less than those of the numerical computation it precedes.
2b19d180-bc42-5d83-8ae8-87600dbfacd4|Binary Tree Termination Detection|The authors propose a binary tree termination detection algorithm to optimize communication efficiency in distributed algorithms. This solution specifically addresses the challenge by reducing the time complexity of termination detection from O(P) to O(log P), where P is the number of processors.
05cd1434-4b3d-5af5-8e65-800ddce84325|Simultaneous Work on Multiple Problem Instances|The authors propose exploiting additional parallelism on multiple problem instances by working on all graphs simultaneously. This solution specifically addresses the challenge by reducing idle time and improving overall performance.
54808596-d987-5d2f-9ee3-ed97b1e59a15|Hybridization of Modi edDCSC with Tarjan's Serial Algorithm|This solution proposes a hybrid approach that combines the Modi edDCSC algorithm with Tarjan's serial algorithm to optimize load balance in distributed systems. The idea is to use Tarjan's algorithm to detect local SCCs on each processor independently, collapse these SCCs into single nodes (supernodes), and then apply the Modi edDCSC algorithm to the remaining graph.
17fa3f69-1d25-5d27-983e-806073c6b79a|Distributed Termination Detection Algorithm|This solution involves using a distributed termination detection algorithm to determine when a trim or mark step is completed. The algorithm uses a binary tree topology to send termination detection messages, allowing for efficient detection of termination conditions.
56bf179e-e560-5865-a62f-ff8fdad059dc|LACC (Linear Algebraic Connected Components)|LACC is a distributed-memory algorithm for finding connected components in large graphs. It uses linear algebraic primitives and is based on the Awerbuch-Shiloach algorithm. LACC employs a combination of conditional and unconditional hooking, shortcutting, and starcheck operations to efficiently identify connected components. It also uses sparse vectors to reduce computational costs and communication. LACC outperforms the state-of-the-art algorithm ParConnect by a factor of up to 12x for small to medium-scale graphs and scales to 4K nodes (262K cores) on a Cray XC40 supercomputer.
6d01d562-f269-5ce2-822c-b01b5a19460c|Customized All-to-All Communication Scheme|The authors propose a customized all-to-all communication scheme to optimize communication efficiency in distributed algorithms. This scheme is designed to handle imbalanced collective communication patterns inherent in the AS algorithm. The scheme involves broadcasting entries from few low-ranked processes and then removing those processes from all-to-all collective calls. This approach reduces the number of messages sent and words moved, resulting in improved communication efficiency. The paper reports that this scheme makes the shortcut and starcheck operations highly scalable, contributing to the overall performance of the LACC algorithm.
784535c2-2752-5351-bdb7-04f4d25d0907|Hypercube-Based All-to-All Implementation|The authors propose a hypercube-based all-to-all implementation to replace MPI Alltoallv calls, which are not scaling beyond 1024 MPI ranks. This implementation uses a hypercube-based algorithm with log p latency cost, which is more efficient than the pairwise exchange algorithm used in MPI Alltoallv. The paper reports that this implementation improves the scalability of the LACC algorithm, allowing it to scale to 4K nodes (262K cores) on a Cray XC40 supercomputer.
40438fb6-07f2-57bf-b854-70a4504975dd|Adaptive Use of Sparse Vectors|The authors propose an adaptive use of sparse vectors to reduce communication overhead in the LACC algorithm. The algorithm uses sparse vectors to represent the parent and star vectors, which reduces the number of elements that need to be communicated. The algorithm also adapts to the sparsity of the input graph, using dense vectors when the graph is dense and sparse vectors when the graph is sparse. The paper reports that this approach reduces the communication overhead and improves the performance of the LACC algorithm, especially for graphs with a large number of connected components.
d9bcaaa2-3244-5b08-a9c0-863643001659|Adaptive All-to-All Communication Scheme|The authors propose an adaptive all-to-all communication scheme to optimize load balance in distributed systems. This scheme dynamically adjusts the communication pattern based on the data distribution, reducing the impact of imbalanced collective communication patterns inherent in the AS algorithm.
d9625bca-a7e2-5ff2-b984-abc6f37f9388|Customized Vector Operations|The authors design customized vector operations to optimize load balance in distributed systems. These operations take advantage of vector sparsity, reducing the amount of data that needs to be communicated and processed.
37a70dbc-c92b-53ed-aa39-e32c5a94ee35|Load Balancing through Random Permutation|The authors propose a load balancing technique through random permutation of rows and columns of the adjacency matrix. This approach ensures a load-balanced distribution of the matrix and associated dense vectors.
253d4c86-e668-5c89-9b06-4a4c5c3c86e6|Iterative Contraction of Vertices|The authors propose an algorithm that iteratively contracts vertices in the graph to reduce the number of vertices and edges, making it more efficient to process dynamic updates.
bbce38c8-8bde-5afb-b2a1-885385e9c281|Incremental Betweenness Centrality Updates|The authors propose an incremental approach to updating betweenness centrality measures in response to edge modifications, reducing the number of iterations required to maintain graph structures.
7b01fcdf-d344-5939-903d-6b7b5198c051|Distributed 1-Coloring Algorithm|The authors present a distributed 1-coloring algorithm that can be used to color a graph with a small number of colors. This algorithm is designed to optimize communication efficiency by minimizing the number of communication rounds.
3b8796dd-7b10-5e55-8ade-578235a0ef88|Lower Bound Technique|The authors present a lower bound technique that can be used to analyze the communication complexity of distributed algorithms. This technique is specifically designed to address the challenge of optimizing communication efficiency in distributed algorithms.
56ba7cf7-604a-5171-bcf2-44acd9d36a44|Multi-Round HCubeJoin|This solution addresses the challenge of efficient graph dynamics processing by proposing a multi-round HCubeJoin algorithm for distributed subgraph counting. The algorithm is designed to minimize communication cost and computing cost with additional group by and aggregation over joins.
25eb9bef-28e2-52e8-bf17-e8d688a7276d|Leapfrog with Aggregation|This solution addresses the challenge of efficient graph dynamics processing by proposing a modified Leapfrog algorithm that supports join with group by and aggregation in a pipeline fashion. The algorithm is designed to minimize the intermediate results and reduce the computing cost.
200f2100-c4ee-5f47-ace1-07e3338c7e8d|Generalized Hypertree Decomposition (GHD)|This solution addresses the challenge of efficient graph dynamics processing by proposing a GHD-based approach for distributed subgraph counting. The approach is designed to minimize the communication cost and computing cost by pushing down group by and aggregation over joins.
17e6e878-bda6-579b-a094-96d1fc0887b7|Homomorphism Counting|This solution addresses the challenge of efficient graph dynamics processing by proposing a homomorphism counting approach for distributed subgraph counting. The approach is designed to minimize the communication cost and computing cost by reducing the number of matches enumerated.
1c492121-629b-5114-b90b-201f49d56b9a|Pipelined Leapfrog with Aggregation|The authors propose a pipelined Leapfrog with aggregation approach to optimize communication efficiency in distributed algorithms. This approach involves pushing down group by and aggregation over joins and processing them in a pipeline fashion, reducing the communication cost by minimizing the number of intermediate results.
e2006aeb-d8d3-5006-9694-95ffe32f797b|Attribute Ordering|The authors propose an attribute ordering approach to optimize communication efficiency in distributed algorithms. This approach involves ordering the attributes of the query to minimize the join cost and reduce the communication cost.
34c360f5-e14d-51a7-a723-5cf38956b009|Modified Leapfrog with Aggregation|The authors propose a modified Leapfrog algorithm that supports join with group by and aggregation in a pipeline fashion. This approach reduces the intermediate results and improves load balance by pushing down aggregation over joins.
a33ba149-4a44-56d2-b3b2-b94dd8ffa414|Cost Sharing|The authors propose a cost-sharing approach to optimize load balance in distributed systems. This approach involves sharing the computing cost of common sub-queries among multiple queries, reducing the overall computing cost and improving load balance.
692de7c3-2825-5da8-b7f2-fdae7339fdec|Parallel Complex Coloring Algorithm|The authors propose a parallel complex coloring algorithm to optimize GPU memory access for graph processing. This algorithm is designed to efficiently color the edges of a bipartite graph, which represents the scheduling problem in input-queued switches.
f97befaa-4557-59d7-8dda-94cfe43fe34e|Frame-Based Scheduling Algorithm|The authors propose a frame-based scheduling algorithm that uses the parallel complex coloring algorithm to optimize GPU memory access for graph processing. This algorithm is designed to schedule packets in input-queued switches, taking into account the memory access patterns and synchronization overhead.
9d9f174d-f9a0-5971-8f5d-c0a6e4b32f49|Complex Coloring Algorithm|The authors propose a complex coloring algorithm to optimize load balance in distributed systems. This algorithm is designed to efficiently color the edges of a bipartite graph, representing the scheduling of packets in a frame-based packet switch. The complex coloring algorithm uses a parallel processing approach, allowing for simultaneous color exchanges on vertices in the bipartite graph. This approach enables the algorithm to efficiently eliminate variables and achieve a proper edge coloring with a minimal number of colors. The authors demonstrate the effectiveness of the complex coloring algorithm through simulations, showing that it can achieve 100% throughput and an acceptable delay in large-scale packet switches.
af28c1fc-d901-54a1-bfb6-5b4c6826c6a4|C DLPA Algorithm|The C DLPA algorithm is a novel method that combines DLPA with the notion of maximal cliques and utilizes a new updating mechanism that updates each node label by probability of its adjacent nodes.
3e69092b-3eb7-5795-b1c5-e04904a1336d|KCminer|KCminer is a distributed solution to the k-clique problem, which is based on the MapReduce framework and can be executed on both distributed systems like cloud and parallel shared memory systems.
27bb8482-7acb-5f2a-888e-854b2e0d96f4|Iterative MapReduce KCminer|The iterative MapReduce version of KCminer launches a separate MapReduce job for each step of expansion, which allows it to handle very large networks.
bd23142d-1dfd-5d4e-bad4-aa868f5c2629|Non-Iterative MapReduce KCminer|The non-iterative MapReduce version of KCminer does all the work in a single iteration, which makes it much faster than the iterative version.
341e0cbb-aba5-57f6-b428-ccba4f39186a|Parallel Shared Memory KCminer|The parallel shared memory version of KCminer is designed to handle networks that can be loaded into the main memory of a single machine and uses multithreading to execute the algorithm in parallel.
ac2f98b6-26ec-5e36-bd5b-8ad762b9c181|Dynamic Load Balancing|The authors propose a dynamic load balancing technique to optimize load balance in distributed systems. This technique involves adjusting the workload distribution among nodes in real-time to ensure that no node is overwhelmed or underutilized.
8176e061-cd34-5cc4-b342-64ff004683fb|Partial Evaluation and Assembly Framework|The authors propose a partial evaluation and assembly framework to address the challenge of efficient graph dynamics processing. This framework involves evaluating a query Q on each graph fragment in parallel to find local partial matches, which are then assembled to compute crossing matches.
66f868ad-63dd-5c2f-8eaf-870860e5450e|Centralized Assembly Algorithm|The authors propose a centralized assembly algorithm to assemble local partial matches and compute crossing matches. This algorithm iteratively joins local partial matches to form the final query result.
0e0f403c-c850-5b68-a54a-ac35bff5330f|Distributed Assembly Algorithm|The authors propose a distributed assembly algorithm to assemble local partial matches and compute crossing matches in parallel. This algorithm divides the search space among multiple sites, which then assemble local partial matches in parallel.
01ead8c2-dabc-5731-83a6-02e1a950ff73|Cost Model for Optimal Partitioning|The authors propose a cost model to determine the optimal partitioning of the query graph, which minimizes computational costs and iterations.
e241e7f8-7838-5ac1-86e9-83900e0b9a1b|Divide and Conquer Approach|The authors propose a divide and conquer approach to optimize communication efficiency in distributed algorithms. This approach involves dividing the search space into smaller sub-problems and solving them in parallel, which reduces the number of communication rounds required.
2ed8f5ce-8e74-5fff-8a91-8176ac2ba361|Optimal Partitioning of Local Partial Matches|The authors propose an algorithm to find the optimal partitioning of local partial matches, which reduces the number of communication rounds required for assembly.
7980d7a6-4bfe-5c89-8ab5-d6cc82fb3614|Bulk Synchronous Parallel (BSP) Model|The authors propose using the BSP model to design a synchronous algorithm for distributed assembly, which reduces the number of communication rounds required.
896a3205-ca96-59fe-ac11-5702ac332e6f|Optimal Partitioning Algorithm|The authors propose an optimal partitioning algorithm to optimize load balance in distributed systems. This algorithm finds the optimal partitioning of local partial matches to minimize the cost of assembly.
ecff0481-055a-5d38-8a9e-9438540bd68e|Partitioning-Based Join Strategy|The authors propose a partitioning-based join strategy to optimize load balance in distributed systems. This strategy uses the partitioning information to optimize the join order and reduce the cost of assembly.
9a604688-7008-59f7-8f28-ab12d8276424|DistGreedy Algorithm|The DistGreedy algorithm is a distributed scheduling scheme that aims to optimize GPU memory access for graph processing by efficiently allocating memory to vertices in a graph. The algorithm works by dividing the vertices into layers based on their weights and then selecting the vertices with the highest weights in each layer. This approach ensures that the vertices with the highest memory requirements are allocated memory first, reducing memory access inefficiencies. The paper does not provide specific results for the DistGreedy algorithm in the context of optimizing GPU memory access for graph processing. However, it does demonstrate the algorithm’s effectiveness in achieving high throughput and low delay in wireless networks.
1a8c1dfd-7ecd-550d-bb3f-e1fd31196fc6|Layered Vertex Selection|The layered vertex selection technique is a key component of the DistGreedy algorithm, which addresses the challenge of efficient graph dynamics processing by minimizing computational costs and iterations.
8ec01e6d-d224-5440-a7c1-070050269f12|Maximal Independent Set Computation|The maximal independent set computation is another crucial component of the DistGreedy algorithm, which addresses the challenge of efficient graph dynamics processing by minimizing computational costs and iterations.
7dd0becd-ffb1-5b6b-b45f-cc75e94114d3|Local Maximum Weight Calculation|The local maximum weight calculation is a technique used in the DistGreedy algorithm to address the challenge of efficient graph dynamics processing by minimizing computational costs and iterations.
572bd8d0-dd5e-5f02-9222-eaa536e5e6f6|Distributed Greedy Approximation (DistGreedy) Algorithm|The DistGreedy algorithm is a distributed solution that addresses the challenge of optimizing communication efficiency in distributed algorithms by minimizing the number of communication rounds. It achieves this by iteratively selecting a maximal independent set of vertices in a graph, where each vertex represents a link in the network. The algorithm operates in a distributed manner, with each node making local decisions based on its neighbors’ weights, and it terminates after a certain number of intervals.
6ce604dd-a860-5272-8c1a-cd0b1f6d0c82|Layering Structure|The layering structure is a technique used in the DistGreedy algorithm to partition vertices into layers based on their weights. This allows the algorithm to consider multiple vertices in parallel, reducing the number of communication rounds required.
87ac1c44-6219-593b-881d-c16469cd2b53|Distributed Greedy Approximation to Maximum Weighted Independent Set (DistGreedy)|DistGreedy is a distributed algorithm designed to optimize load balance in distributed systems by solving the Maximum Weighted Independent Set (MWIS) problem. It aims to achieve a balance between throughput and delay performance in wireless networks with fading channels. The algorithm operates in a distributed manner, where each node makes local decisions based on its neighbors' weights, and it uses a layered structure to reduce complexity.
96645ee9-38f6-5f1c-b99c-f299143ab4a7|Silent Self-stabilizing 1-Maximal Matching Algorithm|The authors propose a silent self-stabilizing 1-maximal matching algorithm that efficiently processes graph dynamics by maintaining a 1-maximal matching in the presence of node and edge updates. This algorithm ensures that the graph remains in a legitimate state, even after arbitrary transient faults, and stabilizes to a 1-maximal matching configuration. The algorithm uses a combination of local variables and pointers to neighboring nodes to maintain the matching. It employs a distributed unfair daemon, which allows for the selection of any number of nodes to execute their actions simultaneously. The algorithm’s silent property ensures that it reaches a terminal configuration where no node can move, making it efficient for graph dynamics processing. The authors demonstrate that their algorithm stabilizes in O(e) moves, where e is the number of edges in the graph, making it efficient for large-scale graph processing.
d2c0cfa4-2c0a-5148-98b9-1fa6354b451b|Distributed Daemon with Unfair Scheduling|The authors propose a distributed daemon with unfair scheduling to optimize communication efficiency in distributed algorithms. The daemon allows multiple nodes to move simultaneously, reducing the number of communication rounds.
9e9df8bd-22e2-56ce-8f7d-3821e856f07f|Adaptive Sparse-Dense Mode Selection|The authors propose an adaptive sparse-dense mode selection approach to optimize GPU memory access for graph processing. This approach dynamically switches between sparse and dense representations of the graph data during computation, depending on the number of updated vertices. The approach maintains a partial sparse representation and a full dense representation of the graph data. It selectively uses either representation based on the number of updated vertices, ensuring that the chosen representation minimizes memory access overhead. This adaptive approach differs from existing methods that select the representation before or after local computation, which can lead to inaccurate selections and suboptimal memory access patterns.
925ad9a3-54ef-5541-a05b-6855e506326b|Hyper Stepping Algorithm|The Hyper Stepping algorithm is a novel approach to efficiently process dynamic updates in large graphs by minimizing computational costs and iterations. It combines the optimized stepping algorithm with a dynamic sliding window width, which is mathematically optimized for the zero-bounded weight distribution.
5138c5d8-037e-5b9f-be4a-316eb83b8cea|Adaptive Sparse-Dense Selection|The adaptive sparse-dense selection is a technique to dynamically switch between sparse and dense representations of vertices data during computation. It maintains a partial sparse representation and a full dense representation, and selectively uses either of them based on the number of updated vertices.
77004295-924e-5d54-8eef-974b62de333e|Adaptive Sparse Dense Selection|The authors propose an adaptive sparse dense selection method to optimize communication efficiency in distributed algorithms. This method dynamically switches between sparse and dense representations of data during computation, depending on the number of updated vertices.
62303b29-8cc2-5542-a368-aeb238fd4c1c|Delegated Vertices|The authors use delegated vertices to optimize communication efficiency in distributed algorithms. Delegated vertices are duplicated vertices of high-degree vertices that are shared among certain computing nodes.
38412fc3-435c-509c-9c19-b408ace4300b|Direction Optimization|The authors propose a direction optimization method to optimize communication efficiency in distributed algorithms. This method optimizes the direction of communication based on the globally updated vertices.
fd70f087-bc2f-5f38-b0c3-c8e6660747b0|Quick Preprocessing|The authors propose a quick preprocessing method to optimize communication efficiency in distributed algorithms. This method uses R-MAT generating information to construct the subgraphs directly from the original vertex ID.
ab734b54-c902-5859-bd95-ea8f14f7c232|Adaptive Dense-Sparse Mode Selection|The authors propose an adaptive method for selecting between dense and sparse modes in distributed graph processing. This approach maintains both partial sparse and full dense representations and dynamically switches between them based on the number of updated vertices.
4f105ede-70df-5f14-89a5-3170f2c2afc6|Iterative Arboricity Reduction|The authors propose an iterative approach to reduce the arboricity of the graph, which is a measure of how close the graph is to being a forest. By iteratively removing edges and reorienting the remaining edges, the algorithm reduces the arboricity of the graph, making it more sparse and easier to process.
f64c2f46-0cab-5eab-a314-afc64d9ada11|Sparsity-Aware Kp Listing|The authors propose a sparsity-aware algorithm for listing all instances of Kp in the graph. The algorithm takes advantage of the reduced arboricity of the graph to efficiently list all instances of Kp.
46b7158b-1d3a-555c-ad36-ff175415ad3c|Load-Balanced Routing|The authors propose a load-balanced routing algorithm to efficiently route messages within the graph. The algorithm takes advantage of the reduced arboricity of the graph to minimize the number of messages that need to be routed.
c1958dda-523d-5baa-8439-90d54608348c|Iterative Arboricity Listing|This solution addresses the challenge of optimizing communication efficiency in distributed algorithms by iteratively applying a listing algorithm to a sequence of graphs with decreasing arboricity. The algorithm, denoted as LIST, splits the edge set into two subsets, Em and Es, where Em contains the edges that are used to list all Kp instances in the graph, and Es contains the remaining edges. The arboricity of Es is reduced by a factor of 2 in each iteration, allowing for more efficient listing of Kp instances.
802fa0f6-26e3-50b0-9a2d-abb297ac2282|Sparsity-Aware Listing|This solution addresses the challenge of optimizing communication efficiency in distributed algorithms by using a sparsity-aware listing algorithm. The algorithm takes advantage of the fact that the graph becomes sparse as the algorithm progresses, allowing for more efficient listing of Kp instances.
bb3f65fa-72c3-55e4-a3fa-69907345dfc9|Intra-Component Routing|This solution addresses the challenge of optimizing communication efficiency in distributed algorithms by using an intra-component routing algorithm. The algorithm routes messages within clusters in a way that minimizes the number of rounds required.
3a7bcd9b-d2a6-5977-9ed9-6fe9a7e6a0be|Sparsity-Aware Load Balancing|The authors propose a sparsity-aware load balancing technique to optimize the distribution of workloads in distributed systems. This approach involves iteratively decreasing the arboricity of the graph, which represents the computational problem, to ensure that the ratio between the computation bandwidth and the problem size is optimized. By doing so, the authors aim to minimize the number of edges that need to be processed by each node, thereby reducing the load imbalance.
66d54aca-8608-597a-9f47-dafef7cb8c85|Load-Balanced Edge Redistribution|The authors propose a load-balanced edge redistribution technique to optimize the distribution of edges in the graph. This approach involves redistributing the edges in a way that ensures each node has a similar number of edges to process, thereby reducing the load imbalance.
a8aabee8-ebe0-54dd-908e-9f21c3035cbc|Distributed Algorithm for 2-Colored Bipartite Graphs|The authors propose a distributed algorithm for 2-colored bipartite graphs to solve the maximum weighted fractional matching problem. This algorithm is designed to work in the CONGEST model, where each message must be bounded in size.
23d4e2fb-581b-563a-8478-ac1c0c6c3811|Rounding Algorithm for Bipartite Graphs|The authors propose a rounding algorithm for bipartite graphs to obtain an integer solution from a fractional weighted maximum matching solution. The algorithm works by rounding each edge e to value 0 or 2^k-1, where k is the largest integer such that e is in E_k.
4bedea68-6466-5957-a552-6773103c16d1|Approximating Maximum Matching in Paths and Cycles|The authors propose an algorithm to approximate the maximum matching in paths and cycles. The algorithm works by defining an edge to be light if its weight is at most the average weight in some subpath of length O(log n).
8a5e7df7-87e2-58a5-9dd7-b9e9086be4fd|Distributed Algorithm for Exact Unweighted Maximum Matching in Bipartite Graphs|The authors propose a distributed algorithm for exact unweighted maximum matching in bipartite graphs. The algorithm works by iteratively finding augmenting paths and using them to increase the size of the matching.
a8eadb9c-e88f-56e7-8470-07236d0ec379|Lower Bound for Approximate Fractional Matching|The authors propose a lower bound for approximate fractional matching in unweighted bipartite graphs. The lower bound is based on the framework of 27 and is shown by reduction from two-party communication complexity.
25016032-26d5-5dff-bf4a-9f123bec6cea|Deterministic Rounding of Fractional Matchings|The authors propose a deterministic rounding algorithm for fractional matchings, which is a key component in achieving efficient communication in distributed algorithms. This solution specifically addresses the challenge of optimizing communication efficiency by providing a method to round fractional matchings in a deterministic manner, reducing the need for extensive communication.
ad684288-d4a8-56c4-8375-0506ce9b5246|Distributed Fractional Matching Algorithm|The authors propose a distributed fractional matching algorithm, which is designed to optimize communication efficiency in distributed algorithms. This solution specifically addresses the challenge of minimizing round complexity by providing a method to compute a fractional matching in a distributed manner, reducing the need for extensive communication.
c916045d-0167-571e-9388-dad699193085|Reduction to Bipartite Case|The authors propose a reduction from the general graph case to the bipartite case, which is a key component in achieving efficient communication in distributed algorithms. This solution specifically addresses the challenge of minimizing round complexity by providing a method to reduce the problem of computing a fractional matching in a general graph to the problem of computing a fractional matching in a bipartite graph, reducing the need for extensive communication.
66680e65-4901-5639-b435-d6ce0fe103b2|Monte Carlo Method for PageRank Approximation|The authors propose a Monte Carlo method to approximate PageRank values by simulating random walks on the graph and estimating the stationary distribution with the performed walk's distribution.
1b0f3c3b-8699-5633-9982-1701e16e7cc5|Distributed Random Walk Algorithm for PageRank Computation|The authors propose a distributed algorithm for computing PageRank values in a graph, which involves performing random walks in parallel and counting the number of visits to each node.
9d37b679-2fae-5196-979f-7c1acbd0fa65|Improved Distributed PageRank Algorithm for Undirected Graphs|The authors propose an improved distributed algorithm for computing PageRank values in undirected graphs, which involves performing short random walks and stitching them together to form longer walks.
26a5ef72-b42c-51f1-bf8d-1cd750afa526|Coupon-Based Random Walk Stitching|This solution addresses the challenge of optimizing communication efficiency in distributed algorithms by introducing a novel coupon-based random walk stitching technique. The method enables the stitching of short random walks to form longer walks, reducing the need for extensive communication and minimizing round complexity.
a60ae249-e892-5fac-bf60-9868fb20d0b3|Token-Based Random Walk Termination|This solution addresses the challenge of optimizing communication efficiency in distributed algorithms by introducing a token-based random walk termination technique. The method enables the efficient termination of random walks, reducing the need for extensive communication and minimizing round complexity.
d805f5eb-f20b-5719-9333-9b5758283ebf|Distributed Random Walk Counting|This solution addresses the challenge of optimizing communication efficiency in distributed algorithms by introducing a distributed random walk counting technique. The method enables the efficient counting of random walks, reducing the need for extensive communication and minimizing round complexity.
0ba8e14e-9a57-5c1c-973c-83fa6d1a1bd7|Shortcut-based Graph Coloring|The authors propose a shortcut-based approach to increase the parallelism in graph coloring without affecting the coloring quality. This approach is based on the Jones-Plassmann algorithm with the largest degree first heuristic.
a9d6bbad-22ac-5f7f-b476-335fedf1ab2a|Shortcutting in Graph Coloring|The authors propose a novel approach to increase parallelism in graph coloring by introducing shortcuts that allow lower-degree vertices to be colored before their higher-degree neighbors. This technique is specifically designed to optimize communication efficiency in distributed algorithms by reducing the number of rounds required for coloring.
b801bf49-ba9f-595a-8fd3-3a4ad3e1ac71|Summary Graph-Based Partial Match Scheduling|This solution addresses the challenge of optimizing communication efficiency in distributed algorithms by utilizing a summary graph to capture data locality and reduce remote accesses. The summary graph is used to prune suf cient intermediate results and schedule data movement, thereby minimizing the number of communication rounds.
14efe65d-e924-5515-803b-fa626aef1b3b|Joining Algorithm with Reduced Transmitted Intermediate Results|This solution addresses the challenge of optimizing communication efficiency in distributed algorithms by reducing the amount of transmitted intermediate results during the joining phase. The solution achieves this by pruning suf cient intermediate results using the summary graph and scheduling join operations to optimize network overhead.
b5bfaef2-25f3-551c-9c08-068569d3d2cc|Workload-Aware Graph Repartitioning|This solution addresses the challenge of optimizing communication efficiency in distributed algorithms by repartitioning the graph to minimize communication costs and balance workload. The solution employs a workload-aware repartitioning algorithm that redistributes the workload of the cluster to minimize communication costs and achieve a balanced partition.
693dbc9b-f705-5349-b301-317acd0c9e4d|Network Flow-Based Heuristic|This solution addresses the challenge of optimizing load balance in distributed systems by proposing a network flow-based heuristic algorithm. The algorithm maximizes the total benefit of all active vertices while obtaining a balanced partition.
fb4bc520-470a-5a80-b667-2453dcaccc05|Summary Graph-Based Monitoring|This solution addresses the challenge of optimizing load balance in distributed systems by proposing a summary graph-based monitoring approach. The approach uses a summary graph to monitor the imbalance of the cluster and updates the graph partitioning based on the workload information.
9a1598ba-94ff-55e5-af22-9ad73c8fc707|Bi-indexes based , core decomposition algorithm|The authors propose a Bi-indexes based , core decomposition algorithm to efficiently process dynamic updates in large bipartite graphs. This algorithm iteratively computes the n-order Bi-indexes of vertices to determine the maximum value of , such that a vertex is in the corresponding , core.
0e6b6ddd-dd50-544e-85eb-0a8c337c4aaa|Optimized n-order Bi-indexes computation|The authors propose an optimized algorithm for computing n-order Bi-indexes, which reduces the number of candidate pairs to be examined.
9c2889bf-eea6-5b64-bdd9-1399bbc96155|Distributed , core decomposition algorithm|The authors extend their Bi-indexes based , core decomposition algorithm to distributed graph processing frameworks, enabling efficient processing of large bipartite graphs in distributed environments.
ff9ebc4f-a9de-57fe-b0db-119255c6f44f|Optimized Distributed , Core Decomposition Algorithm|The authors propose an optimized distributed , core decomposition algorithm that iteratively computes n-order Bi indexes for vertices, leveraging local information to reduce communication overhead. This solution specifically addresses the challenge of optimizing communication efficiency in distributed algorithms by minimizing the number of communication rounds required for , core decomposition.
dc9bb195-6776-503f-a2c6-2a7cc8bd4d8f|Vertex-Centric Distributed , Core Decomposition Algorithm|The authors propose a vertex-centric distributed , core decomposition algorithm that extends the optimized algorithm to vertex-centric frameworks. This solution specifically addresses the challenge of optimizing communication efficiency in distributed algorithms by adapting the optimized algorithm to vertex-centric frameworks.
65da7616-389a-5df1-9b52-51a3545fe668|Block-Centric Distributed , Core Decomposition Algorithm|The authors propose a block-centric distributed , core decomposition algorithm that extends the optimized algorithm to block-centric frameworks. This solution specifically addresses the challenge of optimizing communication efficiency in distributed algorithms by adapting the optimized algorithm to block-centric frameworks.
1e056f88-e324-58c0-a430-3ce58bd4d60b|Optimization 1|Optimization 1 is a method proposed by the authors to optimize load balance in distributed systems by reducing candidate pairs examination. This solution specifically addresses the challenge of optimizing load balance by employing lower and upper bounds to limit the search space for n-order Bi-index computation.
39dbb332-a8b0-5e5a-bdba-0b43fb1b90fb|Optimization 2|Optimization 2 is another method proposed by the authors to optimize load balance in distributed systems by leveraging intermediate results. This solution specifically addresses the challenge of optimizing load balance by reusing previously computed results to reduce the computational overhead.
88ff7935-ccec-5c63-99bc-ded68f6abe1f|Workload Aware Distribution Strategy|The authors propose a workload aware distribution strategy to optimize communication efficiency in distributed algorithms. This strategy aims to balance the workload among workers by considering the cost of expanding a partial subgraph instance and the degree of the data vertex.
0bec497b-c6d0-5ffd-9c53-50496e71e4c9|Light Weight Edge Index|The authors propose a light weight edge index to reduce the number of invalid partial subgraph instances and minimize communication cost.
c39d9325-c830-5783-ab36-7d0d25eb15ae|Cost Model Based Initial Pattern Vertex Selection|The authors propose a cost model based initial pattern vertex selection method to optimize communication efficiency in distributed algorithms. This method aims to select an initial pattern vertex that minimizes the cost of expanding partial subgraph instances.
b4b5d642-3e59-5abd-b22c-d9d968092ae3|Roulette Wheel Distribution Strategy|This solution proposes a roulette wheel distribution strategy, which chooses a GRAY vertex for a partial subgraph instance with a probability based on the degree information of the data graph. This approach ensures that vertices with higher degrees are less likely to be chosen, reducing the impact of skewed degree distributions.
71bfd655-535e-5891-9e39-31efea1ffe0c|Incremental Graph Simulation Algorithm|The authors propose an incremental graph simulation algorithm that efficiently processes dynamic updates in large graphs by minimizing computational costs and iterations. This algorithm is designed to handle graph pattern matching queries and can be applied to various graph structures, including trees and DAGs.
7f4d9923-cc0b-5f0f-a09a-b8e48eb85efd|Topological Rank-based Message Passing|The authors propose a topological rank-based message passing strategy that optimizes the shipment of updated Boolean variables among sites. This strategy is designed to reduce the number of messages sent and received by each site, thereby improving the overall efficiency of the graph simulation algorithm.
3f8faba6-4b36-5cd4-b3c1-f73c865b9ca7|Local Dependency Graphs|The authors propose the use of local dependency graphs to keep track of the sites with virtual nodes as in-nodes at each site. This allows each site to dynamically generate messages and determine which sites to send the messages to.
a5df9bc5-d094-526d-a609-774f5f43fe0e|Partition Bounded Algorithm|The authors propose a partition bounded algorithm that is designed to handle general graph pattern matching queries. This algorithm is capable of processing dynamic updates in large graphs while minimizing computational costs and iterations.
37aea1b1-1c0f-57ec-ade7-bdb4715b581a|Incremental Partial Evaluation|The authors propose an incremental partial evaluation technique to optimize communication efficiency in distributed algorithms. This approach involves conducting partial evaluation incrementally, propagating updated truth values, and updating the vectors of the ancestors of virtual nodes.
95cc8aa5-31fd-596b-87ac-3092baa90c19|Message Passing with Local Evaluation|The authors propose a message passing approach with local evaluation to optimize communication efficiency in distributed algorithms. This approach involves each site conducting local evaluation to update its local variables and sending messages to other sites to update their variables.
b4a56f2f-2f84-501f-8d77-700ac6bf804f|Scheduling Message Passing|The authors propose a scheduling approach for message passing to optimize communication efficiency in distributed algorithms. This approach involves scheduling the shipment of updated Boolean variables following the topological ranks of query nodes in Q.
03284253-68d1-5199-bde3-ee66ee69fce4|Asynchronous Local Strategy|The asynchronous local strategy is a method for optimizing load balance in distributed systems by scheduling the shipment of messages based on the waiting time of parent sites and the amount of data required to be sent. This approach aims to balance the waiting time and data shipment by outsourcing part of the computation at a site to its parent site, bypassing the site.
bf4d6ade-a89d-52a7-bdb9-ed6fda7955be|Push Operation|The push operation is a technique used in the asynchronous local strategy to ship more data in exchange for better waiting time. This approach involves outsourcing part of the computation at a site to its parent site, bypassing the site, to reduce the waiting time.
43739732-ceea-5f84-86b3-b29975bc6204|Load Balance Optimization using lMsg|The lMsg procedure is a method for optimizing load balance in distributed systems by collecting the set of newly evaluated Boolean variables and sending them to the sites that need them. This approach aims to balance the load by reducing the number of messages sent and the amount of data required to be sent.
06bfe11e-9c6f-5afe-8a95-5ceca18e8a48|Deferred Decisions Framework|The Deferred Decisions Framework is a solution proposed by the authors to optimize communication efficiency in distributed algorithms. This framework involves partitioning the nodes into disjoint sets, called classes, and solving the Maximal Independent Set (MIS) problem sequentially in each class. The framework uses a technique called 
74952cac-bbb3-5acc-a57e-42d5f842bab8|Pipelined Parallelism for Incremental Centrality Computation|This solution addresses the challenge of efficient graph dynamics processing by employing pipelined parallelism to overlap computation and communication blocks in incremental centrality computation. It involves using a distributed memory framework that leverages replicated and pipelined parallelism to speed up the maintenance of closeness centrality scores in dynamic networks.
3cfc2268-4a11-5d34-a33a-bed28fd67c66|Level-Based Work Filtering for Incremental Centrality Computation|This solution addresses the challenge of efficient graph dynamics processing by reducing the number of single-source shortest path (SSSP) computations required for incremental centrality updates. It involves using level-based filtering to identify vertices whose centrality scores do not change after an edge insertion or deletion.
45769200-438d-5d5a-8c27-1fe96abd7783|Special Vertex Utilization for Incremental Centrality Computation|This solution addresses the challenge of efficient graph dynamics processing by exploiting special vertices in the graph to reduce the number of SSSP computations required for incremental centrality updates. It involves using articulation vertices and identical vertices to update the centrality scores of affected vertices.
74e68792-0595-512d-83e2-a07f47b7a0b6|Biconnected Component Decomposition for Incremental Centrality Computation|This solution addresses the challenge of efficient graph dynamics processing by using a biconnected component decomposition to identify the affected vertices after an edge insertion or deletion. It involves partitioning the edges of the graph into biconnected components and updating the centrality scores of affected vertices.
11f1a391-5861-59b1-a6dc-75bda2dfdf5f|Pipelined Parallelism|The authors propose using pipelined parallelism to overlap the process of filtering work and computing updates on the graph. This approach allows for simultaneous computation and communication, reducing the overall execution time.
fa26765f-6fb1-5778-ad99-fa279c611bf6|Replicated Parallelism|The authors propose using replicated parallelism to speed up the computation of closeness centrality scores. This approach involves replicating the ComputeCC filter to process different parts of the graph concurrently.
ccddedb4-1974-5fee-b4b9-8b8ae491ec4b|NUMA-Aware Graph Decomposition|The authors propose using a NUMA-aware graph decomposition approach to reduce communication overhead. This approach involves decomposing the graph into smaller subgraphs, each processed by a different NUMA domain.
806e89fe-08e5-5e4c-a95a-bc4042499e18|Level-Based Work Filtering|The authors propose using a level-based work filtering approach to reduce the number of SSSPs required for closeness centrality computation. This approach involves filtering out vertices that do not need to be updated based on their level in the graph.
c4377944-f3e3-5546-b7ee-18987c813738|Special Vertex Utilization|The authors propose using a special vertex utilization approach to reduce the number of SSSPs required for closeness centrality computation. This approach involves identifying special vertices that can be used to reduce the number of SSSPs.
3e4062a9-48bb-5d72-8a41-e2b6d9779073|Pipelined Parallelism with Work Filtering|The authors propose a pipelined parallelism approach to optimize load balance in distributed systems. This solution involves decoupling the work filtering and computation phases, allowing for simultaneous processing of updates and filtering of work. The work filtering phase is responsible for identifying the updates that need to be processed, while the computation phase performs the actual updates.
07140daf-a4f3-513f-9d37-9e5836a85747|Biconnected Component Decomposition|The authors propose a biconnected component decomposition approach to reduce the number of SSSPs in the incremental centrality computation. This solution involves decomposing the graph into biconnected components and updating the centrality scores only for the affected components.
bd38082e-862b-5a3d-8a84-b8b7081ec4c0|KokkosKernels-based GPU Coloring|The authors propose using KokkosKernels, a performance-portable programming model, to optimize GPU memory access for graph coloring. They leverage KokkosKernels' ability to provide parallelization for both multicore CPUs and GPUs, allowing for efficient on-node parallelism.
5ab4c7c4-561b-51c3-b94f-57c88d528bf6|Speculative and Iterative Coloring|The authors propose a speculative and iterative coloring approach to optimize GPU memory access for graph coloring. This approach involves coloring as many vertices as possible in parallel and then iteratively fixing conflicts in the resulting pseudo-coloring until no conflicts remain.
dc6434d6-f83d-559c-bc93-ef51fa1d7a9e|Distance-2 Coloring with Optimized Conflict Detection|The authors propose a distance-2 coloring approach with optimized conflict detection to optimize GPU memory access for graph coloring. This approach involves detecting conflicts by examining only the edges between ghost vertices and local boundary vertices.
dbd8c621-5179-5317-be7e-5d8e56b14f07|Two-Ghost-Layer Coloring|The authors propose a novel method to reduce communication in distributed graph coloring by introducing a second ghost layer of vertices. This approach aims to minimize the number of communication rounds required for coloring.
477a908c-7d91-5967-b607-d411d3bdff3b|Speculative Coloring with Conflict Resolution|The authors propose a speculative coloring approach that allows for concurrent coloring of vertices and resolves conflicts through a random conflict resolution scheme.
b202fc37-2071-5cfa-9591-38e29a9b0f1a|Coalesced Read Write Memory Accesses|This solution involves inducing coalescence among warp threads through warp shuf e instructions to reduce the overhead caused by many accesses in global memory.
25cc6d29-57d3-566b-8f0a-fc94acdb93c7|Dynamic Virtual Warps|This solution involves calibrating the warp size at each frontier propagation step to balance the workload and minimize thread divergence.
ef16600f-18b5-51f6-93f9-66f9789efcc2|Edge Discover|This solution involves assigning threads to edges rather than vertices to optimize the visit of middle-size degree vertices.
0d216ad8-9821-5a89-b43b-4d3ae55e9f86|Duplicate Detection and Correction|This solution involves using a hash table and 8 bank access mode to sensibly reduce the memory accesses and improve the detection capability.
bd28fd3f-7f64-58b7-a6fe-1a9e7bde889d|Exclusive Pre x Sum|This solution involves using a pre x sum procedure to improve data access time and thread concurrency during the propagation steps.
ddcc49f2-b152-5bfd-a2c8-4f48d2a0f977|Dynamic Parallelism|The authors propose the use of dynamic parallelism to overcome the workload imbalance due to the different degrees of vertices. This technique involves invoking a child kernel to manage the workload imbalance and reduce thread divergence.
266384af-8af9-5ac8-b731-728efaf6bdce|Coalesced Read/Write Memory Accesses|The authors propose a technique to induce coalescence in global memory accesses, which is combined with prefix sum and dynamic virtual warps. This technique aims to improve memory access efficiency and reduce thread divergence.
edfdad06-a3c4-5f34-a983-18b4f5c032e1|Dynamic Trussness Update Algorithm|The authors propose an algorithm for efficiently updating trussness values in a graph after edge insertions or deletions. This algorithm specifically addresses the challenge of efficient graph dynamics processing by minimizing the number of iterations required to maintain maximal k-trusses under updates. The algorithm uses a novel approach based on the concept of 
2c5144b7-551c-52a8-9970-18baead80c03|Batch Graph Update Algorithm|The authors propose an algorithm for batch processing vertex and edge updates while preserving structural integrity. This algorithm addresses the challenge of efficient graph dynamics processing by enabling efficient and adaptive updates to graph structures. The algorithm uses a novel approach based on the concept of 
cb502dfd-31b0-56b1-b8ec-09669a5315d1|Message Aggregation with Dynamic Buffering|The authors propose a message aggregation technique that reduces the number of messages sent between processors, thereby optimizing communication efficiency. This technique uses a dynamic buffer to aggregate multiple small messages into a single message, reducing the startup overhead and total communication volume.
d7e7b9e3-3f3b-5472-b9fc-9de5ea0d345e|Indirect Message Delivery|The authors propose an indirect message delivery technique that reduces the number of messages sent between processors. This technique uses a grid-based approach to route messages through intermediate processors, reducing the number of direct messages sent.
408e8c25-82d5-5601-99e6-53f280985274|Contraction-Based Communication Reduction|The authors propose a contraction-based approach to reduce the communication volume. This approach involves contracting edges in the graph, reducing the number of messages sent between processors.
57243d4e-0c52-598e-9fd8-5cdf6e8e2275|Hybrid Parallelism with Multi-Threading|The authors propose a hybrid parallelism approach that combines MPI parallelism with multi-threading. This approach reduces the communication volume and improves the running time of the algorithm.
52dd1907-80cc-532c-9873-73f5fbc20368|Dynamic Message Aggregation|The authors propose a dynamic message aggregation technique to optimize load balance in distributed systems. This technique involves aggregating multiple small messages into a single message, reducing the number of messages sent between processors and minimizing the startup overhead.
bc0004bf-0397-5a38-87a0-e29ca914e85b|Graph Contraction|The authors propose a graph contraction technique to optimize load balance in distributed systems. This technique involves contracting the graph by removing non-cut edges, reducing the communication volume and improving the load balance.
84c0a72c-6399-5b3f-8f9b-4533ef53af12|Task Fragmentation|Task fragmentation is a load balancing technique designed to deal with skew in the input graphs, which improves the performance of QFrag by up to 4 times. Task fragmentation subdivides a sequential task into a sequence of sequential subtasks, which correspond to the two phases of the subgraph isomorphism algorithm: tree building and embedding enumeration. This approach avoids stragglers while minimizing coordination. The evaluation shows that task fragmentation results in a substantial speedup, especially for skewed graphs.
b832f567-69dc-5630-b11d-3937edcedca8|Replicating the Input Graph|Replicating the input graph at every worker allows QFrag to reuse decades of research in sequential algorithms for subgraph isomorphism, enabling the system to run complex analytical queries that no other system can run. By replicating the input graph, QFrag distributes the computation, not the data, which results in very efficient local graph exploration even with larger graphs and analytical queries. The evaluation shows that QFrag outperforms other systems by orders of magnitude, and performs similar to centralized systems running sequentially.
9c1fb4b9-5c79-5903-bc54-1e9823292ecb|Subgraph Isomorphism Algorithm|QFrag uses a tree-based subgraph isomorphism algorithm, which is a state-of-the-art sequential algorithm for subgraph isomorphism. The algorithm starts by transforming the query graph into a spanning tree and matching this tree, and then enumerates partial embeddings based on the candidate tree. The evaluation shows that QFrag is able to run complex analytical queries that other systems are unable to handle, and outperforms other systems by orders of magnitude.
2f321a08-3d88-5efa-8bfa-c38976842820|Load Balancing through Task Fragmentation|This solution involves using task fragmentation to balance the load among workers in a distributed system. By breaking down tasks into smaller subtasks, the system can distribute the workload more evenly, reducing the need for communication and minimizing the impact of stragglers.
e7ee4be1-0459-5f9d-864f-02a98be99f28|Load Balancing via Subgraph Isomorphism|QFrag uses a task fragmentation approach to deal with skew in the input graphs, which improves its performance by up to 4 compared to a naive approach. QFrag runs independent parallel instances of a sequential graph matching algorithm with load balancing. It replicates the input graph at each worker and uses graph exploration to distribute the work. The paper shows that QFrag outperforms other state-of-the-art distributed graph search systems in running complex analytical queries.
ea08d896-3c76-54cb-b842-a83b4b4d8f34|Multi-phase Radar Push (MRP)|MRP is a distributed algorithm designed to efficiently estimate PageRanks in large graphs by minimizing the number of communication rounds and bandwidth requirements. MRP employs a multi-phase approach, where each phase involves generating and merging random walk segments to construct longer walks. This approach allows for the efficient estimation of PageRanks while reducing the number of communication rounds and bandwidth requirements. The paper demonstrates that MRP achieves a round complexity of O(log log n) and a bandwidth of O(log n^3), significantly improving over existing approaches.
cf947963-a2a5-5a6d-b48e-ddc0f6b832d0|Improved PageRank Algorithm (IPRA)|IPRA is a distributed algorithm designed to efficiently estimate PageRanks in large graphs by minimizing the number of communication rounds and bandwidth requirements. IPRA employs a distributed model that allows nodes to learn the IDs of other nodes through communication and generates short walks of length log n/p from each node, which are then stitched together to compose random walks of length O(log n). The paper demonstrates that IPRA achieves a round complexity of O(log n/p) and a bandwidth of O(log n^3), improving over naive baseline approaches.
cc703c4b-d068-5927-a504-40df51a4327a|Radar Push|Radar Push is a distributed algorithm designed to efficiently estimate PageRanks in large graphs by minimizing the number of communication rounds and bandwidth requirements. Radar Push employs a shuf e and send operation to distribute random walks evenly among nodes, reducing the number of communication rounds and bandwidth requirements. The paper demonstrates that Radar Push achieves a round complexity of O(log n) and a bandwidth of O(log n), improving over existing approaches.
37456b02-0bc9-52ff-9b5a-413a73a890a1|Radar Push (RP)|RP is a distributed algorithm designed to optimize communication efficiency in distributed PageRank computation. It addresses the challenge by reducing the round complexity to O(log n) while maintaining a reasonable bandwidth requirement of O(log n^2).
88b49747-6747-5aa7-ac94-de0473e4479a|Task-Based Vertex Pulling|The authors propose a task-based vertex pulling approach to optimize communication efficiency in distributed algorithms. This approach involves dividing the mining problem into independent tasks, each represented by a different tree branch in the set enumeration tree. Each task is associated with a subgraph that it constructs and mines upon, allowing for concurrent processing and minimizing the need for communication.
85d105af-da3e-53cb-9dc7-198f893d15bc|Bounded Memory Consumption|The authors propose a bounded memory consumption approach to optimize communication efficiency in distributed algorithms. This approach involves keeping a pool of active tasks for processing at any time, allowing for concurrent processing and minimizing the need for communication.
a60b5115-b87f-5abf-90d0-af8b7efe7923|Aggregator-Based Result Aggregation|The authors propose an aggregator-based result aggregation approach to optimize communication efficiency in distributed algorithms. This approach involves using an aggregator thread to synchronize aggregated values periodically at a user-specified frequency.
2b3cf987-ed56-555c-a64a-9dff507fad82|Work Stealing among Machines|This solution involves machines about to become idle stealing tasks from busy ones to balance workloads. The main thread of each worker synchronizes task processing progress, and machines that are about to become idle prefetch tasks from heavily loaded ones for processing.
106318ed-df66-50dc-8ff0-ff97c42bdba5|Task Spilling and Refilling|This solution involves spilling tasks from task queues to disk when they become full and refilling them when there are insufficient tasks to keep CPU cores busy. This approach helps to minimize the number of disk-buffered tasks and prioritize partially processed tasks over new tasks.
212e7147-90f7-5d8a-a826-bcb0fde3cf5c|Load Balancing through Task Generation|This solution involves generating tasks from vertices in the local vertex table on demand when memory permits, rather than generating all tasks at the beginning. This approach helps to balance workloads among machines by dynamically generating tasks based on available memory.
69ed6eec-409c-5625-a68c-b832c677538a|Extendable Embedding Abstraction|The authors propose the extendable embedding abstraction as a solution to efficient graph dynamics processing. This abstraction enables the efficient distributed execution of graph pattern mining algorithms by breaking down the embedding extension sequence into fine-grained tasks with well-defined dependent data.
393cb514-ec88-5d23-b7c0-2abd950abc20|Hybrid BFS-DFS Exploration|The authors propose a hybrid BFS-DFS exploration strategy to address the challenge of efficient graph dynamics processing. This strategy combines the benefits of both BFS and DFS exploration, allowing for efficient computation and communication overlapping.
895c8574-c857-58ad-a8cd-9b6d5a06e66a|Static Data Cache|The authors propose a static data cache to address the challenge of efficient graph dynamics processing. This cache is designed to store frequently accessed graph data, reducing the overhead of remote data accesses.
f9d189e8-2f58-55e0-87bf-acc6ab531d7c|Horizontal Data Sharing|The authors propose horizontal data sharing as a solution to efficient graph dynamics processing. This technique enables the sharing of edge lists between extendable embeddings in the same chunk, reducing communication overhead.
435e6dc8-07ec-55e0-a684-a3d99e29f5ab|Hierarchical Data Representation for Vertical Data Reuse|This solution addresses the challenge of optimizing communication efficiency in distributed algorithms by enabling the sharing of intermediate results between parent and child extendable embeddings. The hierarchical data representation allows for the storage of intermediate results in an extendable embedding, which can be directly accessed and copied by its children, reducing the need for redundant computation and communication.
e194a0e9-c129-5680-b746-8103ef90807a|Static Data Cache with No Replacement|This solution addresses the challenge of optimizing communication efficiency in distributed algorithms by reducing the number of remote data accesses. The static data cache stores frequently accessed graph data, eliminating the need for redundant fetches and reducing communication overhead.
e8a0fc98-14ff-5407-b006-47b298dc4d01|Horizontal Data Sharing among Extendable Embeddings|This solution addresses the challenge of optimizing communication efficiency in distributed algorithms by sharing edge lists among extendable embeddings in the same chunk. This approach reduces the number of remote data accesses and communication overhead.
42a88007-e42d-5d6c-aeb8-acb61ba44d62|BFS-DFS Hybrid Exploration with Fixed-Size Chunks|This solution addresses the challenge of optimizing communication efficiency in distributed algorithms by balancing the trade-off between memory consumption and parallelism. The BFS-DFS hybrid exploration approach generates sufficient concurrent tasks for communication-computation overlapping with bounded memory consumption.
31a9c5e7-a364-5f57-8417-a4a221b1b15f|Hybrid BFS-DFS Exploration with Fixed-Size Extendable Embedding Chunks|This solution addresses the challenge of optimizing load balance in distributed systems by proposing a hybrid exploration strategy that combines the benefits of Breadth-First Search (BFS) and Depth-First Search (DFS) for graph pattern mining. The approach involves dividing the graph into fixed-size chunks, exploring each chunk in a BFS manner, and then performing DFS within each chunk. This strategy enables the system to generate a large number of concurrent tasks, which can be distributed evenly across nodes, thereby achieving better load balance.
00c4f1eb-92b8-5967-ba12-6b37ecc607ed|Static Software Graph Data Cache with No Replacement|This solution addresses the challenge of optimizing load balance in distributed systems by proposing a static software graph data cache that stores frequently accessed graph data. The cache is shared across all chunks and nodes, and its size is typically 5-15% of the graph size per node. The cache is filled at the beginning of the execution and remains unchanged throughout.
300a4d47-09b6-5990-9c2d-ad60691b412f|Horizontal Data Sharing among Extendable Embeddings in the Same Chunk|This solution addresses the challenge of optimizing load balance in distributed systems by proposing a horizontal data sharing strategy among extendable embeddings in the same chunk. The approach involves maintaining a hash table that stores the active edge lists requested by extendable embeddings in a chunk, and sharing these edge lists among embeddings in the same chunk.
16182161-15d2-5d42-8827-4098805b9f04|NUMA-Aware Support for Distributed Graph Pattern Mining|This solution addresses the challenge of optimizing load balance in distributed systems by proposing a NUMA-aware support for distributed graph pattern mining. The approach involves dividing the graph partition of a socket node into sub-partitions, and running the BFS-DFS hybrid exploration independently on each socket based on the local sub-partition.
86efd4ac-c2a9-5e8a-96d3-a2cdac139c1b|Task Pipeline Design|The authors propose a task pipeline design to optimize communication efficiency in distributed algorithms. This design allows for the concurrent execution of CPU computation, network communication, and disk I/O, effectively hiding the overheads of network communication and disk I/O within the cost of CPU computation.
7ba52f64-d6d4-50b1-811a-0e45d886510e|Locality-Sensitive Hashing (LSH) based Task Priority Queue|The authors propose an LSH-based task priority queue to optimize communication efficiency in distributed algorithms. This design orders inactive tasks that share common remote candidates to be near each other, reducing the number of communication rounds required.
dec5cf17-bda1-5e55-8d83-29628681bb05|Remote Candidate Vertex (RCV) Cache|The authors propose an RCV cache to optimize communication efficiency in distributed algorithms. This design stores remote candidate vertices in a local cache, reducing the number of communication rounds required to access these vertices.
5f579c44-1711-54c3-97ab-c1e9e4239a13|Task Stealing|The authors propose a task stealing mechanism to optimize communication efficiency in distributed algorithms. This design enables tasks to be stolen from other nodes, reducing the number of communication rounds required.
3bc0714b-c04a-54f4-8121-878d56b5ad2a|BDG Partitioning|BDG partitioning is a static load balancing technique that partitions the graph into blocks of vertices based on their degrees, and then assigns these blocks to workers. This approach aims to balance the number of vertices in each worker and preserve the locality of the partitioned graph data.
61a91440-a72a-558d-813f-88f48ee1667b|LSH-based Task Priority Queue|The LSH-based task priority queue is a technique used to order tasks in the task pipeline based on their locality-sensitive hashing (LSH) keys. This approach aims to reduce the communication overhead and improve the locality of the task pipeline.
0559f490-bc94-5e16-ad23-9f82e2f6751a|RCV Cache|The RCV cache is a technique used to store remote vertices in a local cache, which can reduce the communication overhead and improve the locality of the task pipeline.
6db375e1-e5ba-56f8-b2cb-3a239e3c11d8|Deterministic Distributed Vertex Coloring|The authors propose a deterministic distributed vertex coloring algorithm that achieves a 2-approximation in O(log log n) rounds, significantly improving upon the previous best known deterministic algorithm.
4662e1fc-445f-5237-af9c-fb1c727edb77|Distributed Approximation of Weighted Vertex Covers and Matchings|The authors present a distributed algorithm for approximating the minimum weighted vertex cover and maximum weighted matching problems in the CONGEST model.
db9e5708-24a9-5190-b3a7-a58a07008956|Polylogarithmic Time Deterministic Network Decomposition|The authors propose a polylogarithmic time deterministic network decomposition algorithm that can be used to improve the efficiency of distributed algorithms.
ddfe3870-b83f-5e26-be8f-609cc9546cbf|Distributed Local Approximation Algorithms for Maximum Matching|The authors present a distributed local approximation algorithm for the maximum matching problem that achieves a 1-approximation in polylogarithmic time.
8bba5e09-5caa-5053-9c35-c790b4629897|Mask-Based Hash Table|The authors propose using a mask-based hash table to store query object values and meta data during search, allowing them to persist in the cache during candidate verification. Mechanisms/Techniques: The hash table array is initialized with negative values, and for each feature in the query vector, a hash key is computed by truncating the feature ID to the 0, h-1 domain using a mask. Offsets into the sparse query vector are stored at locations in the hash table corresponding to feature hash keys. Results: The authors report that this technique leads to few collisions in practice and allows for O(1) access times for most lookups.
d3bc04ae-d6c5-5b84-a272-e87041d50e38|Cache Tiling|The authors propose breaking the inverted index into blocks that can fit in the system cache, reducing latency during candidate generation. Mechanisms/Techniques: The authors assign up to inz non-zero values to be indexed in each tile, where inz is an input parameter, and create a sparse forward index containing prefix values for objects in each tile. Results: The authors report that this technique improves cache locality and reduces latency during candidate generation.
772f86f5-cc05-5835-aa70-b77ba60602a9|Dynamic Task Partitioning|The authors propose dynamically assigning small sets of objects to a thread to process as soon as it has finished processing its previous assigned set. Mechanisms/Techniques: The authors use a dynamic task partitioning approach to assign objects to threads, preventing threads from reading query objects from different portions of the dataset and reducing cache thrashing. Results: The authors report that this technique improves cache locality and reduces execution time.
04f35e1c-5c34-58fc-bdc5-482d9dda90d3|pL2AP|pL2AP is a multi-core parallel algorithm designed to efficiently solve the All-Pairs similarity search problem in high-dimensional sparse datasets. It employs cache tiling optimizations, combined with fine-grained dynamically balanced parallel tasks, to improve cache locality during similarity search. It uses a mask-based hash table to store query object values and meta-data, allowing for O(1) access times and reducing memory requirements. pL2AP achieves 1.5x-238x speedup over existing parallel baselines and 2x-34x speedup over the fastest serial method on datasets with hundreds of millions of non-zeros.
753be57e-af8a-5d4b-b74c-882e5577357e|Cache Tiling with Dynamic Task Partitioning|This solution addresses the challenge of optimizing communication efficiency in distributed algorithms by employing cache tiling and dynamic task partitioning. The authors propose dividing the inverted index into blocks that fit in the system cache, reducing latency during candidate generation. Additionally, they use dynamic task partitioning to assign small sets of objects to threads, allowing for efficient processing and minimizing communication overhead.
7c5854b2-9100-59e2-84f9-d4ff8fe2a8f8|Mask-Based Hash Tables|This solution addresses the challenge of optimizing communication efficiency in distributed algorithms by using mask-based hash tables. The authors propose using hash tables to store query object values and meta-data during search, allowing them to persist in the cache during candidate verification.
e7f980db-91d9-59df-b1c1-41ce2a973dbc|Query Vector Mask Hashing|This solution addresses the challenge of optimizing communication efficiency in distributed algorithms by using query vector mask hashing. The authors propose using a hash table to store offsets into the sparse query vector, allowing for efficient lookup of query object values during candidate verification.
bdf841ee-550c-5d97-8ae2-17be1edff08e|Star-Clique Preserved (SCP) Storage Mechanism|The SCP storage mechanism is a novel approach to storing data graphs in a distributed environment, allowing for both star and clique structures to be used as join units. This mechanism enables the algorithm to make a better choice between star and clique, reducing the number of execution rounds and intermediate results.
482b4e23-df9e-5562-b6b5-b8b632b4ed50|Optimal Bushy Join Plan|The optimal bushy join plan is a technique used to optimize the join order in distributed algorithms, aiming to minimize the number of communication rounds. The plan is computed using a dynamic programming approach, which takes into account the cost of each join operation and the dependencies between them.
a6ff2a28-c935-5e14-b128-df3fc43576d8|Clique Compression|Clique compression is a technique used to reduce the number of communication rounds in distributed algorithms, by compressing the matches of large cliques. The technique represents the matches in a compressed way, reducing the amount of data that needs to be communicated.
2871210c-07b0-5d88-a5c5-5d368d6e7a77|Dynamic Programming Algorithm for Optimal Bushy Join Plan|The dynamic programming algorithm is designed to optimize load balance in distributed systems by computing the optimal bushy join plan. This approach enables the efficient distribution of workloads across nodes, reducing the impact of workload imbalance and skewness.
266f6a83-a9a8-516c-94a6-0a314c6e3441|Clique Compression Technique|The clique compression technique is designed to optimize load balance in distributed systems by compressing large cliques in the data graph. This approach enables the efficient distribution of workloads across nodes, reducing the impact of workload imbalance and skewness.
dee4dac8-93fe-549c-a831-c85fdeee07b2|Bounded Incremental Evaluation|This solution addresses the challenge of efficient graph dynamics processing by employing bounded incremental evaluation to minimize the cost of iterative computations. It involves using a sequential incremental algorithm to compute the changes to the output caused by updates to the graph, and then applying these changes to the partial results.
786771d9-30c9-5c08-b983-cd1fad7a7df4|Partial Evaluation|This solution addresses the challenge of efficient graph dynamics processing by employing partial evaluation to minimize the cost of computations. It involves using a sequential algorithm to compute the partial results for each fragment of the graph, and then combining these partial results to obtain the final output.
228407d7-3b76-5295-972b-c896b075f9a5|Assemble Partial Results|This solution addresses the challenge of efficient graph dynamics processing by employing a function to assemble partial results from each fragment of the graph. It involves combining the partial results to obtain the final output.
9d436af6-7b1d-543b-bcd7-57bdbbaf2673|Graph Partitioning|This solution addresses the challenge of efficient graph dynamics processing by employing graph partitioning to minimize the cost of computations. It involves partitioning the graph into fragments and distributing them across multiple processors.
87c8caf6-7c0d-51f0-ad8b-236a8adbfc36|Load Balancer|This solution addresses the challenge of efficient graph dynamics processing by employing a load balancer to minimize the cost of computations. It involves computing an assignment of work units to physical workers to minimize both computational cost and communication cost.
23cc0c24-41cb-5ef9-8980-2bf07ed8119f|Query Preserving Compression|This solution addresses the challenge of efficient graph dynamics processing by employing query preserving compression to minimize the cost of computations. It involves compressing the graph while preserving the query results.
8793a8ec-d11a-5f7d-8c41-6cf63cc5f567|Indexing|This solution addresses the challenge of efficient graph dynamics processing by employing indexing to minimize the cost of computations. It involves creating an index on the graph to speed up query processing.
64bcefd9-2015-5818-996d-7c3b35cabd87|Dynamic Grouping|This solution addresses the challenge of efficient graph dynamics processing by employing dynamic grouping to minimize the cost of computations. It involves grouping nodes and edges in the graph to speed up query processing.
47387990-9abd-5fda-91ea-9dbca9fa0dcf|Fault Tolerance|This solution addresses the challenge of efficient graph dynamics processing by employing fault tolerance to minimize the cost of computations. It involves using an arbitrator mechanism to recover from both worker failures and coordinator failures.
d5f3fc9b-20df-597e-8bbf-7cee0da92bac|Consistency Control|This solution addresses the challenge of efficient graph dynamics processing by employing consistency control to minimize the cost of computations. It involves using a consistency control strategy to ensure the consistency of the graph.
ab45e216-c232-59e6-bacf-34adb02cecdf|Data Partitioned Parallelism|The authors propose using data partitioned parallelism to reduce communication costs in distributed algorithms. This approach involves partitioning the data into smaller fragments and processing each fragment in parallel.
ec3e5c17-77cc-5904-8db7-2d10f1d89264|Message Composition|The authors propose using message composition to reduce communication costs in distributed algorithms. This approach involves composing messages from variables with changed values and deducing their designations by referencing the graph partition.
159fbf76-2326-5abb-ab69-f4c168ac1357|Multi-Level 2-Hop Labeling Index (ML2hop)|The authors propose a novel distributed indexing scheme called ML2hop to efficiently handle set reachability queries in a distributed environment. This index is designed to restrict message exchange among different partitions within one single round, thereby reducing computational costs and iterations.
e8c64175-2d82-5b69-ace8-67a443097a8b|Bi-Directional Query Algorithm (MLQA)|The authors propose a bi-directional query algorithm called MLQA to efficiently answer set reachability queries using the ML2hop index. MLQA adopts a bi-directional query technique to simultaneously activate all source and target vertices, reducing the number of iterations and computational costs.
4a6d0ea4-f0dd-5082-a37e-25549e6d4459|Incremental Index Maintenance|The authors propose an incremental index maintenance approach to efficiently update the ML2hop index under edge insertions. This approach updates the inner paths in each subgraph based on the inner 2-hop index of the affected vertices.
8b7267af-3b1c-5aa3-a371-3bae241df998|Multi-Level 2-Hop (ML2hop) Indexing|The authors propose a novel distributed indexing scheme called Multi-Level 2-Hop (ML2hop) to optimize communication efficiency in distributed algorithms. This solution specifically addresses the challenge by reducing the number of communication rounds required for set reachability queries in distributed environments.
2c15299f-3005-5e3c-be13-9688e1fff603|Nearly Most Balanced Sparse Cut Algorithm|The authors propose a distributed algorithm for finding a nearly most balanced sparse cut in a graph, which is a key component in their expander decomposition algorithm. This algorithm is designed to efficiently process dynamic updates in large graphs by minimizing computational costs and iterations.
ca4ddc94-f725-56d2-b389-6fe0dae5c18f|Low Diameter Decomposition Algorithm|The authors propose a low diameter decomposition algorithm that can be used to reduce the diameter of a graph, making it more efficient to process dynamic updates.
14209a3d-88cf-5947-b72f-55d2e6aac2fb|Expander Decomposition Algorithm|The authors propose an expander decomposition algorithm that can be used to decompose a graph into smaller components with high conductance.
8fda06b9-5bbb-5373-ab48-4e9c9f1c0a1c|Distributed Routing Algorithm|The authors propose a distributed routing algorithm that can be used to efficiently route messages in a graph.
3f4ca742-23bc-5e9b-a070-cb4ca46b469d|Low Diameter Decomposition|The authors propose a low diameter decomposition algorithm that is used to decompose the graph into components of low diameter. This algorithm is designed to address the challenge of optimizing load balance in distributed systems by reducing the diameter of the graph, which can help to improve communication efficiency.
75108c1c-f5d5-586c-b9bc-01c1106768bc|Triangle Enumeration Algorithm|The authors propose a triangle enumeration algorithm that is designed to address the challenge of optimizing load balance in distributed systems by enumerating triangles in the graph. This algorithm is a key component of their overall approach to optimizing load balance in distributed systems.
f237cad2-de47-5f40-b618-78630b736947|PTE (Pre-partitioned Triangle Enumeration)|PTE is a distributed algorithm designed to efficiently enumerate triangles in massive graphs by minimizing the amount of shuffled data, total work, and network read. PTE exploits pre-partitioning to decrease the shuffled data, considers color direction to remove redundant operations, and carefully schedules triangle computations in subproblems to shrink the amount of network read. PTE outperforms the state-of-the-art scalable distributed algorithm by up to 47% and successfully enumerates more than 3 trillion triangles in the ClueWeb12 graph with 6.3 billion vertices and 72 billion edges.
78e516bf-e3b3-5a5d-8712-f2cae63ac930|Pre-Partitioned Triangle Enumeration (PTE)|PTE is a distributed algorithm designed to optimize communication efficiency in triangle enumeration by minimizing the amount of shuffled data, total work, and network read. PTE achieves this by pre-partitioning the graph into sets of edges, storing them in a distributed storage, and then enumerating triangles in each subproblem using a single map step. This approach reduces the amount of shuffled data from O(E^3/2M) to O(E), where E is the number of edges in the graph. The paper demonstrates that PTE outperforms the state-of-the-art distributed algorithm, CTTP, by up to 47% in terms of running time and successfully enumerates more than 3 trillion triangles in the ClueWeb12 graph, which contains 6.3 billion vertices and 72 billion edges.
a5d29f1e-b55a-596e-95c7-0179ea1199c0|Color-Directed Edge Processing (CDEP)|CDEP is a technique used in PTE to remove redundant operations by considering the color direction of edges. CDEP works by intersecting the neighbor sets of two vertices to find triangles, instead of considering all possible edges. This approach eliminates unnecessary computations and reduces the total work. The paper shows that CDEP improves the performance of PTE by reducing the number of redundant operations.
72760582-18fa-5f09-a077-7f6217d652db|Scheduling Function for Triangle Enumeration (SFTE)|SFTE is a scheduling function used in PTE to minimize network read by carefully scheduling triangle computations in subproblems. SFTE works by restricting the number of edge sets read in each subproblem, reducing the amount of network read from O(E^3/2M) to O(E). The paper demonstrates that SFTE improves the performance of PTE by reducing the amount of network read.
d1441930-dd88-550f-a66d-734b35198c3c|Color Direction-based Redundancy Removal|This solution removes redundant operations in triangle enumeration by considering the color direction of edges.
1760903b-dc04-561e-9bce-5436a7897651|Scheduling Function-based Network Read Minimization|This solution minimizes network read by carefully scheduling triangle computations in subproblems.
89679332-b714-53b4-8aa7-6e033cdb8257|Lazy Update BSP Communication Paradigm|The authors propose a novel communication paradigm called Lazy Update BSP to address the challenge of efficient graph dynamics processing. This paradigm is designed to reduce network communication overhead by updating vertex information only when vertices on the same machine are changed, rather than updating information per vertex.
19dcf07d-600e-5439-96a4-cf5dea6b07c2|Quick Convergence Label Propagation (QCLP) Algorithm|The authors propose a novel QCLP algorithm to address the challenge of efficient graph dynamics processing. This algorithm is designed to reduce computation and increase the quality of edge cuts by implementing the LP process only for limited vertices based on the VP Score.
4b6b9bf7-01bb-511f-a9e5-a0550b3b09cf|Stabilization Process|The authors propose a stabilization process to address the challenge of efficient graph dynamics processing. This process is designed to prevent the algorithm from becoming trapped in local optima by relocating highly connected vertices.
aa610e85-23c3-545a-9511-15bdd8969050|Edge Balanced Partitioning Process|The authors propose an edge balanced partitioning process to address the challenge of efficient graph dynamics processing. This process is designed to maintain a near-perfect edge balance by prioritizing edge balance over vertex balance.
5674db25-0ac7-5ee2-b1b0-e6dffb32e36b|Bulk Synchronous Parallel (BSP) Style Lazy Updating Scheme|The authors apply a BSP style lazy updating scheme to reduce the amount of network communication and improve performance. This approach involves updating vertex information in bulk, rather than individually, to minimize the number of communication rounds.
0bab613b-2f57-5a41-93bf-e40e2aec6696|Score-Based Approach with VP Score|The authors propose a score-based approach that uses a vertex partition score (VP Score) to indicate the appropriateness of a vertex in its current partition. This approach prioritizes vertex balance and reduces the number of candidate vertices in every iteration of the LP process.
2ebea322-04e0-5fe4-b1e7-a4a24743f29c|Stabilization Process with HCRV|The authors propose a stabilization process that relocates higher connectivity to remote vertices (HCRV) to prevent the algorithm from becoming trapped in local optima. This approach changes the graph topology based on the most required vertices in each partition.
7575572b-3543-5212-ba58-7bd0e0dcd24a|Hypergraph MIS Algorithm|The authors propose a deterministic algorithm for solving the maximal independent set (MIS) problem on hypergraphs, which is a fundamental problem in graph dynamics processing. The algorithm is designed to work efficiently in the LOCAL model of distributed computing, where nodes can communicate with their neighbors in synchronous rounds.
58778028-f0e4-5ec4-bca2-094cb98a3200|Hypergraph Maximal Matching Algorithm|The authors propose a deterministic algorithm for solving the maximal matching problem on hypergraphs, which is another fundamental problem in graph dynamics processing. The algorithm is designed to work efficiently in the LOCAL model of distributed computing.
742c9c8c-bc8f-51e8-b067-052908fe3889|Round Elimination Technique|The authors propose a round elimination technique for proving lower bounds on the time required to solve locally checkable problems on trees or hypertrees. The technique is designed to work efficiently in the LOCAL model of distributed computing.
f9dd4ccc-a249-5c36-b749-6f5808c75132|Fixed Point Relaxation|The authors propose a fixed point relaxation technique for proving lower bounds on the time required to solve locally checkable problems on trees or hypertrees. The technique is designed to work efficiently in the LOCAL model of distributed computing.
6e864196-f50d-5fab-840e-aa2d7e02aa12|Hypergraph Coloring Algorithm|The authors propose a deterministic algorithm for solving the coloring problem on hypergraphs, which is a fundamental problem in graph dynamics processing. The algorithm is designed to work efficiently in the LOCAL model of distributed computing.
4a836704-5c3a-5f9f-835e-08b1abcfb9fb|Unique Maximum Coloring Algorithm|The authors propose a deterministic algorithm for solving the unique maximum coloring problem on hypergraphs, which is a fundamental problem in graph dynamics processing. The algorithm is designed to work efficiently in the LOCAL model of distributed computing.
6f070030-ea89-54e5-88a6-f1526501cd68|Distributed Lower Bounds|The authors propose a technique for proving lower bounds on the time required to solve locally checkable problems on trees or hypertrees in the LOCAL model of distributed computing.
ad93de32-aa0f-559f-bd2f-4585151f024c|Hypergraph Maximal Matching Lower Bound|The authors propose a lower bound on the time required to solve the maximal matching problem on hypergraphs in the LOCAL model of distributed computing.
b4e80683-2482-5fd7-8fbe-47f0643d082f|Hypergraph MIS Lower Bound|The authors propose a lower bound on the time required to solve the MIS problem on hypergraphs in the LOCAL model of distributed computing.
8f952d72-dc3c-5e9e-8a6e-5f313cb30473|Hypergraph Coloring Lower Bound|The authors propose a lower bound on the time required to solve the coloring problem on hypergraphs in the LOCAL model of distributed computing.
62c4ab3a-9b60-5628-90f2-9cd932dea763|Unique Maximum Coloring Lower Bound|The authors propose a lower bound on the time required to solve the unique maximum coloring problem on hypergraphs in the LOCAL model of distributed computing.
72507226-9837-58cb-a3f9-2f599123b884|Distributed Algorithm for Hypergraph MIS|The authors propose a distributed algorithm for solving the MIS problem on hypergraphs in the LOCAL model of distributed computing.
e933a771-2f6b-5925-802d-32b5a8fcdc9e|Distributed Algorithm for Hypergraph Maximal Matching|The authors propose a distributed algorithm for solving the maximal matching problem on hypergraphs in the LOCAL model of distributed computing.
ab68eb02-0a0a-5bf1-8d15-00cb8c0f9614|Distributed Algorithm for Hypergraph Coloring|The authors propose a distributed algorithm for solving the coloring problem on hypergraphs in the LOCAL model of distributed computing.
a76ddcdc-58b1-5ee9-988f-b40a2a7fe3cd|Distributed Algorithm for Unique Maximum Coloring|The authors propose a distributed algorithm for solving the unique maximum coloring problem on hypergraphs in the LOCAL model of distributed computing.
6fb437b6-e438-571e-950f-58863203c649|Round Elimination Technique for Hypergraph MIS|The authors propose a round elimination technique for proving lower bounds on the time required to solve the MIS problem on hypergraphs in the LOCAL model of distributed computing.
f1e67476-53bb-5091-b85f-a962a3f43c2b|Round Elimination Technique for Hypergraph Maximal Matching|The authors propose a round elimination technique for proving lower bounds on the time required to solve the maximal matching problem on hypergraphs in the LOCAL model of distributed computing.
5b4f3aac-b218-5109-b08e-8ab1c50ae03a|Round Elimination Technique for Hypergraph Coloring|The authors propose a round elimination technique for proving lower bounds on the time required to solve the coloring problem on hypergraphs in the LOCAL model of distributed computing.
c2712066-7c02-55cb-9557-7428986829a2|Round Elimination Technique for Unique Maximum Coloring|The authors propose a round elimination technique for proving lower bounds on the time required to solve the unique maximum coloring problem on hypergraphs in the LOCAL model of distributed computing.
360dd879-7a03-5ae2-a8fc-4e9bfbb8a447|Distributed Algorithm for Hypergraph MIS with Unique Maximum Coloring|The authors propose a distributed algorithm for solving the MIS problem on hypergraphs with unique maximum coloring in the LOCAL model of distributed computing.
fc327ead-15bc-5319-88b3-11b7683dc98f|Distributed Algorithm for Hypergraph Maximal Matching with Unique Maximum Coloring|The authors propose a distributed algorithm for solving the maximal matching problem on hypergraphs with unique maximum coloring in the LOCAL model of distributed computing.
c3296b4f-d49f-5231-bc62-bcac1f56541d|Distributed Algorithm for Hypergraph Coloring with Unique Maximum Coloring|The authors propose a distributed algorithm for solving the coloring problem on hypergraphs with unique maximum coloring in the LOCAL model of distributed computing.
0158cd21-9f4c-5b01-9827-4c76e0d0fc88|Distributed Algorithm for Unique Maximum Coloring with Hypergraph MIS|The authors propose a distributed algorithm for solving the unique maximum coloring problem on hypergraphs with MIS in the LOCAL model of distributed computing.
d6f5ee10-5e7a-5e6c-9415-1ec714d01956|Distributed Algorithm for Unique Maximum Coloring with Hypergraph Maximal Matching|The authors propose a distributed algorithm for solving the unique maximum coloring problem on hypergraphs with maximal matching in the LOCAL model of distributed computing.
62b7de08-8b3e-514e-b010-69a74c0767f5|Distributed Algorithm for Unique Maximum Coloring with Hypergraph Coloring|The authors propose a distributed algorithm for solving the unique maximum coloring problem on hypergraphs with coloring in the LOCAL model of distributed computing.
94ae7276-b83d-5623-92dd-8cc61c0bb7fb|Distributed Algorithm for Hypergraph MIS with Coloring|The authors propose a distributed algorithm for solving the MIS problem on hypergraphs with coloring in the LOCAL model of distributed computing.
b1d9bcf3-97c7-5c3a-9bc8-c7e407dcefdf|Distributed Algorithm for Hypergraph Maximal Matching with Coloring|The authors propose a distributed algorithm for solving the maximal matching problem on hypergraphs with coloring in the LOCAL model of distributed computing.
b4e6c28b-0282-55dd-9814-1cec2910bb1c|Distributed Algorithm for Hypergraph Coloring with MIS|The authors propose a distributed algorithm for solving the coloring problem on hypergraphs with MIS in the LOCAL model of distributed computing.
b2df3794-3f11-511c-8eb8-694d6d309bd6|Distributed Algorithm for Hypergraph Coloring with Maximal Matching|The authors propose a distributed algorithm for solving the coloring problem on hypergraphs with maximal matching in the LOCAL model of distributed computing.
931181aa-1e4d-5913-ab75-05e17b7477f6|Distributed Algorithm for Unique Maximum Coloring with Hypergraph MIS and Coloring|The authors propose a distributed algorithm for solving the unique maximum coloring problem on hypergraphs with MIS and coloring in the LOCAL model of distributed computing.
7c996bd9-a3cf-510f-9e93-cae37a5aac4c|Distributed Algorithm for Unique Maximum Coloring with Hypergraph Maximal Matching and Coloring|The authors propose a distributed algorithm for solving the unique maximum coloring problem on hypergraphs with maximal matching and coloring in the LOCAL model of distributed computing.
0e1a3897-6784-5e32-b921-91618276169c|Distributed Algorithm for Hypergraph MIS with Unique Maximum Coloring, Coloring, and Maximal Matching|The authors propose a distributed algorithm for solving the MIS problem on hypergraphs with unique maximum coloring, coloring, and maximal matching in the LOCAL model of distributed computing.
84f82a35-4048-53e7-9926-e7558c6cd150|Distributed Algorithm for Hypergraph Maximal Matching with Unique Maximum Coloring, Coloring, and MIS|The authors propose a distributed algorithm for solving the maximal matching problem on hypergraphs with unique maximum coloring, coloring, and MIS in the LOCAL model of distributed computing.
176d5997-b946-543a-bfd3-1f0afc6162c5|Distributed Algorithm for Hypergraph Coloring with Unique Maximum Coloring, Coloring, and Maximal Matching|The authors propose a distributed algorithm for solving the coloring problem on hypergraphs with unique maximum coloring, coloring, and maximal matching in the LOCAL model of distributed computing.
95dcc822-3847-5224-9073-6ec8bc6a30c7|Distributed Algorithm for Unique Maximum Coloring with Hypergraph MIS, Coloring, and Maximal Matching|The authors propose a distributed algorithm for solving the unique maximum coloring problem on hypergraphs with MIS, coloring, and maximal matching in the LOCAL model of distributed computing.
3cc2d01c-a1e5-5488-9433-4a53cd20549e|Distributed Algorithm for Hypergraph MIS with Unique Maximum Coloring, Coloring, Maximal Matching, and Hypergraph Coloring|The authors propose a distributed algorithm for solving the MIS problem on hypergraphs with unique maximum coloring, coloring, maximal matching, and hypergraph coloring in the LOCAL model of distributed computing.
2925799a-229a-50c3-876a-36106a3419b8|Distributed Algorithm for Hypergraph Maximal Matching with Unique Maximum Coloring, Coloring, Maximal Matching, and Hypergraph Coloring|The authors propose a distributed algorithm for solving the maximal matching problem on hypergraphs with unique maximum coloring, coloring, maximal matching, and hypergraph coloring in the LOCAL model of distributed computing.
2e21bcf2-e13c-5fa3-a773-ad6528113dc5|Distributed Algorithm for Hypergraph Coloring with Unique Maximum Coloring, Coloring, Maximal Matching, and Hypergraph Coloring|The authors propose a distributed algorithm for solving the coloring problem on hypergraphs with unique maximum coloring, coloring, maximal matching, and hypergraph coloring in the LOCAL model of distributed computing.
8e521365-5b87-5963-8cbe-9b2968e0ac6a|Distributed Algorithm for Unique Maximum Coloring with Hypergraph MIS, Coloring, Maximal Matching, and Hypergraph Coloring|The authors propose a distributed algorithm for solving the unique maximum coloring problem on hypergraphs with MIS, coloring, maximal matching, and hypergraph coloring in the LOCAL model of distributed computing.
bc003dcc-588b-5bbb-9880-fccb04f05cce|Distributed Algorithm for Hypergraph MIS with Unique Maximum Coloring, Coloring, Maximal Matching, Hypergraph Coloring, and Hypergraph Maximal Matching|The authors propose a distributed algorithm for solving the MIS problem on hypergraphs with unique maximum coloring, coloring, maximal matching, hypergraph coloring, and hypergraph maximal matching in the LOCAL model of distributed computing.
6927b75a-f557-571b-8028-8dcc47bc085e|Distributed Algorithm for Hypergraph Maximal Matching with Unique Maximum Coloring, Coloring, Maximal Matching, Hypergraph Coloring, and Hypergraph Maximal Matching|The authors propose a distributed algorithm for solving the maximal matching problem on hypergraphs with unique maximum coloring, coloring, maximal matching, hypergraph coloring, and hypergraph maximal matching in the LOCAL model of distributed computing.
4ea8767e-7cb8-55ec-bc72-43ffc4942d19|Distributed Algorithm for Hypergraph Coloring with Unique Maximum Coloring, Coloring, Maximal Matching, Hypergraph Coloring, and Hypergraph Maximal Matching|The authors propose a distributed algorithm for solving the coloring problem on hypergraphs with unique maximum coloring, coloring, maximal matching, hypergraph coloring, and hypergraph maximal matching in the LOCAL model of distributed computing.
bd4d0c16-4e51-50de-aec3-2d875bf70e0f|Distributed Algorithm for Unique Maximum Coloring with Hypergraph MIS, Coloring, Maximal Matching, Hypergraph Coloring, and Hypergraph Maximal Matching|The authors propose a distributed algorithm for solving the unique maximum coloring problem on hypergraphs with MIS, coloring, maximal matching, hypergraph coloring, and hypergraph maximal matching in the LOCAL model of distributed computing.
871d934b-3b38-57fc-b442-80de5c47a305|Automatic Round Elimination Framework|The automatic round elimination framework is a general outline for proving lower bounds in the distributed setting. It provides a systematic way to apply the round elimination technique to a wide range of problems.
30f03b84-bf4b-515d-9521-234e512818a1|Decomposing a Problem|Decomposing a problem involves breaking down a complex problem into smaller sub-problems, each of which can be solved more efficiently.
0d98cff1-b2b2-52db-928c-5e9c1cf410ce|Relaxing a Problem|Relaxing a problem involves adding further configurations to the lists collecting the allowed configurations for the nodes or the hyperedges, at the cost of making the problem potentially easier to solve.
6ee52b53-cb57-595d-9479-88f41c6b0b88|Label Merging|Label merging involves combining multiple labels into a single label, in order to reduce the number of labels in the problem.
f994e490-683e-5b72-82aa-918b0c7b4abe|Hypergraph-Based Load Balancing|The authors propose a novel approach to load balancing in distributed systems by utilizing hypergraphs to model the system and its workloads. This method involves representing the system as a hypergraph, where nodes represent processors or nodes, and hyperedges represent tasks or workloads. The authors then apply hypergraph-based algorithms to optimize the distribution of workloads across the nodes, ensuring a more balanced and efficient allocation of resources.
23d9e781-9079-5a3f-a5e0-aef715134488|Distributed Load Balancing via Hypergraph MIS|The authors propose a distributed algorithm for load balancing in hypergraphs, which is based on the concept of maximal independent sets (MIS). The algorithm works by iteratively computing MIS in the hypergraph, which represents the system and its workloads. The MIS is then used to allocate tasks to nodes, ensuring a balanced distribution of workloads.
cd35159f-158c-58f8-935f-3ae03ea7eea0|Round Elimination-Based Load Balancing|The authors propose a novel approach to load balancing in distributed systems, which is based on the round elimination technique. This technique involves iteratively eliminating rounds of communication between nodes, while maintaining the correctness of the load balancing algorithm. The authors apply this technique to hypergraph-based load balancing, enabling a more efficient and scalable algorithm.
3448f787-b639-55eb-8b13-ca41f9412333|Interleaved Hash Table Layout|The authors propose an interleaved hash table layout to optimize GPU memory access for graph processing. This solution involves storing each level of a bucket consecutively instead of storing all the elements of a bucket consecutively, leading to coalesced global memory access in linear search.
165f8389-72e8-5116-be40-2a3d912265db|Caching Hash Table Elements in Shared Memory|The authors propose caching the first few items of each bucket in shared memory to reduce global memory access latency. This solution involves storing hashTable i:len in shared memory and interleaving the hash buckets of each hashTable to cache the first few items of each bucket in shared memory.
64f227b0-79cf-5fbb-ab8b-fa0ae894d6c4|Linear Search with Coalesced Memory Access|The authors propose using linear search with coalesced memory access to optimize GPU memory access for graph processing. This solution involves using linear search instead of binary search, which allows for coalesced global memory access and reduces memory access latency.
ebf02375-f197-5ee8-b037-a424b7a21e14|Degree-Aware Resource Allocation|The authors propose a degree-aware resource allocation mechanism to optimize GPU memory access for graph processing. This solution involves assigning more hash buckets, shared memory, and threads to large degree vertices to reduce memory access latency and improve performance.
f522dab0-c437-536e-9a0d-7c95e5caa281|Hashing-Based 2D Partitioning|The authors propose a hashing-based 2D partitioning scheme to optimize communication efficiency in distributed algorithms. This solution specifically addresses the challenge by reducing the number of communication rounds required for triangle counting.
9b796cc6-8021-52e8-8aba-737e9d0446ad|Collision and Workload Imbalance Co-Optimization|The authors propose a co-optimization technique to address both collision and workload imbalance in distributed algorithms. This solution specifically addresses the challenge by reducing the number of collisions and balancing the workload across vertices.
3759ff2b-a313-5898-91f0-5146c1e30be1|Virtual Combination for Workload Balancing|The authors propose a virtual combination method to balance the intra-vertex workload in distributed algorithms. This solution specifically addresses the challenge by reducing the number of idling threads and balancing the workload across vertices.
75fa1742-a752-57a5-a8dd-473ca56a5916|Atomic Operation-Based Dynamic Workload Assignment|The authors propose an atomic operation-based dynamic workload assignment mechanism to optimize communication efficiency in distributed algorithms. This solution specifically addresses the challenge by balancing the workload across vertices.
548e6699-0b31-5eba-b83b-f53771e06c30|Core Number Ordering for Maximal Clique Enumeration|This solution addresses the challenge of efficient graph dynamics processing by proposing a novel ordering of vertices based on their core numbers for maximal clique enumeration. The core number ordering is used to reduce the computational cost of MCE by minimizing the number of iterations and set intersections.
0d57bf79-2bbb-5a99-8a76-c48b600af717|Distributed Maximal Clique Computation with Prefix Trees|This solution addresses the challenge of efficient graph dynamics processing by proposing a distributed algorithm for maximal clique computation using prefix trees. The algorithm is designed to minimize computational costs and iterations by leveraging the properties of prefix trees.
51b12735-d12b-57d8-9318-d61ede00e6c0|LocalMCE Algorithm for Maximal Clique Enumeration|This solution addresses the challenge of efficient graph dynamics processing by proposing a novel algorithm for maximal clique enumeration, called LocalMCE. The algorithm is designed to minimize computational costs and iterations by leveraging local properties of the graph.
b3286a68-8706-5210-8f78-48bd07d3eba0|Update Maintenance for Maximal Cliques|This solution addresses the challenge of efficient graph dynamics processing by proposing an algorithm for update maintenance of maximal cliques. The algorithm is designed to minimize computational costs and iterations by leveraging the properties of prefix trees.
bccc70e1-40c6-53ca-b35a-1a300580751f|Data Distribution with Vertex Ordering|The authors propose a data distribution method that utilizes vertex ordering to reduce the amount of data being communicated in the distributed algorithm. By ordering the vertices based on their core number, degree, or degeneracy, the algorithm can minimize the number of edges that need to be distributed, resulting in improved communication efficiency.
fe74431b-6314-5b68-abe2-ecc7e6273f82|LocalMCE with Set Intersection Optimization|The authors propose an optimization technique for the LocalMCE algorithm that reduces the cost of set intersections. By intersecting smaller sets first, the algorithm can minimize the number of operations required, resulting in improved communication efficiency.
d6c55219-6732-5f39-839c-94242c65d1f1|Core Number Ordering|The authors propose using core number ordering to optimize load balance in distributed systems. This involves ordering the vertices of the graph by their core numbers, which helps to reduce the size of the subgraphs that need to be processed by each worker. The core number ordering technique is based on the concept of k-core decomposition, which is a method for decomposing a graph into subgraphs based on the degree of the vertices. By ordering the vertices by their core numbers, the authors can ensure that the subgraphs processed by each worker are more balanced, which helps to optimize load balance. The authors report that using core number ordering reduces the running time of the algorithm by a factor of 1.60 on average when the number of machines is doubled.
c5edf7ee-ee17-5230-b1f4-9facd94cd25c|Degeneracy Ordering|The authors propose using degeneracy ordering to optimize load balance in distributed systems. This involves ordering the vertices of the graph by their degeneracy numbers, which helps to reduce the size of the subgraphs that need to be processed by each worker. The degeneracy ordering technique is based on the concept of graph degeneracy, which is a measure of the minimum degree of a vertex in a subgraph. By ordering the vertices by their degeneracy numbers, the authors can ensure that the subgraphs processed by each worker are more balanced, which helps to optimize load balance. The authors report that using degeneracy ordering reduces the running time of the algorithm by a factor of 1.60 on average when the number of machines is doubled.
3703d027-8be0-5d11-97c9-f7f217c40a84|Distributed Graph Partitioning Algorithm|The authors propose a distributed graph partitioning algorithm that partitions the edge set of the network into three parts: Em, Es, and Er. This algorithm is designed to efficiently process dynamic updates in large graphs by minimizing computational costs and iterations.
95bf43d7-cfb0-5c3e-b706-7ff52a28fef4|Low Conductance Subroutine|The authors propose a low conductance subroutine that can be used to find a sparse cut in a subgraph with low conductance. This subroutine is designed to efficiently process dynamic updates in large graphs by minimizing computational costs and iterations.
2550325d-b898-51e0-b992-6f9c330b669f|High Diameter Subroutine|The authors propose a high diameter subroutine that can be used to find a sparse cut in a subgraph with high diameter. This subroutine is designed to efficiently process dynamic updates in large graphs by minimizing computational costs and iterations.
01eab559-ce97-58e9-876a-afa0c12f1f6b|Low Degree Subroutine|The authors propose a low degree subroutine that can be used to remove low-degree vertices from the graph. This subroutine is designed to efficiently process dynamic updates in large graphs by minimizing computational costs and iterations.
e6f3c573-8c56-5afc-a641-23d8dd39dff1|Distributed Nibble Algorithm|The authors propose a distributed nibble algorithm that can be used to find a sparse cut in a subgraph. This algorithm is designed to efficiently process dynamic updates in large graphs by minimizing computational costs and iterations.
0c6b0543-2b04-5fd3-a736-916d0f2fa44d|CRACKER Algorithm|The CRACKER algorithm is a distributed iterative algorithm designed to efficiently identify connected components in large graphs. It works by iteratively growing a tree for each connected component, removing nodes from the graph and reducing the amount of computation at each iteration.
0ce9a7ae-d47a-52d1-bc6e-9e8da9072993|Edge Pruning (EP) Optimization|The Edge Pruning optimization is a technique used to reduce the number of redundant edges created during the CRACKER algorithm’s MinSelection phase.
25de11dc-5fbb-579d-b7b1-88c192255bc7|Oblivious Seed (OS) Optimization|The Oblivious Seed optimization is a technique used to reduce the creation of high-degree vertices during the CRACKER algorithm’s seed identification phase.
b9c8ee9f-9e51-5293-86f5-dbf1e1cb4b53|Finish Computation Sequentially (FCS) Optimization|The Finish Computation Sequentially optimization is a technique used to reduce the number of MapReduce iterations during the CRACKER algorithm’s seed propagation phase.
e3bfa995-f54d-577c-a1a7-ccb682fe546f|Edge Pruning (EP)|The Edge Pruning (EP) solution is a technique used to reduce the number of messages exchanged between nodes in a distributed algorithm. It works by identifying and removing unnecessary edges in the graph, thereby decreasing the amount of communication required between nodes.
13ceb7dc-1b12-5730-941f-75eefffacf7e|Oblivious Seed (OS)|The Oblivious Seed (OS) solution is a technique used to reduce the number of seed identifications in a distributed algorithm. It works by identifying and propagating the smallest node identifier seen so far, without considering the actual seed value.
618177ad-3eaa-5bf9-bc88-ffcc0f8161fa|Finish Computation Sequentially (FCS)|The Finish Computation Sequentially (FCS) solution is a technique used to reduce the number of MapReduce iterations in a distributed algorithm. It works by gathering all nodes that still require processing into a single machine, allowing for sequential computation and reducing the number of iterations required.
c4feceb1-9a73-5912-8b69-f9f1882cd45a|Parallel Complex Coloring|The authors propose a parallel complex coloring algorithm to optimize GPU memory access for graph processing. This algorithm is designed to efficiently color the edges of a bipartite graph, which represents the memory access pattern of the graph processing application.
532ec906-3561-5f2c-af91-e328aab0dec9|Frame-based Scheduling|The authors propose a frame-based scheduling algorithm to optimize GPU memory access for graph processing. This algorithm is designed to schedule the memory access of graph processing applications in a frame-by-frame manner, allowing for efficient use of memory bandwidth.
9bc913f0-e5e0-5258-8f64-efbfaa7a8c71|On-Line Scheduling Algorithm|The authors propose an on-line scheduling algorithm to optimize load balance in distributed systems. This algorithm uses a parallel complex coloring algorithm to eliminate variables in the bipartite graph and schedules packets in real-time to minimize contention and maximize throughput.
7686219e-ff0f-5ea7-996c-95a6f02c3875|Batch Reconfiguration Scheduling|The authors propose a batch reconfiguration scheduling approach to efficiently process dynamic updates in large graphs. This method involves dividing the graph into smaller clusters and processing updates in batches, allowing for parallelism and reducing the number of iterations required to maintain graph structures.
0756e06e-7734-5871-8f23-a72476fdedfa|Small Separator Decomposition|The authors propose a small separator decomposition technique to divide the graph into smaller clusters, enabling efficient batch processing of updates. This technique involves identifying a small separator set that separates the graph into clusters with small diameters.
d7bc945f-2481-550a-b666-7b5eac50f9be|Distributed Computation of Schedules|The authors propose a distributed computation approach to efficiently compute batch reconfiguration schedules for large graphs. This method involves dividing the graph into smaller clusters and processing updates in parallel, using a distributed algorithm to compute the schedules.
71940a3f-1244-598d-95f9-0838896fa0c8|Distributed Vertex Cover Reconfiguration|The authors propose a distributed algorithm for vertex cover reconfiguration, which allows for the reconfiguration of multiple vertices concurrently while maintaining feasibility. This approach addresses the challenge of load balance optimization in distributed systems by enabling the efficient reconfiguration of vertex covers in a distributed setting.
6411d6d9-cce5-5893-bc5e-6f2774e137f3|Cactus Core Decomposition|The authors propose a cactus core decomposition algorithm that divides the graph into independent clusters, which can be reconfigured simultaneously. This approach addresses the challenge of load balance optimization in distributed systems by enabling the efficient decomposition of the graph into smaller subgraphs.
98865815-a521-5dd3-85ba-bd18a9382cc0|Svelto Architectural Template|The Svelto architectural template is a solution proposed by the authors to address the challenge of optimizing GPU memory access for graph processing. This template is designed to support single-cycle context switching, hide external memory access latency, maximize memory utilization, and provide dynamic load balancing. The Svelto template employs a hierarchical memory controller, a multi-channel memory interface, and a dynamic task scheduler to manage memory accesses. It also uses atomic memory operations to ensure consistency and provide a necessary element to guarantee the consistency model. The paper presents results showing that the Svelto architecture scales linearly when increasing the number of contexts, and that the context switching mechanisms do not introduce performance overheads. The architecture also demonstrates area efficiency, with reductions up to 50% in LUTs and 49.41% in Slices compared to previous approaches.
1f523105-2856-5152-8a6b-9a3e74da0eb8|Svelto Architecture Template|The Svelto architecture template is a novel solution proposed by the authors to address the challenge of efficient graph dynamics processing. It is a high-level synthesis methodology that generates custom accelerators optimized for irregular graph kernels. The template exploits both instruction-level and task-level parallelism, providing dynamic load balancing and maximizing external memory utilization through latency tolerance.
fe2efe56-9ed1-50ef-a977-85e0cc0c6196|Hierarchical Memory Controller|The Hierarchical Memory Controller is a solution proposed by the authors to optimize communication efficiency in distributed algorithms. It is designed to manage the arbitration of requests from workers to the top memory controller, ensuring efficient communication and minimizing latency.
c8d04e3e-62f2-5b32-af63-eae659609b73|Context Switching|Context Switching is a solution proposed by the authors to optimize communication efficiency in distributed algorithms. It allows workers to execute different tasks while waiting for memory operations to complete, reducing idle time and improving overall system performance.
d174053a-9d09-5a9d-8535-614481a51b3a|Parallel Memory Controller|The Parallel Memory Controller is a solution proposed by the authors to optimize communication efficiency in distributed algorithms. It is designed to handle the arbitration of requests from workers to the top memory controller, ensuring efficient communication and minimizing latency.
02a02c30-8380-5612-bf4a-ab3fef3926fe|Dispatcher|The Dispatcher is a solution proposed by the authors to optimize communication efficiency in distributed algorithms. It is responsible for distributing tasks to workers and managing the execution of tasks.
dd1181cf-b816-517e-8466-0d851d606c3c|Scheduler|The Scheduler is a solution proposed by the authors to optimize communication efficiency in distributed algorithms. It is responsible for managing the execution of tasks within a worker and ensuring that tasks are executed efficiently.
7f7b9fb8-7028-52a0-83ca-53af8711a171|Dynamic Task Scheduling with Context Switching|This solution addresses the challenge of optimizing load balance in distributed systems by employing dynamic task scheduling with context switching. The approach involves dynamically scheduling tasks to workers based on their availability and workload, and using context switching to quickly switch between tasks when a worker is idle or waiting for memory access.
f60b22bd-bd69-547b-a0be-2b8033eeec29|Parallel Memory Controller with Round-Robin Arbitration|This solution addresses the challenge of optimizing load balance in distributed systems by designing a parallel memory controller with round-robin arbitration. The approach involves using a parallel memory controller that manages memory requests from multiple workers and uses round-robin arbitration to ensure fair access to memory resources.
82bcd3ab-ec5b-523b-9a3c-a26edae8bfd3|Hybrid Task Decomposition Strategy|The authors propose a hybrid task decomposition strategy to optimize communication efficiency in distributed algorithms. This strategy involves decomposing tasks into smaller sub-tasks and processing them in parallel, while also considering the trade-off between solution accuracy and communication rounds.
5a763ea1-231d-5140-9eac-7fcf237ac4f6|Priority-based Task Scheduling with Global Task Queue|This solution addresses the challenge of optimizing load balance in distributed systems by introducing a priority-based task scheduling mechanism that utilizes a global task queue. The global task queue allows for the prioritization of tasks based on their computational requirements, ensuring that tasks with higher computational demands are executed first. This approach enables the system to effectively balance the workload across nodes, reducing the likelihood of straggler tasks and improving overall system performance.
67f15cf7-12fb-5769-bd36-30b2b6683d20|Dynamic Task Decomposition with Timeout Mechanism|This solution addresses the challenge of optimizing load balance in distributed systems by introducing a dynamic task decomposition mechanism that incorporates a timeout mechanism. The timeout mechanism allows the system to detect and decompose tasks that are taking too long to execute, preventing straggler tasks and improving overall system performance.
0923fb10-50e1-52d2-99e1-1c1b14eb3b14|Work Stealing with Load Balancing|This solution addresses the challenge of optimizing load balance in distributed systems by introducing a work stealing mechanism that incorporates load balancing. The work stealing mechanism allows idle nodes to steal tasks from busy nodes, reducing the likelihood of straggler tasks and improving overall system performance.
edc743db-0d89-54c9-b9da-605a893e83d5|Heuristic Weighted Memory Based Algorithm (HWMA)|The HWMA is a distributed algorithm designed to optimize the minimum weighted vertex cover (MWVC) problem in multi-agent systems. It employs a combination of local rules, including a weighted memory rule and a perturbation rule, to improve the quality of the resulting dominant Nash equilibrium (DNE) solutions.
3108c950-cc59-5819-b6c3-98b02c9001c9|Restricted Greed and Memory-Based Algorithm (RGMA)|The RGMA is a distributed algorithm designed to solve the MWVC problem by decomposing the system-level objective into local utilities. It employs a restricted greed rule and a memory-based rule to update player actions.
cdd06cae-684f-5db2-8725-fb1ada10f162|Fully Best Response (FBR) Algorithm|The FBR algorithm is designed to solve the MWVC problem by using an asymmetric game, where the utility of a player is co-determined by the actions and weights of neighboring nodes.
8220aa75-6725-58ff-8875-f0f8855ba34a|Restricted Greed and Memory Based Algorithm (RGMA)|The RGMA is a distributed algorithm designed to address the challenge of efficient graph dynamics processing by providing better approximation for the MWVC problem in multi-agent systems. The algorithm focuses on learning in potential games, where each vertex makes decisions using local information of its own and the immediate neighbors only.
6bf1f6cc-5a0e-576e-bfeb-338feac6dbe0|Asymmetric Game-Based Algorithm (FBR)|The FBR is a distributed algorithm designed to address the challenge of efficient graph dynamics processing by providing better approximation for the MWVC problem in multi-agent systems. The algorithm focuses on learning in potential games, where each vertex makes decisions using local information of its own and the immediate neighbors only.
e01af385-777a-50cd-b137-6c6464f1c62d|Perturbation Rule|The perturbation rule is a technique used in the HWMA to destroy the stability of inferior Nash equilibrium (INE) solutions. It involves recording one's best restricted response and 0 simultaneously, allowing the algorithm to converge to higher-quality Nash equilibria.
c5536c76-f1fd-5086-8a46-d6c1c09b3cb6|Weighted Memory Rule|The weighted memory rule is a technique used in the HWMA to update the actions of players based on their memories. It assigns a higher probability to ai=0 when i's neighbors could cover their adjacent edges with a lower average cost.
967b5186-57d7-5a4b-966d-adab4f489cb6|Time-Variant Binary Log Linear Learning Algorithm (TVBLLA)|The TVBLLA is a distributed optimization algorithm designed to solve the vertex cover problem in complex networks. It employs a novel cost function and a time-variant learning rate to drive the covering states of all vertices to converge to the minimum vertex cover (MVC) state of a general complex network.
38691116-7739-5c3d-8e52-effad72599db|Time-Variant Binary Log-Linear Learning Algorithm (TVBLLA)|The TVBLLA is a distributed optimization algorithm designed to solve the vertex cover problem in complex networks. It addresses the challenge of optimizing communication efficiency by allowing each vertex to update its strategy independently, reducing the need for extensive communication. The algorithm uses a time-variant learning rate to adapt to the changing environment and ensure convergence to the minimum vertex cover state.
c71e5efa-3e3d-5484-9714-b79dd760f4d9|Relaxed Greedy and Memory-Based Algorithm (RGMA)|The RGMA is a distributed optimization algorithm that addresses the challenge of optimizing communication efficiency by allowing each vertex to record the temporal strategy by the relaxed greedy rule of the latest step into its memory. This enables the algorithm to select a strategy from the memory with a certain probability, reducing the need for extensive communication.
8a7200d6-15eb-591f-a3bc-43b482701a83|Game-Based Memetic Algorithm (GMA)|The GMA is a hybrid algorithm that addresses the challenge of optimizing communication efficiency by combining a game-based approach with a memetic algorithm. The algorithm allows each vertex to evolve locally using the asynchronous updating rule and repeats each chromosome evolution for a certain number of generations.
334c8d8d-8379-5dbf-b2ef-a5044afe7e66|Binary Log-Linear Learning Algorithm (BLLA)|The BLLA is a distributed optimization algorithm that addresses the challenge of optimizing communication efficiency by allowing each vertex to update its strategy independently using a log-linear learning rule.
4f965afa-2c3b-5fa5-8105-c7b4d204140d|Genetic Algorithm (GA)|The GA is a centralized algorithm that addresses the challenge of optimizing communication efficiency by using a genetic approach to evolve the population of solutions.
4e75f5c8-8bbf-5bd7-b97b-7e40026f280d|LRBU Cache Structure|The LRBU cache structure is designed to efficiently manage remote vertices and their neighbors in the context of subgraph enumeration. It consists of three members: a cache to store remote vertices and their neighbors, an ordered set to track the order of remote vertices that can be safely removed from the cache, and a set to store the IDs of remote vertices that need to be fetched. The LRBU cache structure uses a two-stage execution strategy, where the first stage fetches the required remote vertices and the second stage performs the intersection to obtain the results. This approach allows for zero-copy and lock-free cache access, reducing memory copies and locks. The paper demonstrates that the LRBU cache structure outperforms other cache designs, such as LRU and concurrent LRU, in terms of execution time and memory usage.
d7c32a76-f7f3-590d-aec8-334e5cbb18f8|DFS-BFS Adaptive Scheduler|The DFS-BFS adaptive scheduler is designed to dynamically control the memory usage of subgraph enumeration. It adapts between BFS and DFS scheduling strategies based on the memory usage, ensuring that the memory bound is not exceeded. The scheduler uses a threshold to determine when to switch between BFS and DFS scheduling. When the memory usage exceeds the threshold, the scheduler switches to DFS scheduling to reduce memory consumption. The paper demonstrates that the DFS-BFS adaptive scheduler achieves a tight memory bound of 2 for subgraph enumeration, where is the number of query vertices and is the maximum degree of the data graph.
b5431b97-9b28-5aca-8c77-83586940d568|Work-Stealing Technique|The work-stealing technique is designed to balance the load among machines in a distributed environment. It allows machines to steal work from other machines that are overloaded, ensuring that the load is evenly distributed. The work-stealing technique uses a decentralized approach, where each machine is responsible for stealing work from other machines. This approach allows for efficient load balancing and reduces the overhead of centralized load balancing. The paper demonstrates that the work-stealing technique achieves better load balancing and reduces the execution time compared to other load balancing techniques.
11f6de5b-7833-507f-9914-7945bbbb7b5a|Hybrid Communication Layer|The hybrid communication layer is designed to support both pushing and pulling communication modes. It allows for efficient communication between machines in a distributed environment. The hybrid communication layer uses a combination of pushing and pulling communication modes to reduce communication overhead. It also uses a cache structure to store remote vertices and their neighbors, reducing the need for communication. The paper demonstrates that the hybrid communication layer achieves better performance and reduces communication overhead compared to other communication strategies.
d95c4677-baea-5151-a120-4a7ac6595826|Optimal Execution Plan|The optimal execution plan is designed to compute the optimal join order and physical settings for subgraph enumeration. It uses a dynamic programming approach to minimize the communication cost and computation time. The optimal execution plan uses a combination of join algorithms and communication modes to minimize the communication cost and computation time. It also uses a cache structure to store remote vertices and their neighbors, reducing the need for communication. The paper demonstrates that the optimal execution plan achieves better performance and reduces communication overhead compared to other execution plans.
cb5f0d9c-aa93-513d-870f-d36b781b3feb|Two-Stage Execution Mode|The authors introduce a two-stage execution mode that combines a lock-free and zero-copy cache design with a novel execution strategy. This approach enables efficient processing of subgraph enumeration queries while minimizing communication overhead.
2f043271-465d-5200-b45a-d336df9ac136|Batching RPC Requests|The authors propose batching RPC requests to improve network utilization and reduce communication overhead. This approach enables the system to aggregate multiple requests into a single batch, reducing the number of communication rounds.
94446bb7-1765-5d2d-adcc-a94448ead3b1|Adaptive Scheduling|The authors propose an adaptive scheduling approach that dynamically adjusts the scheduling strategy based on the characteristics of the data and the algorithm. This approach enables the system to optimize communication efficiency and minimize memory usage.
a78ff4a0-aec4-55dd-a19c-f9da353ad299|Work Stealing with Intra-Machine Deque|The authors propose a work stealing mechanism with an intra-machine deque to address load imbalance in distributed systems. This solution involves maintaining a deque in each worker, where partial results are injected and popped out for processing. When a worker completes its task, it sends its status to the first machine in the cluster, which then broadcasts the message to other machines. A list of finished machines is maintained, and their jobs are not stolen.
d7b56026-f25d-5062-8e6b-2594c2d7360f|Adaptive Scheduling with Output Queue|The authors propose an adaptive scheduling technique that uses a fixed-capacity output queue for each operator. The scheduler tends to let an operator consume as much input data as possible while preventing memory overflow by yielding when the output queue is full.
7032caf1-89ad-576e-9bfe-9027f6992746|Bulk Synchronous Parallel BSP Model|The authors propose using the Bulk Synchronous Parallel BSP model to design parallel algorithms for graph pattern matching. This solution specifically addresses the challenge of efficient graph dynamics processing by allowing for the concurrent computation of multiple vertices in the graph, reducing the overall computational cost and iterations required for graph updates.
d59fd9fa-c7ed-56b3-8db8-19e51c132e20|Unidirectional Relaxation Simulation URS|The authors propose the Unidirectional Relaxation Simulation URS algorithm, which extends graph simulation by allowing partially absent vertices. This solution specifically addresses the challenge of efficient graph dynamics processing by reducing the number of iterations required for graph updates and allowing for more flexible graph matching.
e311e5ed-e628-5785-8c33-7b988b28487d|Dual Relaxation Simulation DRS|The authors propose the Dual Relaxation Simulation DRS algorithm, which extends the URS algorithm by considering both child and parent nodes. This solution specifically addresses the challenge of efficient graph dynamics processing by further reducing the number of iterations required for graph updates and allowing for more flexible graph matching.
7a598385-43ef-5373-b08d-d030c48ef931|Bidirectional Communication in Dual Relaxation Simulation (DRS)|The authors propose a solution to optimize communication efficiency in distributed algorithms by introducing bidirectional communication in the Dual Relaxation Simulation (DRS) algorithm. This approach allows vertices to send messages to both their matched parents and children, reducing the need for additional communication rounds.
7eb60330-2606-5199-a4f5-dc7570f02e11|Hierarchical Graph Partitioning Algorithm (HGPA)|HGPA is a distributed algorithm designed to efficiently compute Personalized PageRank Vectors (PPVs) in large graphs. It addresses the challenge of efficient graph dynamics processing by utilizing a hierarchical graph partitioning approach to minimize computational costs and iterations.
046e24e7-cb1d-5aa0-be49-976c23c34408|Distributed Partial Vectors Computation|This solution involves computing partial vectors for all nodes in parallel using the selective expansion algorithm. It addresses the challenge of efficient graph dynamics processing by reducing the computational cost and iterations required for PPV computation.
6539300d-a154-5c11-b5cb-50346698581e|Hub Node Selection|This solution involves selecting hub nodes to partition the graph into smaller subgraphs. It addresses the challenge of efficient graph dynamics processing by reducing the computational cost and iterations required for PPV computation.
864963bc-0d12-5f05-a37a-b5a9266d8544|Distributed Skeleton Vectors Computation|This solution involves computing skeleton vectors for all nodes in parallel on separate machines, utilizing a dynamic programming algorithm.
eaba690c-83d1-5dd8-9f06-52b079f076e2|Distributed Betweenness Centrality Computation|The authors propose a distributed algorithm for computing betweenness centrality in dynamic graphs, which enables every node to compute its own centrality by exchanging messages with its neighbors. The algorithm is based on a distributed implementation of the dynamic programming algorithm by Brandes, which is well-suited for a distributed implementation. The algorithm uses a constant number of elementary operations per message, making it efficient for large graphs. The authors demonstrate the effectiveness of their algorithm through simulations, showing that it converges in a number of distance vector phases proportional to the diameter of the network.
cf32c3c6-11cd-5465-a22c-0008814311f5|Distributed Computation of Betweenness Centrality|The authors propose a distributed algorithm for computing betweenness centrality in a network, which is a measure of the proportion of shortest paths between all pairs of nodes that pass through a given node. The algorithm is designed to minimize the number of communication rounds while maintaining solution quality.
e6e85d54-2e04-5286-a7cc-880c24d7a5c5|Load Centrality Computation|The authors propose a distributed algorithm for computing load centrality, which is a measure of the amount of traffic that passes through a given node in a network. The algorithm is designed to minimize the number of communication rounds while maintaining solution quality.
47f5ed97-0368-5c43-9b23-f646540503cc|Distributed Betweenness Centrality Algorithm|The authors propose a distributed algorithm for computing betweenness centrality in a network, which can be used to optimize load balance in distributed systems. The algorithm enables each node to compute its own betweenness centrality value, which can be used to determine the optimal frequency of sensing its neighbors.
634168e7-37f1-56b8-b679-e380c28477a1|Load Centrality-based Optimization|The authors propose using load centrality, a related measure to betweenness centrality, to optimize load balance in distributed systems. Load centrality is defined as the amount of flow passing through a node, and the authors show that it can be used to determine the optimal frequency of sensing its neighbors.
d55fb7e9-9ca9-587e-a5a9-ffd1052a0815|Adaptive Sampling for k-Core Decomposition|The authors propose an adaptive sampling technique for k-core decomposition, which efficiently processes dynamic updates in large graphs by iteratively estimating the coreness of all nodes in the graph through the analysis of sparse subgraphs. The solution involves adaptively sampling edges with different probabilities in denser areas of the graph and less aggressively in sparser areas. This approach allows for the efficient estimation of coreness numbers and the maintenance of the k-core decomposition under dynamic updates. The paper demonstrates the effectiveness of this solution through experiments on real-world graphs, showing that the adaptive sampling technique achieves a good approximation of the coreness numbers while using significantly less memory than the input graph.
3725b8c2-dbf3-5174-9208-0adee2908734|Adaptive Edge Sampling|The authors propose an adaptive edge sampling technique to optimize communication efficiency in distributed algorithms. This technique involves sampling edges with different probabilities in different areas of the graph, with denser areas being sampled more aggressively. The adaptive edge sampling technique uses a carefully designed probability distribution to sample edges, which allows for a balance between reducing round complexity and maintaining solution quality. This approach is different from existing methods that use uniform sampling or fixed probability distributions. The paper demonstrates that the adaptive edge sampling technique can achieve a significant reduction in round complexity while maintaining a good approximation ratio. Specifically, the authors show that their algorithm can compute a 1-approximate k-core decomposition in O(log n) rounds, which is a significant improvement over existing algorithms.
541486a3-46a1-590b-ad65-a2744f43cf53|Adaptive Edge Sampling Strategy|The authors propose an adaptive edge sampling strategy to optimize load balance in distributed systems. This strategy involves sampling edges with different probabilities in different areas of the graph, with denser areas being sampled more aggressively.
5685b401-dff5-5ef9-af4c-4c5fd4d51681|MapReduce-based Algorithm|The authors propose a MapReduce-based algorithm to compute an approximate k-core decomposition of a graph in O(log n) rounds of computation.
d891fd75-a435-5297-80ab-03ced3491b13|Semi-Streaming Algorithm|The authors propose a semi-streaming algorithm to compute an approximate k-core decomposition of a graph in one pass using only O(n) space.
1e2e7105-79fc-5755-8f1c-cbaaae7c8389|Order-Independent MIS Computation (OIMIS)|OIMIS is a distributed framework for computing a near-maximum independent set in large dynamic graphs. It relaxes the order dependency in existing algorithms, making it more efficient and effective for dynamic graph updates.
c723f8c6-6c08-503b-8b73-737aca3dba2d|Dynamic OIMIS (DOIMIS)|DOIMIS is an extension of OIMIS for handling dynamic graph updates. It activates affected vertices and their neighbors to re-run the algorithm, ensuring the maintenance of a high-quality independent set.
3f353c34-a91e-512d-b6c1-43daf92230ec|Lower-Ranking Activation|This optimization technique reduces the number of active vertices in OIMIS and DOIMIS by only activating lower-ranking neighbors.
2117dd0e-2f19-593f-bee8-dc1a54c83003|Same-Status Activation|This optimization technique further reduces the number of active vertices in OIMIS and DOIMIS by only activating same-status neighbors.
5a09b453-a00f-58c2-974c-9154a3abb264|Batch Update Processing|This solution enables OIMIS and DOIMIS to process batch updates efficiently by activating affected vertices and their neighbors.
a6e2a602-da77-5c0f-bfda-d7609edec26f|Lower Ranking Activation|This solution specifically addresses the challenge of optimizing load balance in distributed systems by reducing the number of active vertices in each superstep, thereby decreasing computation and communication costs. The unique mechanism involved is the selective activation strategy, which only activates lower-ranking neighbors for each vertex, significantly reducing the number of active vertices and the associated costs.
0f816ec2-e198-52f6-8f75-5066468afd7b|Same Status Activation|This solution addresses the challenge of optimizing load balance in distributed systems by reducing the number of active vertices in each superstep, thereby decreasing computation and communication costs. The unique mechanism involved is the selective activation strategy, which only activates vertices with the same status, reducing the number of active vertices and the associated costs.
7c624f9d-1673-5f2b-8c1d-f1e83f8c3302|Localized Distributed Algorithm for Vertex Cover|The authors propose a localized distributed algorithm for detecting vertex cover using 2-hop local neighborhood information in distributed systems. This algorithm addresses the challenge of efficient graph dynamics processing by minimizing the number of nodes in the vertex cover, which is essential for maintaining graph structures under updates. The algorithm uses a scoring-based mechanism to minimize the number of nodes in the vertex cover by identifying nodes that cover more edges than others. Each node decides about its neighbors’ status in or out of the vertex cover based on the total edges and 1-hop neighbors in the subgraph. The algorithm has a time complexity of O(Δ^2), where Δ is the maximum node degree. The authors conducted a detailed computational analysis and compared their algorithm with existing distributed algorithms on three different benchmark sets. The analysis showed that the proposed algorithm generates smaller vertex covers than the other algorithms in all benchmarks, with an average difference of more than 11 in some evaluated graph instances.
d95dd427-f3cb-5216-a597-3b4e9659c872|2-Hop Local Neighborhood Information-Based Distributed Algorithm|The authors propose a distributed algorithm that utilizes 2-hop local neighborhood information to construct the vertex cover of a given network. This approach enables nodes to make decisions based on their local subgraph, reducing the need for extensive communication.
e56e8da2-f3f9-5143-b710-e4694a9736d2|Distributed Tip Maintenance Algorithm (DTMA)|DTMA is a distributed algorithm designed to efficiently maintain the tip numbers of vertices in large-scale dynamic bipartite graphs. It addresses the challenge of efficient graph dynamics processing by utilizing a task-split strategy to break down complex updates into smaller sub-tasks, which are then processed in parallel.
a3b6a4c7-cf34-5c22-9b61-7e0cd87e88a9|Message Aggregation Strategy|The message aggregation strategy is a technique used to reduce massive redundant messaging and avoid memory overflow problems while processing large-scale graphs. It addresses the challenge of efficient graph dynamics processing by aggregating messages from vertices and sending them to machines, rather than sending individual messages to neighbors.
88448eef-c7c9-56af-a519-b64d546c9369|Distributed Butterfly Counting Algorithm (DBCA)|DBCA is a distributed algorithm designed to efficiently count the number of butterflies in large-scale bipartite graphs. It addresses the challenge of efficient graph dynamics processing by utilizing a priority-based message passing strategy to reduce the number of messages sent and received.
c8206b45-276f-5f87-bbc2-185c55ce95d7|Task Split Strategy|The authors propose a task split strategy to maintain tip numbers when given bipartite graphs are updated. This strategy involves generating sub-tasks for each updated edge and processing them in serial.
24fd445f-5693-5c0b-8b99-6de7952e8f42|Candidate Sharing Theory|The authors propose a candidate sharing theory to reduce redundant computation of sub-tasks with two same endpoints.
e88e6ba6-2cfe-5aa4-bcc1-35848d261924|Task-Split Strategy|The authors propose a task-split strategy to maintain tip numbers when given bipartite graphs are updated. This strategy involves breaking down the complex problem into several sub-tasks, each of which is processed in serial.
b60e1659-d2ad-5e29-95a8-797d5874be04|Update Combination Mechanism|The authors propose an update combination mechanism to reduce data communication in the scatter phase of the edge-centric graph processing paradigm. This mechanism combines updates that have the same destination vertex before writing them into the external memory, thereby reducing the volume of data written into the external memory.
5327b52a-df81-577b-bb93-8f274e4e5736|Optimized Data Layout|The authors propose an optimized data layout to improve external memory performance and reduce data communication between the FPGA and external memory. This layout sorts the edges of each shard based on the destination vertices, enabling consecutive updates with the same destination vertex to be easily combined.
6cb72587-d8ee-5eb4-9bcf-0f9261d70653|Vertex Buffering|The authors propose vertex buffering to buffer vertex data in the on-chip RAMs of the FPGA, reducing the need for external memory accesses and improving performance.
d72e068e-e176-5b5e-a137-d06e67ce5088|Parallel Pipelined Processing|The authors propose parallel pipelined processing to concurrently process distinct edges or updates of each shard, improving performance and reducing the need for external memory accesses.
e1c03b93-38d9-592d-845d-97d2c445efa8|Inter-Partition Parallelism|The authors propose inter-partition parallelism to concurrently process distinct partitions, improving performance and reducing the need for external memory accesses.
a45de90e-2541-57e9-918c-53f7a516955f|Intra-Partition Parallelism|The authors propose intra-partition parallelism to concurrently process distinct edges or updates of each partition, improving performance and reducing the need for external memory accesses.
c026657d-cc2f-59c1-9ccf-31544fbaf836|TrIndexing|TrIndexing is a technique used to precompute and index the triangles (3-cycles) of the graph to facilitate pruning and reduce communication cost. TrIndexing involves grouping vertices that are connected to the same set of vertices, allowing for local computation of intersections and reducing the need for communication. The paper shows that TrIndexing can greatly improve the performance of BinJoin and WOptJoin algorithms, especially when the graph is dense.
0c6b5e81-19e2-5503-8328-e660afee3d2f|Compression|Compression is a technique used to maintain intermediate results in a compressed form to reduce maintaining and communication cost. Compression involves compressing the intermediate results by representing them as intersections of vertex covers, reducing the size of the data that needs to be communicated. The paper shows that Compression can improve the performance of BinJoin and WOptJoin algorithms, especially when the graph is sparse.
57ed1b8a-4f00-590e-a01b-5dbd01f790fa|Batching|Batching is a technique used to divide the computation into sub-tasks that can be evaluated independently, reducing the need for communication. Batching involves partitioning the data vertices and computing the matches of the query graph in parallel, reducing the need for communication between workers. The paper shows that Batching can improve the performance of BinJoin and WOptJoin algorithms, especially when the graph is large.
93b31f85-e036-5192-8434-fc7d2fd41ea2|Binary Search-based Triangle Counting|The authors propose a binary search-based triangle counting approach to optimize GPU memory access for graph processing. This method involves using binary search to find triangles in the graph, which improves memory locality and reduces memory access overhead.
4704bc88-8751-51f9-b77a-fc87f2bbbe90|Edge Proxy-based Partitioning|The authors propose an edge proxy-based partitioning approach to optimize GPU memory access for graph processing. This method involves creating edge proxies to reduce memory access overhead and improve memory locality.
a78fd621-25c0-51b9-a779-03e5849fe53c|Proxy Edge-Based Partitioning Policy|The authors propose a novel application-agnostic graph partitioning strategy that eliminates almost all communication for distributed triangle counting. This approach is based on the proxy model of partitioning, where edges are distributed among host machines and cached copies of the endpoints (called proxy vertices) are created. One proxy for a vertex in the graph is designated as the master proxy, which is responsible for the vertex's canonical value. The unique mechanism involved in this solution is the creation of edge proxies to obtain an induced subgraph from vertex proxies. This allows local triangle counting to proceed without communication, as all edges of a triangle are present on the same host. The approach also ensures that each triangle is counted exactly once, even if it exists on multiple hosts. The authors demonstrate the effectiveness of this solution by achieving up to 1.6x speedup over the 2018 Graph Challenge champion, TriCore, on large graphs such as clueweb12.
4b6fa0f3-8005-5410-90f4-827a6a0f92f2|Binary Search-Based Intersection Method|The authors employ a binary search-based intersection method for finding triangles, which improves performance on GPUs due to better exploitation of memory bandwidth. This method involves using binary search to find the intersection of neighbor lists, which reduces the number of memory accesses and improves coalesced memory accesses on GPUs. The authors demonstrate the effectiveness of this solution by achieving a 1.54x speedup over IrGL, a Graph Challenge 2017 champion, on a single GPU.
019394b7-037c-5e47-a29a-0b07f4fb46eb|Proxy Edge-Based Partitioning|The authors propose a novel graph partitioning strategy that duplicates edges to avoid communication during triangle counting. This approach is designed to minimize communication overhead by ensuring that all necessary information for triangle counting is available locally on each host.
a916311f-2a02-5c56-bfa1-550ddca71eea|Binary Search-Based Intersection|The authors employ a binary search-based intersection method for finding triangles, which improves performance on GPUs due to better exploitation of memory bandwidth.
a1e82f20-d664-54db-9a70-00df87ae2901|Local Triangle Counting with Aggregation|The authors propose a local triangle counting approach that counts triangles independently on each host without communication, and then aggregates the local counts at the end to obtain the final triangle count.
3db49409-85d8-5b25-83ac-78772866c604|Proxy Edge Based Partitioning Policy|The authors propose a novel application-agnostic graph partitioning strategy that eliminates almost all inter-host communication during triangle counting. This approach is designed to optimize load balance in distributed systems by ensuring that each host has a balanced workload and can process its assigned tasks independently without requiring frequent communication with other hosts.
810c965e-663f-5d72-8cbf-c0796dedd891|Defective Coloring Algorithm|The authors propose a defective coloring algorithm to efficiently process graph dynamics. This algorithm is designed to minimize the number of colors used while ensuring that each vertex has a limited number of neighbors with the same color.
f9e4d093-9333-58cb-a2e5-8cf403f20ec6|Set Theoretic Method|The authors also propose a set theoretic method for computing defective colorings. This method uses a family of sets to assign colors to vertices, ensuring that each vertex has a limited number of neighbors with the same color.
d7cccd2d-9c9b-5ad8-a1e3-d63d99b2b482|KW Iterative Procedure|The authors use the KW iterative procedure to reduce the number of colors used in the defective coloring algorithm. This procedure is designed to iteratively reduce the number of colors used while ensuring that each vertex has a limited number of neighbors with the same color.
f19da02a-ac9d-57ee-8d67-4793f690aab8|Algorithm Ak|The authors propose Algorithm Ak, which is designed to compute a 1-coloring in O(log k) time. This algorithm uses a combination of the defective coloring algorithm and the KW iterative procedure.
5895ae19-ea0a-5961-a3da-278ce8dd1992|Algorithm J|The authors propose Algorithm J, which is designed to compute a 1-coloring in O(log log log n) time. This algorithm uses a combination of the defective coloring algorithm and the KW iterative procedure.
05ac2adb-4b1f-5403-be46-fe6666455651|Iterative Procedure for 1-Coloring|The authors present an iterative procedure for 1-coloring that builds upon their defective coloring algorithm. This procedure iteratively applies the defective coloring algorithm to reduce the number of colors used, ultimately achieving a 1-coloring.
92168e9c-11f7-551f-a921-529e71422145|Union 1-Cover Free Family Construction|The authors propose a construction for a union 1-cover free family, which is used in their defective coloring algorithm. This construction enables the algorithm to efficiently select colors for vertices while minimizing conflicts.
94049a3a-f2ed-5784-95b4-b48a719a5a5d|Combinatorial Method for Defective Coloring|The authors propose a combinatorial method for defective coloring that employs a different approach than their set-theoretic method. This method is designed to achieve efficient coloring in linear time.
7a375ced-5419-5557-b4db-b3cb8dbb9bc3|Distributed Delegates Partitioning|This solution addresses the challenge of efficient graph dynamics processing by introducing a novel graph partitioning technique called distributed delegates partitioning. This approach distributes the storage, computation, and communication of high-degree vertices (hubs) in large-scale free graphs among a set of delegates, ensuring a balanced partitioning of edges and reducing the computational costs associated with hub processing.
03ad88bc-f226-5a5a-b332-abc4c34c75b5|Asynchronous Visitor Queue Abstraction|This solution addresses the challenge of efficient graph dynamics processing by introducing an asynchronous visitor queue abstraction. This abstraction provides a framework for parallel graph algorithms to execute on traversed vertices with the ability to pass visitor state to other vertices, enabling efficient and adaptive processing of dynamic graph updates.
41743196-12f4-5eb8-9922-8bd0de63e86f|Routed Point-to-Point Communication|This solution addresses the challenge of efficient graph dynamics processing by introducing routed point-to-point communication. This approach reduces dense communication requirements by routing and aggregating messages through a synthetic network.
d73c8153-17ce-5e0c-9308-a3600537711f|Distributed Delegate Partitioning|The authors propose a novel technique called distributed delegate partitioning to optimize communication efficiency in distributed algorithms. This approach involves distributing high-degree vertices (hubs) across multiple partitions, creating a delegate tree structure to facilitate efficient communication and computation.
9a48e942-bdaa-5bbe-bcac-07650f4eb935|Asynchronous Visitor Queue|This solution addresses the challenge of optimizing load balance in distributed systems by providing a framework for asynchronous graph traversal that can effectively handle high-degree vertices and reduce communication overhead. The solution involves using an asynchronous visitor queue to manage graph traversal, which allows for efficient handling of high-degree vertices and reduces communication overhead by minimizing the number of messages required. The paper demonstrates that the asynchronous visitor queue framework can effectively handle high-degree vertices and achieve good scalability, with a weak scaling study showing excellent performance up to 131K cores.
22c66b03-ce33-5231-b853-38a2fa989e28|Distributed Multimodal Path Query Algorithm (ALGdmp)|"ALGdmp is a distributed algorithm designed to process multimodal path queries over large transportation networks. It aims to minimize communication efficiency by reducing the number of visits to each machine and the total network traffic. ALGdmp employs a novel approach by incorporating an automata that describes the regular language used in the query. It also uses a graph partitioning approach to accelerate the algorithm. The algorithm works in parallel, and each machine is visited only once, reducing the need for extensive communication. The paper reports that ALGdmp is parallel scalable, with a running time of O(m/k * n/k * log(n/k)), where m is the number of edges, n is the number of nodes, and k is the number of machines. The algorithm also achieves a significant reduction in network traffic, with a total network overhead of O(|Vf|^2)."
b2d3c5a7-8ac8-5a4e-b972-bfeaff3c52c7|Graph Partitioning Approach|"The graph partitioning approach is designed to accelerate the distributed multimodal path query algorithm (ALGdmp). It aims to minimize the number of edges and nodes in each fragment of the graph, reducing the communication overhead. The approach assigns a weight to each edge and node in the graph, based on the number of times they are accessed during the query processing. It then uses a graph partitioning strategy to divide the graph into fragments, minimizing the number of edges and nodes in each fragment. The paper reports that the graph partitioning approach achieves a good balance between query time and communication costs. The approach also reduces the network traffic, with a total network overhead of O(|Vf|^2)."
fd72fc73-3cca-5e1a-ba8c-bc9d4c95f9b5|Shortest Path Algorithm with Automata|"The shortest path algorithm with automata is designed to process multimodal path queries over large transportation networks. It aims to minimize communication efficiency by reducing the number of visits to each machine and the total network traffic. The algorithm incorporates an automata that describes the regular language used in the query. It uses a novel approach to compute the shortest path, by incorporating the automata into the shortest path computation. The paper reports that the algorithm achieves a significant reduction in network traffic, with a total network overhead of O(|Vf|^2). The algorithm also achieves a good balance between query time and communication costs."
db4d9b43-ab89-518a-beec-783f4fbccc1f|ALGdmp|ALGdmp is a distributed algorithm designed to process multimodal path queries over large transportation networks. It aims to optimize load balance by minimizing the number of visits to each machine, reducing network traffic, and achieving parallel scalability.
877eaaaa-597a-5564-a11a-69f77e46ce67|ALGprt|ALGprt is a graph partitioning strategy designed to divide the multimodal graph into balanced fragments, ensuring that each machine processes a similar amount of work.
7843ae2b-8221-5e96-9e40-84ceec2c5ef3|Function System|The function system is a mechanism used in ALGdmp to compute the least travel time from the source to the destination.
5d2ff702-8dba-567d-bda5-a76d15c0f86d|Hybrid Approach for Efficient Graph Dynamics Processing|The authors propose a hybrid approach that combines parallel Breadth-First Search (BFS) and Shiloach-Vishkin (SV) algorithms to efficiently process dynamic updates in large graphs. This approach dynamically selects the optimal algorithm based on the graph topology, using BFS for scale-free networks and SV for large diameter graphs.
b8b764eb-92ef-5858-a3f3-3cfe62710c13|Load Balancing for Efficient Graph Dynamics Processing|The authors propose a load balancing technique to optimize the performance of their parallel SV algorithm. This technique removes completed partitions along iterations, reducing the size of the working set and improving load balance among processes.
da20fd52-57fe-5e64-9eb6-69e5629d1882|Parallel SV Algorithm for Efficient Graph Dynamics Processing|The authors propose a parallel SV algorithm for efficient graph dynamics processing. This algorithm uses a novel edge-based approach to compute connected components in large graphs, reducing the number of iterations required for maintaining graph structures.
17ab5eb4-0c91-511d-ad22-d118f6cf9499|Load Balancing through Excluding Completed Partitions|This solution addresses the challenge of optimizing communication efficiency in distributed algorithms by excluding completed partitions from further processing, thereby reducing the amount of data that needs to be communicated among processors.
de802c8a-44c9-5e78-aaac-53cdd15feb9c|Parallel Sorting with Custom Reduction Operators|This solution addresses the challenge of optimizing communication efficiency in distributed algorithms by using parallel sorting with custom reduction operators to minimize the number of communication rounds.
cade77e6-b09a-51fc-9e73-4ea5de67b44a|Dynamic Approach for Runtime Algorithm Selection|This solution addresses the challenge of optimizing communication efficiency in distributed algorithms by dynamically selecting the most efficient algorithm at runtime based on the graph topology.
a06410e0-7454-5b98-b898-cfc5a240ad36|Load Balancing through Redistributing Active Tuples|This solution addresses the challenge of optimizing load balance in distributed systems by redistributing active tuples after each iteration of the parallel SV algorithm. The goal is to evenly distribute the active tuples across processors, reducing the imbalance of data distribution and its effect on the overall run time.
326a2f5e-0975-505c-9cb1-78022656763e|Removing Completed Components|This solution addresses the challenge of optimizing load balance in distributed systems by removing completed components along the iterations of the parallel SV algorithm. The goal is to reduce the size of the working set per each iteration, leading to a more balanced workload across processors.
ae00ac3a-6820-5b6d-855b-d13ade8f0452|Distributed Ensemble Learning for Graph Clustering|The authors propose a distributed ensemble learning algorithm for graph clustering that scales to graphs with billions of edges. This solution addresses the challenge of efficient graph dynamics processing by utilizing a highly scalable but weak learning strategy in an ensemble learning scheme on an Apache Hadoop cluster.
a0df87b2-f362-54c0-869b-02b495d141c7|Ensemble Learning with Distributed Label Propagation|The authors propose an ensemble learning approach to community detection in large-scale networks, which involves distributing the computation of multiple label propagation algorithms across different nodes in a Hadoop cluster. This approach enables the parallel computation of multiple partitions, reducing the overall communication complexity and improving the efficiency of the algorithm.
2facd658-3efb-5f7b-9f04-d7374be5fd65|Advanced Label Initialization Strategy|The authors propose an advanced label initialization strategy that assigns a different randomly chosen set of vertices a head start in the label propagation process. This approach helps to create a diverse ensemble of partitions, which is essential for achieving high-quality community detection results.
30030565-0c62-5606-be2e-e3face52af42|Core Group Detection with Maximal Overlap|The authors propose a core group detection approach that involves computing the maximal overlap of multiple partitions. This approach helps to identify the most stable and consistent community structures in the network.
3f2b1c7b-5384-5c9a-b5f1-bd639cd3f3be|Low Congestion Shortcut Framework|The authors propose the Low Congestion Shortcut Framework as a solution to address the challenge of efficient graph dynamics processing. This framework is designed to provide a universally optimal distributed algorithm for various graph problems, including shortest path and transshipment problems.
5b4370db-617c-595f-985a-a3245a20fbec|Graph-Based 1-Oblivious Routing via LDDs|The authors propose a graph-based 1-oblivious routing algorithm via Low-Diameter Decompositions (LDDs) as a solution to address the challenge of efficient graph dynamics processing. This algorithm is designed to provide an efficient and scalable solution for routing demands in dynamic graphs.
6ab87de9-5b86-56a9-b3ae-b639c0a21697|Distributed Oblivious Routing Evaluation|The authors propose a distributed oblivious routing evaluation algorithm as a solution to address the challenge of efficient graph dynamics processing. This algorithm is designed to provide an efficient and scalable solution for evaluating oblivious routing demands in dynamic graphs.
3918678a-619b-54a4-897d-8a438eaecd61|Distributed Minor Aggregation Model|The authors propose the Distributed Minor Aggregation Model as a solution to optimize communication efficiency in distributed algorithms. This model provides a high-level interface for describing distributed algorithms and can be used to succinctly describe many interesting distributed algorithms.
7cec4de5-f2a2-57b2-a2a3-4b5f880ec77c|Boosting Dual Approximate Solutions|The authors propose a boosting technique for dual approximate solutions as a solution to optimize communication efficiency in distributed algorithms. This technique aims to improve the approximation ratio of dual approximate solutions by using multiplicative weights or gradient descent.
c0709fbb-f0ec-5caf-b946-842131b492b5|Oblivious Routing via LDDs|The Oblivious Routing via LDDs solution is a method for constructing an oblivious routing that uses low-diameter decompositions (LDDs) to route demands in a distributed network.
9384c8fa-139b-5d17-8291-a124cfbf4561|Level-Based Distributed Algorithm for MWVC|The authors propose a level-based distributed algorithm for the Minimum Weight Vertex Cover (MWVC) problem, which aims to optimize communication efficiency by reducing the number of rounds required to achieve a 2-approximation solution. The algorithm introduces three modifications to the BCS Algorithm: (1) attaching levels to vertices based on their remaining weight, (2) decreasing the vault size as the level of the vertex increases, and (3) sending offers only to neighbors with the smallest level. These modifications enable the algorithm to reduce the number of rounds while maintaining a 2-approximation ratio. The paper shows that the algorithm achieves a round complexity of O(log log log log 1 / log log^2 log), which is an improvement over the existing O(log log log) bound.
547f73a4-92ba-5126-bc91-50a17d1342b2|Adaptive Vault and Bank Mechanism|The authors propose an adaptive vault and bank mechanism to optimize communication efficiency in the distributed algorithm for MWVC. The mechanism dynamically adjusts the vault and bank sizes based on the level of the vertex, allowing for more efficient allocation of weights and reducing the number of rounds required. The paper demonstrates that this mechanism enables the algorithm to achieve a 2-approximation solution with a reduced round complexity.
feb41b5a-99a6-5c0d-b702-1e20bf3f068b|Neighbor-Level-Based Offer Sending|The authors propose a neighbor-level-based offer sending mechanism to optimize communication efficiency in the distributed algorithm for MWVC. The mechanism sends offers only to neighbors with the smallest level, reducing the number of offers sent and received, and consequently, the number of rounds required. The paper shows that this mechanism contributes to the overall reduction in round complexity achieved by the algorithm.
0bf3ce21-b4c0-5954-8c73-62e77ed80e88|Random Layering Technique|The random layering technique is a method for analyzing the connectivity of a graph obtained through random edge sampling. It involves assigning each edge to a random layer and then analyzing the connectivity of the graph layer by layer.
b2db3fee-31a7-561c-a102-4c639b381f49|Distributed Cut Tester Algorithm|The distributed cut tester algorithm is a method for testing whether a given cut in a graph is a minimum cut. It involves running Thurimella's connected component identification algorithm on a subgraph of the original graph and then testing the connected components of the subgraph versus a given threshold.
9122020e-c169-5804-9641-0cdc2807b781|Matula's Approach for Min Cut Approximation|Matula's approach is a method for approximating the minimum cut in a graph. It involves finding a sparse certificate for k-edge connectivity of the graph and then using the sparse certificate to find a 2-approximation of the minimum cut.
2f07bdf0-4c61-510a-83d3-6057937934cf|Random Contraction Algorithm|The random contraction algorithm is a method for approximating the minimum cut in a graph. It involves randomly contracting edges in the graph until a minimum cut is found.
c2804cee-a472-552c-913c-558a4d580b80|Distributed Algorithm for Min Cut Approximation|The distributed algorithm for min cut approximation is a method for approximating the minimum cut in a graph in a distributed setting. It involves finding a sparse certificate for k-edge connectivity of the graph and then using the sparse certificate to find a 2-approximation of the minimum cut.
92bbd024-4d8b-534f-9f67-62213fdf20bb|Random Layering for Distributed Minimum Cut Approximation|This solution proposes a novel approach to approximating the minimum cut in distributed networks by utilizing random layering. The method involves sampling edges randomly and assigning them to different layers, which helps to reduce the number of communication rounds required to achieve connectivity.
4e0c6e13-8822-52a0-8961-e82d29af90f7|Matula's Approach for Distributed 2-Minimum Cut Approximation|This solution adapts Matula's centralized algorithm for finding a 2-minimum cut to the distributed setting. The approach involves finding a sparse certificate for k-edge connectivity and then using the random sparsification technique to approximate the minimum cut.
82fcd2cf-afc6-5561-9fdc-e1b489c3adde|Generalized Simulation Theorem for Distributed Protocols|This solution extends the simulation theorem of Das Sarma et al. to a larger family of networks and a slightly larger class of problems. The theorem provides a lower bound on the communication complexity of distributed protocols.
c99986d3-27e2-5f7d-bbde-4fcd3693365f|Push-Pull Optimization|The authors propose a Push-Pull optimization method to reduce the volume of communication in distributed triangle identification. This method involves an initial conditional pass over the data to determine whether to push or pull adjacency information for each target vertex. The Push-Pull optimization method is unique in that it dynamically decides whether to push or pull adjacency information based on the number of edges that will be sent to each target vertex. This approach reduces the communication volume by aggregating edges within an MPI rank and avoiding the overhead of pulling many vertices when a small number of nodes is used. The authors demonstrate that the Push-Pull optimization method reduces the communication volume by more than a factor of 10 on the web cc12 hostgraph dataset, even when using a large number of nodes.
3b2f25a4-963b-5aa7-88f7-c5eb26c03ac9|Asynchronous Communication using YGM|The authors utilize an asynchronous communication library called YGM, which leverages message buffering techniques and serialization to allow truly asynchronous computations. This library enables the exchange of messages of heterogeneous types simultaneously. YGM's message buffering strategy concatenates and transmits variable-length byte arrays as conventional MPI messages, and destination nodes deserialize the arrays back into their original data structure forms. This approach allows for the transparent communication of structured data with no additional overhead. The authors demonstrate that YGM enables scalable performance and composability with pre-built distributed containers, allowing for the efficient processing of large graphs.
408c3bde-ad3c-5602-83cc-9bf8e2db2af0|Degree-Ordered Directed Graph (DODGr) Storage|The authors propose a custom graph storage structure called DODGr, which stores the degree-ordered directed graph in a way that allows for efficient triangle identification. DODGr stores a unique identifier associated with each vertex as the key, and values are a pair containing vertex metadata and an adjacency list augmented to contain the necessary metadata. This approach reduces the storage requirement of vertex metadata from O(V) to O(E). The authors demonstrate that DODGr enables efficient triangle identification and reduces the storage requirement of vertex metadata.
b5c6dc67-e172-53db-9667-eef2b9fb62d5|Merge Path Intersection|The authors propose a merge path intersection technique for identifying triangles in a graph. This technique involves iterating through the adjacency lists of two vertices simultaneously to find common neighbors. The merge path intersection technique is unique in that it allows for the efficient identification of triangles by iterating through the adjacency lists of two vertices simultaneously. The authors demonstrate that the merge path intersection technique enables efficient triangle identification and is used in conjunction with the Push-Pull optimization method to reduce communication volume.
d67db8c8-6d09-5dcd-80f1-2ad487337a71|Push Pull Optimization|The authors propose a Push Pull optimization method to reduce communication volume in distributed triangle counting algorithms. This method involves determining the direction of sending adjacency information between compute nodes based on the degree of vertices, which helps to minimize the number of messages exchanged.
1ae65a80-1083-57c6-b670-f78b8fdae4fb|Message Buffering and Serialization|The authors propose using message buffering and serialization techniques to reduce the overhead of small messages in distributed algorithms. This involves buffering small messages until a threshold is reached or a flush is directed, and then aggregating them into a single large message.
3260ed71-ebdd-5d46-bfd5-67d160e73316|Distributed Counting Set|The authors propose using a distributed counting set to keep track of individual counts of different items seen across ranks. This structure stores a small cache on each rank and is useful for complicated surveys with multiple types of metadata triangles.
626b2305-f860-57f2-87fb-974ff0ebface|Message-Splitting Strategy|The authors propose a message-splitting strategy to optimize GPU memory access for graph processing. This strategy involves separating local messages and remote messages according to their destination vertices, which determines the destination machine to which the message needs to be sent. The message-splitting strategy is designed to reduce memory access overhead by minimizing the number of messages that need to be cached in the message buffer. By separating local and remote messages, the strategy enables each machine to send/receive messages to/from only one machine in each round, eliminating the need to cache messages in the message buffer. The paper does not provide specific quantitative results for this solution. However, it mentions that the message-splitting strategy can solve the problem of memory overflow caused by message delivery.
fab6a6cc-2cdd-544c-8e49-da77ac107976|Distributed Batch-Stream Combined Algorithm (DBCA)|DBCA is a novel algorithm designed to efficiently process batch and streaming edge updates in large dynamic graphs. It addresses the challenge of efficient graph dynamics processing by introducing a task assignment strategy based on the diversity of edge cores of updated edges. This strategy enables the algorithm to handle multiple tasks in parallel, reducing the number of iterations and computational costs.
d67a5195-7ce8-5c7c-9668-cb54e67d83eb|Incremental Core Maintenance Algorithm|The incremental core maintenance algorithm is designed to efficiently update the core numbers of vertices in response to edge insertions and deletions. It addresses the challenge of efficient graph dynamics processing by minimizing the number of iterations required to update the core numbers.
a26fb5ad-ad97-5270-b9f7-bbc4557dbf4e|Message Splitting Strategy|The authors propose a message splitting strategy to optimize communication efficiency in distributed algorithms. This strategy involves separating local messages and remote messages according to their destination vertices, which determines the destination machine to which the message needs to be sent.
ed041b2f-9e32-575f-a129-518aac0969d9|Priority Strategy for Interference Reduction|The authors propose a priority strategy to reduce interference between tasks processing in parallel. This strategy involves assigning tasks with different edge cores to different machines, ensuring that tasks with smaller edge cores are executed earlier.
01b766d0-c80a-52df-b80b-abc04f719e6c|Message Interaction Protocol|The authors propose a message interaction protocol to ensure the accuracy of results when processing multiple tasks in parallel. This protocol involves sending messages between tasks with different edge cores, ensuring that tasks with smaller edge cores are executed earlier.
95881c44-dc85-5f17-a35c-8c1bd846bfe7|Task Assignment Strategy based on Diversity of Edge Cores|The authors propose a task assignment strategy based on diversity of edge cores to optimize load balance in distributed systems. This strategy involves assigning tasks to machines based on the diversity of edge cores of updated edges. The task assignment strategy is designed to balance the load across machines by assigning tasks with different edge cores to different machines. This helps to minimize the impact of tasks on each other and reduce the number of supersteps required to perform tasks.
32c021d9-c06f-5445-8548-089aa0a9cb85|Bounded Rational Behavioral (BRB) Update Rule|The BRB update rule is a solution proposed by the authors to address the challenge of optimizing GPU memory access for graph processing. This solution focuses on designing an algorithm that can efficiently manage memory access patterns to leverage memory bandwidth effectively. The BRB update rule is specifically designed to mitigate memory access inefficiencies, including non-coalesced access and synchronization overhead, by ensuring coalesced memory access and minimizing synchronization latency.
c100807e-4b08-57f3-a1a5-59ef739c2bf2|Memory-Based Best Response (MBR) Update Rule|The MBR update rule is another solution proposed by the authors to address the challenge of optimizing GPU memory access for graph processing. This solution focuses on designing an algorithm that can efficiently manage memory access patterns to leverage memory bandwidth effectively. The MBR update rule is specifically designed to mitigate memory access inefficiencies, including non-coalesced access and synchronization overhead, by ensuring coalesced memory access and minimizing synchronization latency.
c133aee5-3954-5ac9-82a6-3976941c38c5|Spatial Snowdrift Game Model|The spatial snowdrift game model is a solution proposed by the authors to address the challenge of optimizing GPU memory access for graph processing. This solution focuses on designing a game-theoretic approach to optimize memory access patterns. The spatial snowdrift game model is specifically designed to mitigate memory access inefficiencies, including non-coalesced access and synchronization overhead, by ensuring coalesced memory access and minimizing synchronization latency.
129c4f29-b1fc-59a5-b11c-4a4e399e199f|Nash Equilibrium-based Vertex Cover Algorithm|The Nash equilibrium-based vertex cover algorithm is a game-theoretic approach to solving the vertex cover problem in dynamic graphs. It addresses the challenge of efficient graph dynamics processing by finding a Nash equilibrium in the spatial snowdrift game model, where each vertex makes decisions based on local information and adapts to changes in the graph structure.
8b3b134c-1d5c-55ee-9e75-d28c86945694|Hybrid Triangle Computation Method|The authors propose a hybrid method for triangle computation that combines binary search and sorted set intersection (SSI) to optimize GPU memory access for graph processing. This method is designed to minimize memory access inefficiencies by leveraging the strengths of both approaches.
d914366c-59af-5c3b-8613-fa18e29d1053|Caching RMA Accesses with CLaMPI|The authors propose using CLaMPI, a caching layer for RMA, to optimize GPU memory access for graph processing. CLaMPI caches remote data to reduce memory access latency and improve coalescing.
93be38c5-0e2d-518f-91e6-dc2188593cbb|Application-Defined Scores for Cached Entries|The authors propose using application-defined scores for cached entries to optimize GPU memory access for graph processing. This approach allows the caching layer to prioritize entries based on their reuse patterns.
6dd21bf2-f1e8-5d27-9bcc-55d530614e15|Asynchronous Computation with RMA|The authors propose using asynchronous computation with RMA to optimize GPU memory access for graph processing. This approach allows for overlapping computation and communication, reducing memory access latency.
56d023f2-f59e-546c-ac57-0fc9292b0814|Asynchronous Distributed Memory Algorithm for Triangle Counting and Local Clustering Coefficient (LCC) Computation|The authors propose a fully asynchronous distributed memory algorithm for both triangle counting and LCC computation, which removes synchronization overheads by using RMA one-sided operations to retrieve remote parts of the graph. The algorithm uses a 1D partitioning scheme to distribute the graph among processes, and each process computes the number of triangles for every locally owned vertex. The algorithm also exploits data reuse in the remote access pattern of LCC computations by caching RMA accesses using CLaMPI. The authors report a speedup of up to 14x from 4 to 64 nodes for the LiveJournal1 graph on distributed memory, and demonstrate how caching remote accesses reduces total running time by up to 73 with respect to a non-cached version.
27e26de8-f911-5b07-b37c-79d83a86ac08|Hybrid Strategy for Triangle Computation|The authors propose a hybrid strategy for triangle computation based on the frontiers, which combines binary search and sorted set intersection (SSI) methods. The hybrid strategy uses binary search for computing intersections when the degree of one vertex is significantly higher than the other, and SSI when the degrees are similar. The authors report that the hybrid strategy always performed better than using SSI or binary search exclusively, and achieved a speedup of up to 8 on a CPU.
40b5394e-5ec9-5707-ba42-66ac8d317dfb|Parallel Computation of Intersections|The authors propose computing the intersection of adjacency lists in parallel using OpenMP, which improves the performance of the hybrid strategy for triangle computation. The authors distribute work among threads by splitting the shorter keys array into equal-sized chunks for binary search, and splitting the longer array for SSI. The authors report a speedup of up to 2.7 using 16 threads compared to a sequential implementation.
282cd7da-2a6c-5ccb-8ee5-a3db28d947f8|Asynchronous Distributed Memory Triangle Counting and LCC with RMA Caching|The authors propose an asynchronous distributed memory algorithm for triangle counting and local clustering coefficient (LCC) computation, which utilizes Remote Memory Access (RMA) caching to optimize communication efficiency.
08eb8859-ac56-5675-884e-ff385b731f78|TwinTwig Decomposition|TwinTwig decomposition is a pattern decomposition strategy that decomposes the pattern graph into TwinTwigs, which are edges or two incident edges of a node. This decomposition strategy is used to reduce the size of the partial results and improve the performance of subgraph enumeration.
0b897965-0ed7-521d-bd87-5d74f39bb494|Order-Aware Cost Reduction|Order-aware cost reduction is an optimization strategy that reduces the cost of subgraph enumeration by considering the order of the TwinTwig decomposition. This strategy is used to minimize the cost of subgraph enumeration and improve the performance of the algorithm.
2ce1e7fd-dc99-5d37-9fba-7ac48c2ecd0d|Workload Skew Reduction|Workload skew reduction is an optimization strategy that reduces the workload skew caused by high-degree nodes in the data graph. This strategy is used to improve the performance of subgraph enumeration and reduce the workload skew.
12a4de72-631b-5002-be1a-9c042f6dc8aa|Early Filtering|Early filtering is an optimization strategy that uses bloom filters to filter out invalid partial matches in early stages of the algorithm. This strategy is used to reduce the size of the partial results and improve the performance of subgraph enumeration.
ed4b6764-c99a-51da-9ce5-414587853ca1|TwinTwigJoin|TwinTwigJoin is a novel algorithm for subgraph enumeration in MapReduce, which follows a left deep join framework with a new pattern decomposition strategy, namely, TwinTwig decomposition. This approach addresses the challenge of efficient graph dynamics processing by minimizing the computational cost and iterations required for subgraph enumeration in large graphs.
e052d54d-1017-56e6-9fb1-ae9bdd054a52|Iterative Vertex Elimination|The authors propose an iterative vertex elimination technique to efficiently process dynamic updates in large graphs. This technique involves iteratively eliminating vertices that do not meet local constraints imposed by the query pattern, thereby reducing the search space for pattern matching.
a3aca90b-1cad-5da8-b784-c679bf64c3ef|Token Passing for Cycle Detection|The authors propose a token passing approach to detect cycles of appropriate length in large graphs. This approach involves passing tokens through edges in the graph to verify whether a vertex participates in a cycle of the correct length.
725209ba-2d82-56aa-8c18-3448670e51be|Distributed Pattern Matching|The authors propose a distributed pattern matching algorithm to efficiently process dynamic updates in large graphs. This algorithm involves distributing the graph across multiple nodes and using a combination of local constraint checking and cycle checking to eliminate vertices.
da6afaa0-74f1-5829-92a3-b3f376fd7ff6|Token-based Cycle Checking|The authors propose a token-based cycle checking algorithm to optimize communication efficiency in distributed algorithms. This solution specifically addresses the challenge by minimizing the number of communication rounds required to verify cycle constraints in the graph.
f27ecb37-d182-50e8-9ff0-32a18b92873e|Asynchronous Visitor Abstraction|The authors propose an asynchronous visitor abstraction to optimize communication efficiency in distributed algorithms. This solution specifically addresses the challenge by allowing vertices to process visitors asynchronously, reducing the need for synchronization and minimizing communication rounds.
64e58da0-68c3-509e-a1e0-fbee5d54618a|Distributed Quiescence Detection|The authors propose a distributed quiescence detection algorithm to optimize communication efficiency in distributed algorithms. This solution specifically addresses the challenge by minimizing the number of communication rounds required to detect quiescence in the graph.
be908840-0104-5ad8-9a05-6f23e1fab300|HavoqGT's Delegate Partitioned Graph|The authors propose using HavoqGT's delegate partitioned graph to achieve load balancing. This approach distributes the edges of each high-degree vertex across compute nodes, ensuring that the workload is evenly distributed.
32fbd1a0-2136-5876-8711-df778fd15432|Distributed Aggregation Scheduling (DAS)|DAS is a distributed algorithm designed to efficiently manage dynamic updates in large graphs by minimizing computational costs and iterations. It focuses on maintaining graph structures such as maximal k-trusses under updates and efficiently adjusting centrality measures like betweenness in response to edge modifications.
da9ca2d9-471d-5fdb-9279-a72c6070a368|Adaptive Scheduling using DAS|This solution builds upon the DAS algorithm by introducing an adaptive scheduling mechanism that can handle dynamic updates in the graph. It focuses on minimizing the number of nodes that need to be rescheduled when the graph topology changes due to edge/vertex insertions/deletions.
5873dd6d-a76f-523e-911a-421078683ee0|Distributed Aggregation Scheduling (DAS) Algorithm|The DAS algorithm is a distributed algorithm designed to optimize communication efficiency in wireless sensor networks by minimizing the number of communication rounds required for data aggregation.
01d98177-4b7e-5912-ab5d-2d051c5919b1|Adaptive DAS Algorithm|The adaptive DAS algorithm is an extension of the DAS algorithm, designed to handle dynamic network changes, such as node failures and new node joinings.
2b09c6fb-1a6b-5784-af5f-9be53ec47657|Competitor Set Determination Method|The competitor set determination method is a novel technique used in the DAS algorithm to determine the competitor set of each node.
dfe2db17-9af6-55c2-9bca-b31d2c93570c|Tree Construction Algorithm|The tree construction algorithm is a novel method used in the DAS algorithm to create a distributed aggregation tree.
cd1afb5d-04ad-588a-aae6-e1c5bdaf898b|Trie-Based Data Structure for Intermediate Storage|The authors propose a novel trie-based data structure to store intermediate results during subgraph isomorphism computation. This data structure is designed to reduce memory footprint while maintaining good memory access efficiency.
3c71b2f7-82bf-51de-983f-42edd2536db9|Hybrid Scanning Strategy for Subgraph Isomorphism|The authors propose a hybrid scanning strategy that combines the benefits of depth-first search (DFS) and breadth-first search (BFS) strategies. This approach is designed to reduce memory usage and improve parallelism.
a65587c1-13b0-5f68-9cfa-00a9fbdd3566|Efficient Micro-Kernel Design for Intersection Operations|The authors propose an efficient micro-kernel design for intersection operations, which is a critical component of subgraph isomorphism computation.
623f795b-099e-5f71-8370-28e4ea081fd0|Distributed GPU Implementation for Subgraph Isomorphism|The authors propose a distributed GPU implementation for subgraph isomorphism computation, which is designed to handle larger datasets and complex query graphs.
a9f2c73b-4e53-5fd2-953a-4c65eac34d88|Trie-Based Data Structure for Efficient Graph Dynamics Processing|The authors propose a novel trie-based data structure to efficiently process dynamic updates in large graphs. This data structure is designed to minimize computational costs and iterations by allowing for swift recomputation of trussness values and adaptive adjustments to graph topology changes.
b3c71f63-e28f-5194-a769-2757b8d17d0e|Asynchronous Protocol for Work Distribution|The authors propose an asynchronous protocol for work distribution in the distributed implementation of their subgraph isomorphism algorithm. This protocol allows nodes to share their workload with other nodes without requiring synchronization, thereby minimizing communication overhead.
a5e37d3b-ddbf-5381-8399-b02b08f5e4d6|Adaptive Work Distribution Strategy|The authors propose an adaptive work distribution strategy to optimize load balance in distributed systems. This strategy involves dividing each outer iteration into several chunks and processing them sequentially. At the end of each chunk, busy nodes check if any free nodes are available to share the workload. If a free node is found, the busy node sends a portion of its work to the free node along with the required data, and this process is repeated until the entire work is done.
0ba583af-620c-5072-a505-42d81093f585|Virtual Warp Strategy|The authors propose a virtual warp strategy to optimize load balance in distributed systems. This strategy involves grouping paths based on the work into bins and using virtual warps to process the bins. Each warp processes a set of paths, reducing thread idling and improving load balance.
c14d8734-8f54-5475-a159-3c936b820cca|Trie-Based Data Structure|The authors propose a trie-based data structure to optimize load balance in distributed systems. This data structure allows for efficient storage and retrieval of intermediate results, reducing memory requirements and improving load balance.
f32626b4-aab7-5ba8-af49-b96d8be98f3b|Partition-Centric Processing Methodology (PCPM)|PCPM is a novel approach that perceives a graph as a set of links between nodes and partitions, rather than nodes and edges. This abstraction enables the development of a new data layout and system-level optimizations that reduce memory access inefficiencies.
e8d6368a-54eb-5e44-8546-9b6e02700e2f|Binning with Vertex-Centric Processing|Binning is a technique used in conjunction with Vertex-Centric processing to reduce memory access inefficiencies. It stores updates in a semi-sorted manner, inducing spatio-temporal locality in access patterns.
bc637934-e226-595b-a5f3-24f32fe48964|Graph Reordering with GOrder Algorithm|The GOrder algorithm is used to reorder the nodes in the graph, improving spatial locality and reducing memory access inefficiencies.
daeef533-373b-559d-950d-729fe5eecc23|Partition Centric Processing Methodology (PCPM)|PCPM is a novel approach to efficient graph dynamics processing that perceives a graph as a set of links between nodes and partitions, rather than nodes and edges. This abstraction enables the reduction of redundant edge traversals and random memory accesses, while retaining the benefits of the Gather-Apply-Scatter (GAS) model.
e8b9fb21-c472-51ae-8c16-dd71b2522d46|Bipartite Partition-Node Graph (PNG) Data Layout|PNG is a new data layout that reduces communication and random memory accesses by compressing edges and storing them in a semi-sorted manner.
2577c54b-6946-5918-8803-954b68d169a0|Branch Avoidance Mechanism|The branch avoidance mechanism removes unpredictable branches in the gather phase of PCPM, enhancing sustained memory bandwidth and reducing execution time.
1cc6cf3e-7997-51f3-bab9-38f088b02a2b|Intelligent Node Labeling|Intelligent node labeling is a technique that enhances locality in graphs, reducing the number of random memory accesses and improving performance.
94370dc5-cc86-53cf-be04-0c8dfc5355c0|Binning with Vertex-Centric GAS (BVGAS)|BVGAS is a methodology that allocates multiple bins to store incoming messages, reducing the number of communication rounds by inducing spatio-temporal locality in access patterns.
92223208-ca4e-526f-9eab-441b3e5ab683|Pull Direction PageRank (PDPR)|PDPR is a methodology that optimizes communication efficiency by using a pull direction approach, which enables all columns of the adjacency matrix to be traversed asynchronously in parallel without the need to store partial sums in memory.
17f2e7e3-de14-5518-a6ec-817b37e000b1|External Neighbor Expansion|This solution addresses the challenge of efficient graph dynamics processing by proposing a technique called external neighbor expansion. This technique ensures that all relevant edges that span partitions are available in local memory, which guarantees that there will be no false negatives when determining the frequent single edge patterns.
f9e21883-8172-515a-94e4-2b03cabded44|Support Bound Pruning|This solution addresses the challenge of efficient graph dynamics processing by proposing a two-step support bounding technique. This technique allows for the pruning of patterns that cannot possibly be globally frequent, reducing the communication cost and run times.
a66a1128-3bd4-54f4-9fd0-d949fcd1086f|Local Support Computation|This solution addresses the challenge of efficient graph dynamics processing by proposing a local support computation technique. This technique allows for the computation of the local support of each pattern P in each partition Gi, without requiring the computation of the global support.
248ab4b0-24ca-5547-b0fd-f8117c1f19d4|Two-Step Support Bounding Technique|The authors propose a two-step support bounding technique to minimize communication efficiency in distributed algorithms. This technique involves determining patterns that are definitely globally frequent and infrequent, and then eliminating patterns that cannot possibly be globally frequent.
ed25e37c-5ac7-5dea-a0a4-5fb80e04b45d|Regeneration of Embeddings|The authors propose a regeneration of embeddings technique to minimize communication efficiency in distributed algorithms. This technique involves regenerating the embeddings for each pattern in a distributed manner.
67b33573-dd69-5e49-8f17-4467cee5c660|Collective Communication Primitives|The authors propose the use of collective communication primitives to minimize communication efficiency in distributed algorithms. This technique involves using primitives such as AllToAll and AllGather to minimize communication.
ffe32441-0ed3-5550-ad96-df7fc6377e0b|Hybrid Load Balancing via Partitioning and Multi-threading|The authors propose a hybrid approach that combines graph partitioning with multi-threading to optimize load balance in distributed systems. This solution involves dividing the input graph into multiple partitions and processing each partition using multiple threads within a compute node.
c5c8e40f-bbc2-55a4-8628-074af46cfe20|Support Bounding for Load Balancing|The authors propose a support bounding technique to prune patterns that are not globally frequent, which helps to reduce the amount of communication and computation required for load balancing.
c8b14ae7-388c-5976-8ccd-f5179fda4182|External Neighbor Expansion for Load Balancing|The authors propose an external neighbor expansion technique to reduce the amount of communication required for load balancing. This technique involves collecting external neighbor requests for each pattern and storing them in a set for later use.
