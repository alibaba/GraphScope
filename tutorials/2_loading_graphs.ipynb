{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Copyright &copy; 2020 The Alibaba Authors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GraphScope models graph data as [property graph](https://github.com/tinkerpop/blueprints/wiki/Property-Graph-Model), in which the edges/vertices are labeled and have many properties. In this tutorial, we show how GraphScope load graphs, including\n",
    "\n",
    "- How to define the schema of a property graph;s\n",
    "- Simplified forms to load a graph;\n",
    "- Loading graph from various locations;\n",
    "- Serializing/Deserializing a graph to/from disk.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Schema\n",
    "\n",
    "First, we launch a session and import necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import graphscope\n",
    "from graphscope.framework.graph import Graph\n",
    "from graphscope.framework.loader import Loader\n",
    "import vineyard\n",
    "\n",
    "k8s_volumes = {\n",
    "    \"data\": {\n",
    "        \"type\": \"hostPath\",\n",
    "        \"field\": {\n",
    "          \"path\": \"/home/jovyan/datasets\",  # Path in host\n",
    "          \"type\": \"Directory\"\n",
    "        },\n",
    "        \"mounts\": {\n",
    "          \"mountPath\": \"/testingdata\"  # Path in pods\n",
    "          \"readOnly\": True\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "graphscope.set_option(show_log=True)  # enable logging\n",
    "sess = graphscope.session(k8s_volumes=k8s_volumes)  # create a session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the function `load_from` to load a graph. In this function, it will\n",
    "\n",
    "1. build the configurations of vertices and edges\n",
    "2. validate the configurations\n",
    "3. load data into memory and construct a `graphscope.Graph` object for subsequent usage.\n",
    "\n",
    "The basic form of `load_from` looks like this:\n",
    "```python\n",
    "load_from(edges, vertices=None, directed=True, oid_type=\"int64_t\", generate_eid=True)\n",
    "```\n",
    "Next, we give introductions to the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### edges\n",
    "\n",
    "Required.\n",
    "\n",
    "`edges` is a `Dict`. Each item in the dict determines a label for the edges. More specifically, the key of the pair item is the label name, the value of the pair is a configuration Tuple or List, which contains:\n",
    "\n",
    "- a `Loader` object for data source, it tells graphscope where to find the data for this label, it can be a file location, or a numpy array, etc.\n",
    "\n",
    "- a list of properties, the names should consistent to the header_row of the data source file. This list is optional. When it omitted or empty, all columns except the src/dst columns will be added as properties.\n",
    "\n",
    "- a pair of str for the edge source, in the format of (`column_name_for_src`, `label_of_src`);\n",
    "\n",
    "- a pair of str for the edge destination, in the format of (`column_name_for_dst`, `label_of_dst`);\n",
    "\n",
    "Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges={\n",
    "    # a kind of edge with label \"knows\"\n",
    "    \"knows\": (\n",
    "        # the data source, in this case, is a file location.\n",
    "        Loader(\"/testingdata/ldbc_sample/person_knows_person_0_0.csv\"),\n",
    "        # selected column names that would be load as properties\n",
    "        [\"creationDate\"],\n",
    "        # use 'Person.id' column as source id, the src label should be 'person'\n",
    "        (\"Person.id\", \"person\"),\n",
    "        # use 'Person.id.1' column as destination id, the dst label is 'person'\n",
    "        (\"Person.id.1\", \"person\")\n",
    "    )\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a `person` field used as vertex label name, we will defer its explanation to the next subsection. \n",
    "\n",
    "Here the `Loader` is a object wraps how to load a data, including its location(e.g, HDFS, local fs, AmazonS3 or Aliyun OSS), column delimiter and some other metadata. In this case, the Loader assigned a file location in the mounted volume."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vertices\n",
    "\n",
    "Optional, Default to `None`. It can be `None` only when there is only one the vertex label in the graph and any vertex properties is not required.\n",
    "In this case, the vertex ID is deduced from the both ends of edges.\n",
    "\n",
    "Similar to edges, a vertex Dict contains a key as the label, and a set of configuration for the label. The configurations contain:\n",
    "\n",
    " - a loader for data source, which can be a file location, or a numpy, etc. See more details in Loader object.\n",
    "\n",
    " - a list of properties to load, the names should consistent to the header_row of the data source file. This list is optional. When it omitted, all columns except the vertex_id column will be added as properties.\n",
    "\n",
    " - the column used as vertex_id. The value in this column of the data source will be used for src/dst when loading edges.\n",
    "\n",
    "Here is an example for vertices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices={\n",
    "    \"person\": (\n",
    "        # source file for vertices labeled as person;\n",
    "        Loader(\"/testingdata/ldbc_sample/person_0_0.csv\"),\n",
    "        # columns loaded as property\n",
    "        [\"firstName\", \"lastName\"],\n",
    "        # the column used as vertex_id\n",
    "        \"id\"\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### directed\n",
    "\n",
    "Optional, default to `True`.\n",
    "\n",
    "The parameter `Directed` indicates whether to load the graph as an undirected or directed graph. Default is set to True. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directed = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### oid_type\n",
    "\n",
    "Optional, default to `int64_t`.\n",
    "\n",
    "The parameter `oid_type` indicates the data type of the original IDs in the graph. It can be `string` or `int64_t`. We recommend to use `int64_t` if possible as it could save much memory compared to `string`, and it also lead to a performance boost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oid_type = 'int64_t'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate_eid\n",
    "\n",
    "Optional, default to `True`.\n",
    "\n",
    "In some cases, like the [Graph Interactive Engine](https://graphscope.io/docs/interactive_engine.html) requires every edge have an eid. Set `generate_eid` to `True` will generate eids for edges. In short, If you want to use interactive engine, then set this field to `True`, else set to `False`. Default is `False`\n",
    "\n",
    "In this tutorial we just set it to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_eid = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compose them together to define `load_graph`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = sess.load_from(edges, vertices, directed, oid_type, generate_eid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a graph loaded in the graphscope, with one kind of vertice labeled with `person` and one kind of edges labeled with `knows`. Let's check the graph schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(graph.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serialization and Deserialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the graph is huge, it takes large amount of time(e.g., maybe hours) for the graph loadding.\n",
    "GraphScope provides serialization and deserialization for graph data, \n",
    "which dumps and load the constructed graphs in the form of binary data to(from) disk. This functions save much time, and make our lives easier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialization\n",
    "\n",
    "`graph.serialize` takes a `path` argument, indicating the location to store the binary data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.serialize('/tmp/seri')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deserialization\n",
    "\n",
    "`graph.deserialize` is a `classmethod`, its signature looks like `graph.serialize`. However, its `path` argument should be exactly the same to the `path` passed in `graph.serialize`, as it relys on naming to find the binary files. Please note that during serialization, the workers dump its own data to files with its index as suffix. Thus the number of workers for deserialization should be **exactly the same** to that for serialization.\n",
    "\n",
    "In addition, `graph.deserialize` needs an extra `sess` parameter, specifying which session the graph would be deserialized in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deserialized_graph = Graph.deserialize('/tmp/seri', sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Various Forms to Define a Graph\n",
    "\n",
    "Revisit the definition of edges in the previous section, it uses a `tuple` to specify many configurations.\n",
    "\n",
    "\n",
    "Alternatively, they can be define as a `Dict`, The reserved keys of the Dict are `loader`, `properties`, `source` and `destination`. This configuration for edges are exactly the same to the above configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a36d03a1b3fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m edges={\n\u001b[1;32m      2\u001b[0m     \"knows\": (\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/testingdata/property/p2p-31_property_e_0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0;34m\"src_label_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dst_label_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dist\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0;34m\"src_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"person\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Loader' is not defined"
     ]
    }
   ],
   "source": [
    "edges={\n",
    "    \"knows\": (\n",
    "        Loader(\"/testingdata/ldbc_sample/person_knows_person_0_0.csv\"),\n",
    "        [\"creationDate\"],\n",
    "        (\"Person.id\", \"person\"),\n",
    "        (\"Person.id.1\", \"person\")\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = {\n",
    "    \"knows\": {\n",
    "            \"loader\": Loader(\"/testingdata/ldbc_sample/person_knows_person_0_0.csv\"),\n",
    "            \"properties\": [\"creationDate\"],\n",
    "            \"source\": (\"Person.id\", \"person\"),\n",
    "            \"destination\": (\"Person.id.1\", \"person\"),\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, an edge label may connect several kinds of vertices. For example, in ldbc graph, two kinds of edges are labeled with **likes** but represents two relations. i.e., in a forum, people can give a **like** to both posts and comments. These relation can be abstracted as person **likes** post, and person **likes** comment. In this case, a **likes** key follows a list of configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-018280976d27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \"likes\": [\n\u001b[1;32m      4\u001b[0m         (\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0mLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/testingdata/ldbc_sample/person_likes_comment_0_0.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0;34m\"creationDate\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0;34m\"Person.id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"person\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Loader' is not defined"
     ]
    }
   ],
   "source": [
    "edges={\n",
    "    # a kind of edge with label \"likes\"\n",
    "    \"likes\": [\n",
    "        (\n",
    "            Loader(\"/testingdata/ldbc_sample/person_likes_comment_0_0.csv\"),\n",
    "            [\"creationDate\"],\n",
    "            (\"Person.id\", \"person\"),\n",
    "            (\"Comment.id\", \"comment\")\n",
    "        ),\n",
    "        (\n",
    "            Loader(\"/testingdata/ldbc_sample/person_likes_post_0_0.csv\"),\n",
    "            [\"creationDate\"],\n",
    "            (\"Person.id\", \"person\"),\n",
    "            (\"Post.id\", \"post\")\n",
    "        )\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some fields can omit for edges.\n",
    "- If the `Loader` contains only a url, we can omit the class, just put the url\n",
    "- properties can be empty, which means to select all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges={\n",
    "    \"knows\": (\n",
    "        \"/testingdata/ldbc_sample/person_knows_person_0_0.csv\",\n",
    "        [],\n",
    "        (\"Person.id\", \"person\"),\n",
    "        (\"Person.id.1\", \"person\")\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, all column names can be assigned with index. For example, the number in the src/dst assigned the first column is used as Person.id and the second column is used as Person.id.1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges={\n",
    "    \"knows\": (\n",
    "        \"/testingdata/ldbc_sample/person_knows_person_0_0.csv\",\n",
    "        [\"creationDate\"],\n",
    "        # 0 represents the first column.\n",
    "        (0, \"person\"),\n",
    "        # second column used as dst.\n",
    "        (1, \"person\"),\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, edge source and edge destination can be omitted if the graph has only one vertex label, which means all edges relations will contain and only can contain this specific vertex label. Thus it's unambiougous to omit the source and destination specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges={\n",
    "    \"group\": (\n",
    "        \"/testingdata/ldbc_sample/person_knows_person_0_0.csv\",\n",
    "        [\"creationDate\"]\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the simplest case, the configuration can only assign a loader with path. By default, the first column will be used as Person.id, the second column will be used as Person.id.1. all the rest columns in the file are parsed as properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges={\n",
    "    \"knows\": \"/testingdata/ldbc_sample/person_knows_person_0_0.csv\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the edges, the configuration for vertices can also be a Dict, in which the keys are “loader”, “properties” and “vid”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices={\n",
    "    \"person\": {\n",
    "        \"loader\": Loader(\"/testingdata/ldbc_sample/person_0_0.csv\"),\n",
    "        \"properties\": [\"firstName\", \"lastName\"],\n",
    "        \"vid\": \"id\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also omit certain configurations for vertices.\n",
    "\n",
    "- If the Loader contains only a url, we can omit the class, just put the url\n",
    "\n",
    "- properties can be empty, which means that all columns are selected as properties;\n",
    "\n",
    "- vid can be represented by a number of index\n",
    "\n",
    "In the simplest case, the configuration can only contains a loader. In this case, the first column is used as vid, and the rest columns are used as properties.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices={\n",
    "    \"person\": \"/testingdata/ldbc_sample/person_0_0.csv\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, the vertices can be totally omitted. GraphScope will extract vertices ids from edges, and a default label _ will assigned to all vertices in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = graphscope_session.load_from(\n",
    "    edges={\n",
    "        \"knows\": \"/testingdata/ldbc_sample/person_knows_person_0_0.csv\"\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to use the skills to load a graph with more complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = graphscope_session.load_from(\n",
    "    edges={\n",
    "        \"knows\": (\n",
    "            \"/testingdata/ldbc_sample/person_knows_person_0_0.csv\",\n",
    "            [\"creationDate\"],\n",
    "            (\"Person.id\", \"person\"),\n",
    "            (\"Person.id.1\", \"person\")\n",
    "        ),\n",
    "        \"likes\": [\n",
    "            (\n",
    "                \"/testingdata/ldbc_sample/person_likes_comment_0_0.csv\",\n",
    "                [\"creationDate\"],\n",
    "                (\"Person.id\", \"person\"),\n",
    "                (\"Comment.id\", \"comment\")\n",
    "            ),\n",
    "            (\n",
    "                \"/testingdata/ldbc_sample/person_likes_post_0_0.csv\",\n",
    "                [\"creationDate\"],\n",
    "                (\"Person.id\", \"person\"),\n",
    "                (\"Post.id\", \"post\")\n",
    "            )\n",
    "        ]\n",
    "    },\n",
    "    vertices={\n",
    "        \"person\": (\n",
    "            \"/testingdata/ldbc_sample/person_0_0.csv\",\n",
    "            [\"firstName\", \"lastName\"],\n",
    "            \"id\",\n",
    "        ),\n",
    "        \"comment\": (\n",
    "            \"/testingdata/ldbc_sample/comment_0_0.csv\",\n",
    "            [\"creationDate\"],\n",
    "            \"id\",\n",
    "        ),\n",
    "        \"post\": (\n",
    "            \"/testingdata/ldbc_sample/post_0_0.csv\",\n",
    "            [\"creationDate\"],\n",
    "            \"id\",\n",
    "        )\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading From Various Locations\n",
    "\n",
    "A `Loader` defines how to load data, including its location, metadata, and other configurations. Graphscope supports specifying the location in a `str`, which follows the standard of URI. Upon receiving a request from a Loader, GraphScope parse the URI string and invoke corresponding drivers in `vineyard` according to the parsed schema. Currently, the location supports local file system, Amazon S3, Aliyun OSS， HDFS and URL on the web.\n",
    "\n",
    "In addition, pandas dataframes or numpy ndarrays in specified format are also supported.\n",
    "\n",
    "The data loading is managed by `vineyard`. `vineyard` takes advantage of `fsspec` to resolve schemes and formats. Any additional configurations can be passed in kwargs to Loader, for example, the host and port to HDFS, or access-id, secret-access-key to AliyunOSS or Amazon S3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphs from Location\n",
    "\n",
    "When a loader wraps a location, it may only contains a str. The string follows the standard of URI. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1 = Loader(\"file:///var/datafiles/edgefile.e\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load data from S3, users need to provide the `key` and the `secret`. Besides, additional arguments can be passed by `client_kwargs`, e.g., `region_name` of bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d34 = Loader(\"s3://bucket/datafiles/edgefile.e\", key='access-id', secret='secret-access-key', client_kwargs={'region_name': 'us-east-1'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load data from Aliyun OSS, users need to provide `key`, `secret`, and `endpoint` of the bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2 = Loader(\"oss://bucket/datafiles/edgefile.e\", key='access-id', secret='secret-access-key', endpoint='oss-cn-hangzhou.aliyuncs.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load data from HDFS, user need to provide `host` and `port`, extra configurations can be specified by `extra_conf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds3 = Loader(\"hdfs:///var/datafiles/edgefile.e\", host='localhost', port='9000', extra_conf={'conf1': 'value1'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how to load a graph from Amazon S3 as an real example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graphscope_session.load_from(\n",
    "    edges={\n",
    "        \"knows\": (\n",
    "                Loader(\"s3://ldbc/ldbc_sample/person_knows_person_0_0.csv\", key='access-id', secret='secret'),\n",
    "            )\n",
    "    },\n",
    "    vertices={\n",
    "        \"person\": (\n",
    "            Loader(\"s3://ldbc/ldbc_sample/person_0_0.csv\", key='access-id', secret='secret'),\n",
    "        ),\n",
    "    },\n",
    ")\n",
    "print(graph.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Graphs from Numpy and Pandas\n",
    "\n",
    "For pandas, the dataframe's format is like in csv files. TODO（yuansi): create dataframe and array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_e = pd.read_csv('group.e', sep=',',\n",
    "                 usecols=['leader_student_id', 'member_student_id', 'member_size'])\n",
    "\n",
    "df_v = pd.read_csv('student.v', sep=',', usecols=['student_id', 'lesson_nums', 'avg_score'])\n",
    "\n",
    "# use a dataframe as datasource, properties omitted, col_0/col_1 will be used as src/dst by default.\n",
    "# (for vertices, col_0 will be used as vertex_id by default)\n",
    "g1 = sess.load_graph(edges=df_e, vertices=df_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For numpy, load from ndarrays require the data are organized in COO format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "array_e = [df_e[col].values for col in ['leader_student_id', 'member_student_id', 'member_size']]\n",
    "array_v = [df_v[col].values for col in ['student_id', 'lesson_nums', 'avg_score']]\n",
    "\n",
    "g2 = sess.load_graph(edges=array_e, vertices=array_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, close the session to release all resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
