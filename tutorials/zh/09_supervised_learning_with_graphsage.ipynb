{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于 GraphSAGE 的有监督学习\n",
    "\n",
    "图神经网络（GNN）结合了图结构和机器学习的优势. GraphScope提供了处理学习任务的功能。本次教程，我们将会展示GraphScope如何使用GraphSAGE算法训练一个模型。\n",
    "\n",
    "本次教程的学习任务是在文献引用网络上的点分类任务。在点分类任务中，算法会确定[Cora](https://linqs.soe.ucsc.edu/data)数据集上每个顶点的标签。在```Cora```数据集中，由学术出版物作为顶点，出版物之间的引用作为边，如果出版物A引用了出版物B，则图中会存在一条从A到B的边。Cora数据集中的节点被分为了七个主题类，我们的模型将会训练来预测出版物顶点的主题。\n",
    "\n",
    "这一教程将会分为以下几个步骤：\n",
    "\n",
    "- 启动GraphScope的学习引擎，并将图关联到引擎上\n",
    "- 使用内置的GraphSAGE模型定义训练过程，并定义相关的超参\n",
    "- 开始训练\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install graphscope package if you are NOT in the Playground\n",
    "\n",
    "!pip3 install graphscope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the graphscope module.\n",
    "\n",
    "import graphscope\n",
    "\n",
    "graphscope.set_option(show_log=False)  # enable logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cora dataset\n",
    "\n",
    "from graphscope.dataset import load_cora\n",
    "\n",
    "graph = load_cora()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，我们需要定义一个特征列表用于图的训练。训练特征集合必须从点的属性集合中选取。在这个例子中，我们选择了属性集合中所有以\"feat_\"为前缀的属性作为训练特征集，这一特征集也是Cora数据中点的特征集。\n",
    "\n",
    "借助定义的特征列表，接下来，我们使用 [graphlearn](https://graphscope.io/docs/reference/session.html#graphscope.Session.graphlearn) 方法来开启一个学习引擎。\n",
    "\n",
    "在这个例子中，我们在 \"graphlearn\" 方法中，指定在数据中 \"paper\" 类型的顶点和 \"cites\" 类型边上进行模型训练。\n",
    "\n",
    "利用 \"gen_labels\" 参数，我们将 \"paper\" 点数据集进行划分，其中75%作为训练集，10%作为验证集，15%作为测试集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the features for learning\n",
    "paper_features = []\n",
    "for i in range(1433):\n",
    "    paper_features.append(\"feat_\" + str(i))\n",
    "\n",
    "# launch a learning engine.\n",
    "lg = graphscope.graphlearn(\n",
    "    graph,\n",
    "    nodes=[(\"paper\", paper_features)],\n",
    "    edges=[(\"paper\", \"cites\", \"paper\")],\n",
    "    gen_labels=[\n",
    "        (\"train\", \"paper\", 100, (0, 75)),\n",
    "        (\"val\", \"paper\", 100, (75, 85)),\n",
    "        (\"test\", \"paper\", 100, (85, 100)),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "这里我们使用内置的GraphSAGE模型定义训练过程。\n",
    "\n",
    "在本次示例中，我们使用tensorflow作为NN后端训练器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  # https://www.tensorflow.org/guide/migrate\n",
    "  import tensorflow.compat.v1 as tf\n",
    "  tf.disable_v2_behavior()\n",
    "except ImportError:\n",
    "  import tensorflow as tf\n",
    "\n",
    "import argparse\n",
    "import graphscope.learning as gl\n",
    "import graphscope.learning.graphlearn.python.nn.tf as tfg\n",
    "from graphscope.learning.examples import EgoGraphSAGE\n",
    "from graphscope.learning.examples import EgoSAGESupervisedDataLoader\n",
    "from graphscope.learning.examples.tf.trainer import LocalTrainer\n",
    "\n",
    "def parse_args():\n",
    "  argparser = argparse.ArgumentParser(\"Train EgoSAGE Supervised.\")\n",
    "  argparser.add_argument('--class_num', type=int, default=7)\n",
    "  argparser.add_argument('--features_num', type=int, default=1433)\n",
    "  argparser.add_argument('--train_batch_size', type=int, default=140)\n",
    "  argparser.add_argument('--val_batch_size', type=int, default=300)\n",
    "  argparser.add_argument('--test_batch_size', type=int, default=1000)\n",
    "  argparser.add_argument('--hidden_dim', type=int, default=128)\n",
    "  argparser.add_argument('--in_drop_rate', type=float, default=0.5)\n",
    "  argparser.add_argument('--hops_num', type=int, default=2)\n",
    "  argparser.add_argument('--nbrs_num', type=list, default=[25, 10])\n",
    "  argparser.add_argument('--agg_type', type=str, default=\"gcn\")\n",
    "  argparser.add_argument('--learning_algo', type=str, default=\"adam\")\n",
    "  argparser.add_argument('--learning_rate', type=float, default=0.05)\n",
    "  argparser.add_argument('--weight_decay', type=float, default=0.0005)\n",
    "  argparser.add_argument('--epochs', type=int, default=40)\n",
    "  argparser.add_argument('--node_type', type=str, default='paper')\n",
    "  argparser.add_argument('--edge_type', type=str, default='cites')\n",
    "  return argparser.parse_args()\n",
    "args = parse_args()\n",
    "\n",
    "def supervised_loss(logits, labels):\n",
    "  loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "      labels=labels, logits=logits)\n",
    "  return tf.reduce_mean(loss)\n",
    "\n",
    "def accuracy(logits, labels):\n",
    "  indices = tf.math.argmax(logits, 1, output_type=tf.int32)\n",
    "  correct = tf.reduce_sum(tf.cast(tf.math.equal(indices, labels), tf.float32))\n",
    "  return correct / tf.cast(tf.shape(labels)[0], tf.float32)\n",
    "\n",
    "# Define Model\n",
    "dims = [args.features_num] + [args.hidden_dim] * (args.hops_num - 1) \\\n",
    "    + [args.class_num]\n",
    "model = EgoGraphSAGE(dims,\n",
    "                    agg_type=args.agg_type,\n",
    "                    act_func=tf.nn.relu,\n",
    "                    dropout=args.in_drop_rate)\n",
    "\n",
    "# prepare train dataset\n",
    "train_data = EgoSAGESupervisedDataLoader(lg, gl.Mask.TRAIN, 'random', args.train_batch_size,\n",
    "                                        node_type=args.node_type, edge_type=args.edge_type,\n",
    "                                        nbrs_num=args.nbrs_num, hops_num=args.hops_num)\n",
    "train_embedding = model.forward(train_data.src_ego)\n",
    "loss = supervised_loss(train_embedding, train_data.src_ego.src.labels)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=args.learning_rate)\n",
    "\n",
    "# prepare test dataset\n",
    "test_data = EgoSAGESupervisedDataLoader(lg, gl.Mask.TEST, 'random', args.test_batch_size,\n",
    "                                        node_type=args.node_type, edge_type=args.edge_type,\n",
    "                                        nbrs_num=args.nbrs_num, hops_num=args.hops_num)\n",
    "test_embedding = model.forward(test_data.src_ego)\n",
    "test_acc = accuracy(test_embedding, test_data.src_ego.src.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在定义完训练过程和超参后，现在我们可以使用学习引擎和定义的超参开始训练过程。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test\n",
    "trainer = LocalTrainer()\n",
    "trainer.train(train_data.iterator, loss, optimizer, epochs=args.epochs)\n",
    "trainer.test(test_data.iterator, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
