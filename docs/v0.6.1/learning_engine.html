

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>GraphScope Learning Engine &mdash; GraphScope  documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/custom.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Frequently Asked Questions" href="frequently_asked_questions.html" />
    <link rel="prev" title="GraphScope Interactive Engine" href="interactive_engine.html" />

 

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-4TMYCGJ0X2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-4TMYCGJ0X2');
</script>



  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> GraphScope
          

          
          </a>

          
            
            
              <div class="version">
                v0.6.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
      
      
        
          
        
      
      
        <p class="caption"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="deployment.html">Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="loading_graph.html">Loading Graphs</a></li>
<li class="toctree-l1"><a class="reference internal" href="graph_transformation.html">Graph Transformations</a></li>
<li class="toctree-l1"><a class="reference internal" href="analytics_engine.html">GraphScope Analytical Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="interactive_engine.html">GraphScope Interactive Engine</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">GraphScope Learning Engine</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#graph-learning-model">Graph Learning Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#data-model">Data model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#encoder">Encoder</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#developing-your-own-model">Developing Your Own Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#sampling">Sampling</a></li>
<li class="toctree-l3"><a class="reference internal" href="#graph-data-flow">Graph Data Flow</a></li>
<li class="toctree-l3"><a class="reference internal" href="#model">Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#loss-function-and-training-process">Loss Function and Training Process</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="frequently_asked_questions.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="developer_guide.html">Developer Guide</a></li>
</ul>
<p class="caption"><span class="caption-text">Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="reference/python_index.html">Python API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="reference/analytical_engine_index.html">Analytical Engine API Reference</a></li>
</ul>

      
    
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">GraphScope</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>GraphScope Learning Engine</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/learning_engine.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="graphscope-learning-engine">
<h1>GraphScope Learning Engine<a class="headerlink" href="#graphscope-learning-engine" title="Permalink to this headline">¶</a></h1>
<p>The learning engine in GraphScope (GLE) drives from Graph-Learn,
a distributed framework designed for development and training
of large-scale graph neural networks (GNNs).
GLE provides a programming interface carefully designed for
the development of graph neural network models,
and has been widely applied in many scenarios within Alibaba,
such as search recommendation, network security, and knowledge graphs.</p>
<p>Next, we will walk through a quick-start turtorial on how to build
a user-defined GNN model using <strong>GLE</strong>.</p>
<div class="section" id="graph-learning-model">
<h2>Graph Learning Model<a class="headerlink" href="#graph-learning-model" title="Permalink to this headline">¶</a></h2>
<p>There are two ways to train a graph learning model. One is to
compute based on the whole graph directly. The GCN and GAT are originally
proposed using this approach, directly computing on the entire adjacency matrix.
However, this approach will consume huge amount of memory on large-scale graphs,
limiting its applicability.
The other approach is to sample subgraphs from the whole
graph, and use batch training that is
commonly used in deep learning. The typical examples
include GraphSAGE，FastGCN and GraphSAINT methods.</p>
<p><strong>GLE</strong> is designed for large-scale graph neural
networks. It consists of an efficient graph engine, a set of user-friendly APIs,
and a rich set of built-in popular GNN models.
The graph engine stores the graph topology and attributes distributedly,
and support efficient graph sampling amd query.
It can work with popular tensor engines including TensorFlow and PyTorch.
In the following, our model implemnetations are based on TensorFlow.</p>
<img alt="_images/learning_model.png" class="align-center" src="_images/learning_model.png" />
<div class="section" id="data-model">
<h3>Data model<a class="headerlink" href="#data-model" title="Permalink to this headline">¶</a></h3>
<p>To build and train a model, <strong>GLE</strong> usually samples subgraphs as the training data,
and perform batch training with it. We start with introducing the basic data model.</p>
<p><code class="docutils literal notranslate"><span class="pre">EgoGraph</span></code> is the underlying data model in <strong>GLE</strong>. It consists of a
batch of seed nodes or edges(named ‘ego’) and their receptive fields
(multi-hops neighbors). We implement many build-in samplers to traverse
the graph and sample the neighbors. Negative samplers are also implemented
for unsupervised training.</p>
<p>The sampled data grouped in <code class="docutils literal notranslate"><span class="pre">EgoGraph</span></code> is organized into numpy format.
It can be converted to different tensor formats, <code class="docutils literal notranslate"><span class="pre">EgoTensor</span></code>, based on
the different deep learning engine. <strong>GLE</strong> uses <code class="docutils literal notranslate"><span class="pre">EgoFlow</span></code> to convert
<code class="docutils literal notranslate"><span class="pre">EgoGraph</span></code> to <code class="docutils literal notranslate"><span class="pre">EgoTensor</span></code>.
And the <code class="docutils literal notranslate"><span class="pre">EgoTensor</span></code> serves as the training data.</p>
<img alt="_images/egograph.png" class="align-center" src="_images/egograph.png" />
</div>
<div class="section" id="encoder">
<h3>Encoder<a class="headerlink" href="#encoder" title="Permalink to this headline">¶</a></h3>
<p>A graph learning model can be viewed as using an encoder to
encode the <code class="docutils literal notranslate"><span class="pre">EgoTensor</span></code> of a node, edge or subgraph into a vector.</p>
<p><strong>GLE</strong> first uses feature encoders to encode
raw features of nodes or edges, and the produced feature embeddings are
then encoded by different graph encoders
to produce the final embedding vectors.
For most of GNN models, graph encoders provide a way to generate an abstraction of a target node or edge
by aggregating information from its neighbors.
This aggregation and encoding are usually
implemented by many different graph convolutional layers.</p>
<img alt="_images/egotensor.png" class="align-center" src="_images/egotensor.png" />
<p>Based on the data models and encoders, one can easily implement
different graph learning models.
We introduce in detail how to develope
a GNN model in the next section.</p>
</div>
</div>
<div class="section" id="developing-your-own-model">
<h2>Developing Your Own Model<a class="headerlink" href="#developing-your-own-model" title="Permalink to this headline">¶</a></h2>
<p>In this document, we will introduce how to use the basic APIs provided
by <strong>GLE</strong> to cooperate with deep learning engines, such as TensorFlow,
to build graph learning algorithms. We demonstrate the GCN model as an
example which is one of the most popular models in graph neural network.</p>
<p>In general, it requires the following four steps to build an algorithm.</p>
<ul>
<li><p>Specify sampling mode: use graph sampling and query methods to sample
subgraphs and organize them into <code class="docutils literal notranslate"><span class="pre">EgoGraph</span></code></p>
<p>We abstract out four basic functions, <code class="docutils literal notranslate"><span class="pre">sample_seed</span></code>,
<code class="docutils literal notranslate"><span class="pre">positive_sample</span></code>, <code class="docutils literal notranslate"><span class="pre">negative_sample</span></code> and <code class="docutils literal notranslate"><span class="pre">receptive_fn</span></code>. To
generate <code class="docutils literal notranslate"><span class="pre">Node</span></code> or <code class="docutils literal notranslate"><span class="pre">Edges</span></code>, we use <code class="docutils literal notranslate"><span class="pre">sample_seed</span></code> to traverse
the graph. Then, we use <code class="docutils literal notranslate"><span class="pre">positive_sample</span></code> with <code class="docutils literal notranslate"><span class="pre">Nodes</span></code> or
<code class="docutils literal notranslate"><span class="pre">Edges</span></code> as inputs to generate positive samples for training. For
unsupervised learning <code class="docutils literal notranslate"><span class="pre">negative_sample</span></code> produces negative samples.
GNNs need to aggregate neighbor information so that we abstract
<code class="docutils literal notranslate"><span class="pre">receptive_fn</span></code> to sample neighbors. Finally, the <code class="docutils literal notranslate"><span class="pre">Nodes</span></code> and
<code class="docutils literal notranslate"><span class="pre">Edges</span></code> produced by <code class="docutils literal notranslate"><span class="pre">sample_seed</span></code>, and their sampled neighbors
form an <code class="docutils literal notranslate"><span class="pre">EgoGraph</span></code>.</p>
</li>
<li><p>Construct graph data flow: convert <code class="docutils literal notranslate"><span class="pre">EgoGraph</span></code> to <code class="docutils literal notranslate"><span class="pre">EgoTensor</span></code>
using <code class="docutils literal notranslate"><span class="pre">EgoFlow</span></code></p>
<p><strong>GLE</strong> algorithm model is based on a deep learning engine similar to
TensorFlow. As a result, it requires to convert the sampled
<code class="docutils literal notranslate"><span class="pre">EgoGraph</span></code>s to the tensor format <code class="docutils literal notranslate"><span class="pre">EgoTensor</span></code>, which is
encapsulated in <code class="docutils literal notranslate"><span class="pre">EgoFlow</span></code> that can generate an iterator for batch
training.</p>
</li>
<li><p>Define encoder: Use <code class="docutils literal notranslate"><span class="pre">EgoGraph</span></code> encoder and feature encoder to
encode <code class="docutils literal notranslate"><span class="pre">EgoTensor</span></code></p>
<p>After getting the <code class="docutils literal notranslate"><span class="pre">EgoTensor</span></code>, we first encode the original nodes
and edge features into vectors using common feature encoders. Then,
we feed the vectors into a GNN model as the feature input. Next, we
use the graph encoder to process the <code class="docutils literal notranslate"><span class="pre">EgoTensor</span></code>, combining the
neighbor node features with its characteristics to get the nodes or
edge vectors.</p>
</li>
<li><p>Design loss functions and training processes: select the appropriate
loss function and write the training process.</p>
<p><strong>GLE</strong> has built-in common loss functions and optimizers. It also
encapsulates the training process. <strong>GLE</strong> supports both
single-machine and distributed training. Users can also customize the
loss functions, optimizers and training processes.</p>
</li>
</ul>
<p>Next, we introduce how to implement a GCN model using the above four steps.</p>
<div class="section" id="sampling">
<h3>Sampling<a class="headerlink" href="#sampling" title="Permalink to this headline">¶</a></h3>
<p>We use the Cora dataset as the node classification example. We provide a
simple data conversion script <code class="docutils literal notranslate"><span class="pre">cora.py</span></code> to convert the original Cora
to the format required by <strong>GLE</strong>. The script generates following 5
files: node_table, edge_table_with_self_loop, train_table, val_table and
test_table. They are the node table, the edge table, and the nodes
tables used to distinguish training, validation, and testing sets.</p>
<p>Then, we can construct the graph using the following code snippet.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">graphlearn</span> <span class="k">as</span> <span class="nn">gle</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">gle</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>\
      <span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="n">dataset_folder</span> <span class="o">+</span> <span class="s2">&quot;node_table&quot;</span><span class="p">,</span> <span class="n">node_type</span><span class="o">=</span><span class="n">node_type</span><span class="p">,</span>
            <span class="n">decoder</span><span class="o">=</span><span class="n">gle</span><span class="o">.</span><span class="n">Decoder</span><span class="p">(</span><span class="n">labeled</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                               <span class="n">attr_types</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;float&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">1433</span><span class="p">,</span>
                               <span class="n">attr_delimiter</span><span class="o">=</span><span class="s2">&quot;:&quot;</span><span class="p">))</span>\
      <span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="n">dataset_folder</span> <span class="o">+</span> <span class="s2">&quot;edge_table_with_self_loop&quot;</span><span class="p">,</span>
            <span class="n">edge_type</span><span class="o">=</span><span class="p">(</span><span class="n">node_type</span><span class="p">,</span> <span class="n">node_type</span><span class="p">,</span> <span class="n">edge_type</span><span class="p">),</span>
            <span class="n">decoder</span><span class="o">=</span><span class="n">gle</span><span class="o">.</span><span class="n">Decoder</span><span class="p">(</span><span class="n">weighted</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">directed</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>\
      <span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="n">dataset_folder</span> <span class="o">+</span> <span class="s2">&quot;train_table&quot;</span><span class="p">,</span> <span class="n">node_type</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">,</span>
            <span class="n">decoder</span><span class="o">=</span><span class="n">gle</span><span class="o">.</span><span class="n">Decoder</span><span class="p">(</span><span class="n">weighted</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>\
      <span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="n">dataset_folder</span> <span class="o">+</span> <span class="s2">&quot;val_table&quot;</span><span class="p">,</span> <span class="n">node_type</span><span class="o">=</span><span class="s2">&quot;val&quot;</span><span class="p">,</span>
            <span class="n">decoder</span><span class="o">=</span><span class="n">gle</span><span class="o">.</span><span class="n">Decoder</span><span class="p">(</span><span class="n">weighted</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>\
      <span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="n">dataset_folder</span> <span class="o">+</span> <span class="s2">&quot;test_table&quot;</span><span class="p">,</span> <span class="n">node_type</span><span class="o">=</span><span class="s2">&quot;test&quot;</span><span class="p">,</span>
            <span class="n">decoder</span><span class="o">=</span><span class="n">gle</span><span class="o">.</span><span class="n">Decoder</span><span class="p">(</span><span class="n">weighted</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>
</div>
<p>We load the graph into memory by calling <code class="docutils literal notranslate"><span class="pre">g.init()</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">GCN</span><span class="p">(</span><span class="n">gle</span><span class="o">.</span><span class="n">LearningBasedModel</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">graph</span><span class="p">,</span>
               <span class="n">output_dim</span><span class="p">,</span>
               <span class="n">features_num</span><span class="p">,</span>
               <span class="n">batch_size</span><span class="p">,</span>
               <span class="n">categorical_attrs_desc</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span>
               <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
               <span class="n">hops_num</span><span class="o">=</span><span class="mi">2</span><span class="p">,):</span>
  <span class="bp">self</span><span class="o">.</span><span class="n">graph</span> <span class="o">=</span> <span class="n">graph</span>
  <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
</pre></div>
</div>
<p>The GCN model inherits from the basic learning model class
<code class="docutils literal notranslate"><span class="pre">LearningBasedModel</span></code>. As a result, we only need to override the
sampling, model construction, and other methods to build GCN model.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">GCN</span><span class="p">(</span><span class="n">gle</span><span class="o">.</span><span class="n">LearningBasedModel</span><span class="p">):</span>
  <span class="c1"># ...</span>
  <span class="k">def</span> <span class="nf">_sample_seed</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">V</span><span class="p">(</span><span class="s1">&#39;train&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">_positive_sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
      <span class="k">return</span> <span class="n">gle</span><span class="o">.</span><span class="n">Edges</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">ids</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_type</span><span class="p">,</span>
                      <span class="n">t</span><span class="o">.</span><span class="n">ids</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_type</span><span class="p">,</span>
                      <span class="bp">self</span><span class="o">.</span><span class="n">edge_type</span><span class="p">,</span> <span class="n">graph</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_receptive_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nodes</span><span class="p">):</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">V</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="n">feed</span><span class="o">=</span><span class="n">nodes</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s1">&#39;v&#39;</span><span class="p">)</span> \
        <span class="o">.</span><span class="n">outV</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">edge_type</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span><span class="o">.</span><span class="n">by</span><span class="p">(</span><span class="s1">&#39;full&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s1">&#39;v1&#39;</span><span class="p">)</span> \
        <span class="o">.</span><span class="n">outV</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">edge_type</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span><span class="o">.</span><span class="n">by</span><span class="p">(</span><span class="s1">&#39;full&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s1">&#39;v2&#39;</span><span class="p">)</span> \
        <span class="o">.</span><span class="n">emit</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">gle</span><span class="o">.</span><span class="n">EgoGraph</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s1">&#39;v&#39;</span><span class="p">],</span> <span class="p">[</span><span class="n">ag</span><span class="o">.</span><span class="n">Layer</span><span class="p">(</span><span class="n">nodes</span><span class="o">=</span><span class="n">x</span><span class="p">[</span><span class="s1">&#39;v1&#39;</span><span class="p">]),</span> <span class="n">ag</span><span class="o">.</span><span class="n">Layer</span><span class="p">(</span><span class="n">nodes</span><span class="o">=</span><span class="n">x</span><span class="p">[</span><span class="s1">&#39;v2&#39;</span><span class="p">])]))</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">_sample_seed</span></code> and <code class="docutils literal notranslate"><span class="pre">_positive_sample</span></code> use to sample seed nodes and
positive samples. <code class="docutils literal notranslate"><span class="pre">_receptive_fn</span></code> samples neighbors and organizes
<code class="docutils literal notranslate"><span class="pre">EgoGraph</span></code>. <code class="docutils literal notranslate"><span class="pre">OutV</span></code> returns one-hop neighbors so the above code
samples two-hop neighbors. Users can choose different neighbor sampling
methods. For the original GCN, it requires all neighbors of each node
are so we use ‘full’ for sampling. We aggregate the sampling results in
<code class="docutils literal notranslate"><span class="pre">EgoGraph</span></code> which is the return value.</p>
</div>
<div class="section" id="graph-data-flow">
<h3>Graph Data Flow<a class="headerlink" href="#graph-data-flow" title="Permalink to this headline">¶</a></h3>
<p>In <code class="docutils literal notranslate"><span class="pre">build</span></code> function, we convert <code class="docutils literal notranslate"><span class="pre">EgoGraph</span></code> to <code class="docutils literal notranslate"><span class="pre">EgoTensor</span></code> using
<code class="docutils literal notranslate"><span class="pre">EgoFlow</span></code>. <code class="docutils literal notranslate"><span class="pre">EgoFlow</span></code> contains an data flow iterator and several
<code class="docutils literal notranslate"><span class="pre">EgoTensor</span></code>s.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">GCN</span><span class="p">(</span><span class="n">gle</span><span class="o">.</span><span class="n">LearningBasedModel</span><span class="p">):</span>
 <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
   <span class="n">ego_flow</span> <span class="o">=</span> <span class="n">gle</span><span class="o">.</span><span class="n">EgoFlow</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_sample_seed</span><span class="p">,</span>
                         <span class="bp">self</span><span class="o">.</span><span class="n">_positive_sample</span><span class="p">,</span>
                         <span class="bp">self</span><span class="o">.</span><span class="n">_receptive_fn</span><span class="p">,</span>
                         <span class="bp">self</span><span class="o">.</span><span class="n">src_ego_spec</span><span class="p">)</span>
   <span class="n">iterator</span> <span class="o">=</span> <span class="n">ego_flow</span><span class="o">.</span><span class="n">iterator</span>
   <span class="n">pos_src_ego_tensor</span> <span class="o">=</span> <span class="n">ego_flow</span><span class="o">.</span><span class="n">pos_src_ego_tensor</span>
   <span class="c1"># ...</span>
</pre></div>
</div>
<p>We can get the <code class="docutils literal notranslate"><span class="pre">EgoTensor</span></code> corresponding to the previous <code class="docutils literal notranslate"><span class="pre">EgoGraph</span></code>
from <code class="docutils literal notranslate"><span class="pre">EgoFlow</span></code>.</p>
</div>
<div class="section" id="model">
<h3>Model<a class="headerlink" href="#model" title="Permalink to this headline">¶</a></h3>
<p>Next, we first use the feature encoder to encode the original features.
In this example, we use <code class="docutils literal notranslate"><span class="pre">IdentityEncoder</span></code> that returns itself, because
the features of Cora are already in vector formats. For both the
discrete and continuous features, we can use <code class="docutils literal notranslate"><span class="pre">WideNDeepEncoder</span></code>, To
learn more encoders, please refer to
<a class="reference external" href="https://github.com/alibaba/graph-learn/blob/master/graphlearn/python/model/tf/encoders/feature_encoder.py">feature encoder</a>.
Then, we use the
<code class="docutils literal notranslate"><span class="pre">GCNConv</span></code> layer to construct the graph encoder. For each node in GCN,
we sample all of its neighbors, and organize them in a sparse format.
Therefore, we use <code class="docutils literal notranslate"><span class="pre">SparseEgoGraphEncoder</span></code>. For the neighbor-aligned
model, please refer to the implementation of GraphSAGE.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">GCN</span><span class="p">(</span><span class="n">gle</span><span class="o">.</span><span class="n">LearningBasedModel</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">_encoders</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">depth</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hops_num</span>
    <span class="n">feature_encoders</span> <span class="o">=</span> <span class="p">[</span><span class="n">gle</span><span class="o">.</span><span class="n">encoders</span><span class="o">.</span><span class="n">IdentityEncoder</span><span class="p">()]</span> <span class="o">*</span> <span class="p">(</span><span class="n">depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">conv_layers</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># for input layer</span>
    <span class="n">conv_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">gle</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">GCNConv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">))</span>
    <span class="c1"># for hidden layer</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">depth</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
      <span class="n">conv_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">gle</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">GCNConv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">))</span>
    <span class="c1"># for output layer</span>
    <span class="n">conv_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">gle</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">GCNConv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">,</span> <span class="n">act</span><span class="o">=</span><span class="kc">None</span><span class="p">))</span>
    <span class="n">encoder</span> <span class="o">=</span> <span class="n">gle</span><span class="o">.</span><span class="n">encoders</span><span class="o">.</span><span class="n">SparseEgoGraphEncoder</span><span class="p">(</span><span class="n">feature_encoders</span><span class="p">,</span>
                                                  <span class="n">conv_layers</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;src&quot;</span><span class="p">:</span> <span class="n">encoder</span><span class="p">,</span> <span class="s2">&quot;edge&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;dst&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="loss-function-and-training-process">
<h3>Loss Function and Training Process<a class="headerlink" href="#loss-function-and-training-process" title="Permalink to this headline">¶</a></h3>
<p>For the Cora node classification model, we can select the corresponding
classification loss function in TensorFlow. Then, we combine the encoder
and loss function in the <code class="docutils literal notranslate"><span class="pre">build</span></code> function, and finally return a data
iterator and a loss function.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">GCN</span><span class="p">(</span><span class="n">gle</span><span class="o">.</span><span class="n">LearningBasedModel</span><span class="p">):</span>
  <span class="c1"># ...</span>
  <span class="k">def</span> <span class="nf">_supervised_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">emb</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sparse_softmax_cross_entropy_with_logits</span><span class="p">(</span><span class="n">emb</span><span class="p">,</span> <span class="n">label</span><span class="p">))</span>

  <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">ego_flow</span> <span class="o">=</span> <span class="n">gle</span><span class="o">.</span><span class="n">EgoFlow</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_sample_seed</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">_positive_sample</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">_receptive_fn</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">src_ego_spec</span><span class="p">,</span>
                          <span class="n">full_graph_mode</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">full_graph_mode</span><span class="p">)</span>
    <span class="n">iterator</span> <span class="o">=</span> <span class="n">ego_flow</span><span class="o">.</span><span class="n">iterator</span>
    <span class="n">pos_src_ego_tensor</span> <span class="o">=</span> <span class="n">ego_flow</span><span class="o">.</span><span class="n">pos_src_ego_tensor</span>
    <span class="n">src_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoders</span><span class="p">[</span><span class="s1">&#39;src&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">pos_src_ego_tensor</span><span class="p">)</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">pos_src_ego_tensor</span><span class="o">.</span><span class="n">src</span><span class="o">.</span><span class="n">labels</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_supervised_loss</span><span class="p">(</span><span class="n">src_emb</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">iterator</span>
</pre></div>
</div>
<p>Next, we use <code class="docutils literal notranslate"><span class="pre">LocalTFTrainer</span></code> to train on a single-machine.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">graph</span><span class="p">)</span>
  <span class="k">def</span> <span class="nf">model_fn</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">GCN</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span>
               <span class="n">config</span><span class="p">[</span><span class="s1">&#39;class_num&#39;</span><span class="p">],</span>
               <span class="n">config</span><span class="p">[</span><span class="s1">&#39;features_num&#39;</span><span class="p">],</span>
               <span class="n">config</span><span class="p">[</span><span class="s1">&#39;batch_szie&#39;</span><span class="p">],</span>
               <span class="o">...</span><span class="p">)</span>
  <span class="n">trainer</span> <span class="o">=</span> <span class="n">gle</span><span class="o">.</span><span class="n">LocalTFTrainer</span><span class="p">(</span><span class="n">model_fn</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
  <span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">config</span> <span class="o">=</span> <span class="p">{</span><span class="o">...</span><span class="p">}</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">load_graph</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
    <span class="n">g</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">server_id</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">server_count</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">tracker</span><span class="o">=</span><span class="s1">&#39;../../data/&#39;</span><span class="p">)</span>
    <span class="n">train</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">g</span><span class="p">)</span>
</pre></div>
</div>
<p>This concludes how to build a GCN model.
Please refer to <a class="reference external" href="https://github.com/alibaba/graph-learn/tree/master/examples/tf/gcn">GCN example</a> for the complete codes.</p>
<p>We have implemented a rich set of popular models,
including GCN, GAT, GraphSage, DeepWalk, LINE, TransE,
Bipartite GraphSage, sample-based GCN, GAT, etc., which can be used
as a starting point for building a similar model.</p>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="frequently_asked_questions.html" class="btn btn-neutral float-right" title="Frequently Asked Questions" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="interactive_engine.html" class="btn btn-neutral" title="GraphScope Interactive Engine" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020-2023, Damo Academy, Alibaba Inc.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
    

  

  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
  

  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="fa fa-book"> Read the Docs</span>
      v: v0.6.1
      <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
      <dl>
        <dt>Versions</dt>
        
          

            
              
                <dd><a href="../latest/index.html">latest</a></dd>
              
            

          
        
          

            
              
                <dd><a href="../index.html">stable</a></dd>
              
            

          
        
          

            
              
                <dd><a href="../v0.6.1/index.html">v0.6.1</a></dd>
              
            

          
        
          

            
              
                <dd><a href="../v0.6.0/index.html">v0.6.0</a></dd>
              
            

          
        
          

            
              
                <dd><a href="../v0.5.0/index.html">v0.5.0</a></dd>
              
            

          
        
          

            
              
                <dd><a href="../v0.4.1/index.html">v0.4.1</a></dd>
              
            

          
        
          

            
              
                <dd><a href="../v0.4.0/index.html">v0.4.0</a></dd>
              
            

          
        
          

            
              
                <dd><a href="../v0.3.0/index.html">v0.3.0</a></dd>
              
            

          
        
          

            
              
                <dd><a href="../v0.2.1/index.html">v0.2.1</a></dd>
              
            

          
        
          

            
              
                <dd><a href="../v0.2.0/index.html">v0.2.0</a></dd>
              
            

          
        
          

            
              
                <dd><a href="../v0.1.3/index.html">v0.1.3</a></dd>
              
            

          
        
          

            
              
                <dd><a href="../v0.1.2/index.html">v0.1.2</a></dd>
              
            

          
        
          

            
              
                <dd><a href="../v0.1.1/index.html">v0.1.1</a></dd>
              
            

          
        
          

            
              
                <dd><a href="../v0.1.0/index.html">v0.1.0</a></dd>
              
            

          
        
      </dl>
    </div>
  </div>

  <div class="rst-languages shift-up" role="note" aria-label="languages">
    <div class="rst-other-languages">
      <dl>
        <dt>Languages</dt>
        <dd><a href="index.html">en</a></dd>
        <dd><a href="zh/index.html">zh_CN</a></dd>
      </dl>

      <hr />
      <small>
        <span>Hosted by <a href="https://pages.github.com/">Github Pages</a>.</span>
      </small>
    </div>
  </div>


</body>
</html>