<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Developing Your Own Model &mdash; GraphScope  documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />

 

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-4TMYCGJ0X2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-4TMYCGJ0X2');
</script>

<script>
  var _hmt = _hmt || [];
  (function() {
    var hm = document.createElement("script");
    hm.src = "https://hm.baidu.com/hm.js?da649ade2298891886e31922dfc8870f";
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(hm, s);
  })();
</script>


</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> GraphScope
          </a>
              <div class="version">
                latest
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div>
  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      
      
        
          
        
      
      
        <p class="caption"><span class="caption-text">Contents</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deployment.html">Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../loading_graph.html">Loading Graphs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../graph_transformation.html">Graph Transformations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../analytics_engine.html">GraphScope Analytical Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../interactive_engine.html">GraphScope Interactive Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../learning_engine.html">GraphScope Learning Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../persistent_graph_store.html">Persistent Graph Store</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../frequently_asked_questions.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../developer_guide.html">Developer Guide</a></li>
</ul>
<p class="caption"><span class="caption-text">Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../python_index.html">Python API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../analytical_engine_index.html">Analytical Engine API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gae_java/index.html">Analytical Engine Java API Reference</a></li>
</ul>

      
    
  </div>

      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">GraphScope</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Developing Your Own Model</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/alibaba/graphscope/edit/main/docs/reference/gnn_engine/algo_en.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="developing-your-own-model">
<h1>Developing Your Own Model<a class="headerlink" href="#developing-your-own-model" title="Permalink to this headline"></a></h1>
<p>In this document, we will introduce how to use the basic APIs provided
by <strong>GL</strong> to cooperate with deep learning engines, such as TensorFlow,
to build graph learning algorithms. We demonstrate the GCN model as an
example which is the most popular model in graph neural network. In
<a class="reference external" href="model_programming_cn.md">Algorithm Programming Paradigm</a>, we
introduced some basic concepts used in developing algorithms, such as
ʻEgoGraph<code class="docutils literal notranslate"><span class="pre">,</span> <span class="pre">ʻEgoTensor</span></code> encoder, etc. Please understand these basic
concepts before continuing to read.</p>
</div>
<div class="section" id="how-to-build-a-graph-learning-algorithm">
<h1>How to Build a Graph Learning Algorithm<a class="headerlink" href="#how-to-build-a-graph-learning-algorithm" title="Permalink to this headline"></a></h1>
<p>In general, it requires the following four steps to build an algorithm</p>
<ul>
<li><p>Specify sampling mode: use graph sampling and query methods to sample
subgraphs and organize them into <code class="docutils literal notranslate"><span class="pre">EgoGraph</span></code></p>
<p>We abstract out four basic functions, <code class="docutils literal notranslate"><span class="pre">sample_seed</span></code>,
<code class="docutils literal notranslate"><span class="pre">positive_sample</span></code>, <code class="docutils literal notranslate"><span class="pre">negative_sample</span></code> and <code class="docutils literal notranslate"><span class="pre">receptive_fn</span></code>. To
generate <code class="docutils literal notranslate"><span class="pre">Node</span></code> or <code class="docutils literal notranslate"><span class="pre">Edges</span></code>, we use <code class="docutils literal notranslate"><span class="pre">sample_seed</span></code> to traverse
the graph. Then, we use <code class="docutils literal notranslate"><span class="pre">positive_sample</span></code> with <code class="docutils literal notranslate"><span class="pre">Nodes</span></code> or
<code class="docutils literal notranslate"><span class="pre">Edges</span></code> as inputs to generate positive samples for training. For
unsupervised learning <code class="docutils literal notranslate"><span class="pre">negative_sample</span></code> produces negative samples.
GNNs need to aggregate neighbor information so that we abstract
<code class="docutils literal notranslate"><span class="pre">receptive_fn</span></code> to sample neighbors. Finally, the <code class="docutils literal notranslate"><span class="pre">Nodes</span></code> and
<code class="docutils literal notranslate"><span class="pre">Edges</span></code> produced by <code class="docutils literal notranslate"><span class="pre">sample_seed</span></code>, and their sampled neighbors
form an <code class="docutils literal notranslate"><span class="pre">EgoGraph</span></code>.</p>
</li>
<li><p>Construct graph data flow: convert <code class="docutils literal notranslate"><span class="pre">EgoGraph</span></code> to <code class="docutils literal notranslate"><span class="pre">EgoTensor</span></code>
using <code class="docutils literal notranslate"><span class="pre">EgoFlow</span></code></p>
<p><strong>GL</strong> algorithm model is based on a deep learning engine similar to
TensorFlow. As a result, it requires to convert the sampled
<code class="docutils literal notranslate"><span class="pre">EgoGraph</span></code>s to the tensor format <code class="docutils literal notranslate"><span class="pre">EgoTensor</span></code>, which is
encapsulated in <code class="docutils literal notranslate"><span class="pre">EgoFlow</span></code> that can generate an iterator for batch
training.</p>
</li>
<li><p>Define encoder: Use <code class="docutils literal notranslate"><span class="pre">EgoGraph</span></code> encoder and feature encoder to
encode <code class="docutils literal notranslate"><span class="pre">EgoTensor</span></code></p>
<p>After getting the <code class="docutils literal notranslate"><span class="pre">EgoTensor</span></code>, we first encode the original nodes
and edge features into vectors using common feature encoders. Then,
we feed the vectors into a GNN model as the feature input. Next, we
use the graph encoder to process the <code class="docutils literal notranslate"><span class="pre">EgoTensor</span></code>, combining the
neighbor node features with its characteristics to get the nodes or
edge vectors.</p>
</li>
<li><p>Design loss functions and training processes: select the appropriate
loss function and write the training process.</p>
<p><strong>GL</strong> has built-in common loss functions and optimizers. It also
encapsulates the training process. <strong>GL</strong> supports both
single-machine and distributed training. Users can also customize the
loss functions, optimizers and training processes.</p>
</li>
</ul>
<p>Next, we introduce how to implement a GCN model using the above 4 steps.</p>
<div class="section" id="sampling">
<h2>Sampling<a class="headerlink" href="#sampling" title="Permalink to this headline"></a></h2>
<p>We use the Cora dataset as the node classification example. We provide a
simple data conversion script <code class="docutils literal notranslate"><span class="pre">cora.py</span></code> to convert the original Cora
to the format required by <strong>GL</strong>. The script generates following 5
files: node_table, edge_table_with_self_loop, train_table, val_table and
test_table. They are the node table, the edge table, and the nodes
tables used to distinguish training, validation, and testing sets.</p>
<p>Then, we can construct the graph using the following code.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">g</span> <span class="o">=</span> <span class="n">gl</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>\
      <span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="n">dataset_folder</span> <span class="o">+</span> <span class="s2">&quot;node_table&quot;</span><span class="p">,</span> <span class="n">node_type</span><span class="o">=</span><span class="n">node_type</span><span class="p">,</span>
            <span class="n">decoder</span><span class="o">=</span><span class="n">gl</span><span class="o">.</span><span class="n">Decoder</span><span class="p">(</span><span class="n">labeled</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                               <span class="n">attr_types</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;float&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">1433</span><span class="p">,</span>
                               <span class="n">attr_delimiter</span><span class="o">=</span><span class="s2">&quot;:&quot;</span><span class="p">))</span>\
      <span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="n">dataset_folder</span> <span class="o">+</span> <span class="s2">&quot;edge_table_with_self_loop&quot;</span><span class="p">,</span>
            <span class="n">edge_type</span><span class="o">=</span><span class="p">(</span><span class="n">node_type</span><span class="p">,</span> <span class="n">node_type</span><span class="p">,</span> <span class="n">edge_type</span><span class="p">),</span>
            <span class="n">decoder</span><span class="o">=</span><span class="n">gl</span><span class="o">.</span><span class="n">Decoder</span><span class="p">(</span><span class="n">weighted</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">directed</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>\
      <span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="n">dataset_folder</span> <span class="o">+</span> <span class="s2">&quot;train_table&quot;</span><span class="p">,</span> <span class="n">node_type</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">,</span>
            <span class="n">decoder</span><span class="o">=</span><span class="n">gl</span><span class="o">.</span><span class="n">Decoder</span><span class="p">(</span><span class="n">weighted</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>\
      <span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="n">dataset_folder</span> <span class="o">+</span> <span class="s2">&quot;val_table&quot;</span><span class="p">,</span> <span class="n">node_type</span><span class="o">=</span><span class="s2">&quot;val&quot;</span><span class="p">,</span>
            <span class="n">decoder</span><span class="o">=</span><span class="n">gl</span><span class="o">.</span><span class="n">Decoder</span><span class="p">(</span><span class="n">weighted</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>\
      <span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="n">dataset_folder</span> <span class="o">+</span> <span class="s2">&quot;test_table&quot;</span><span class="p">,</span> <span class="n">node_type</span><span class="o">=</span><span class="s2">&quot;test&quot;</span><span class="p">,</span>
            <span class="n">decoder</span><span class="o">=</span><span class="n">gl</span><span class="o">.</span><span class="n">Decoder</span><span class="p">(</span><span class="n">weighted</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>
</div>
<p>We load the graph into memory by calling <code class="docutils literal notranslate"><span class="pre">g.init()</span></code>.</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">graphlearn</span> <span class="k">as</span> <span class="nn">gl</span>
<span class="k">class</span> <span class="nc">GCN</span><span class="p">(</span><span class="n">gl</span><span class="o">.</span><span class="n">LearningBasedModel</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">graph</span><span class="p">,</span>
               <span class="n">output_dim</span><span class="p">,</span>
               <span class="n">features_num</span><span class="p">,</span>
               <span class="n">batch_size</span><span class="p">,</span>
               <span class="n">categorical_attrs_desc</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span>
               <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
               <span class="n">hops_num</span><span class="o">=</span><span class="mi">2</span><span class="p">,):</span>
  <span class="bp">self</span><span class="o">.</span><span class="n">graph</span> <span class="o">=</span> <span class="n">graph</span>
  <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
</pre></div>
</div>
<p>The GCN model inherits from the basic learning model class
<code class="docutils literal notranslate"><span class="pre">LearningBasedModel</span></code>. As a result, we only need to override the
sampling, model construction, and other methods to build GCN model.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">GCN</span><span class="p">(</span><span class="n">gl</span><span class="o">.</span><span class="n">LearningBasedModel</span><span class="p">):</span>
  <span class="c1"># ...</span>
  <span class="k">def</span> <span class="nf">_sample_seed</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">V</span><span class="p">(</span><span class="s1">&#39;train&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">_positive_sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
      <span class="k">return</span> <span class="n">gl</span><span class="o">.</span><span class="n">Edges</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">ids</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_type</span><span class="p">,</span>
                      <span class="n">t</span><span class="o">.</span><span class="n">ids</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_type</span><span class="p">,</span>
                      <span class="bp">self</span><span class="o">.</span><span class="n">edge_type</span><span class="p">,</span> <span class="n">graph</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_receptive_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nodes</span><span class="p">):</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">V</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="n">feed</span><span class="o">=</span><span class="n">nodes</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s1">&#39;v&#39;</span><span class="p">)</span> \
        <span class="o">.</span><span class="n">outV</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">edge_type</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span><span class="o">.</span><span class="n">by</span><span class="p">(</span><span class="s1">&#39;full&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s1">&#39;v1&#39;</span><span class="p">)</span> \
        <span class="o">.</span><span class="n">outV</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">edge_type</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span><span class="o">.</span><span class="n">by</span><span class="p">(</span><span class="s1">&#39;full&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s1">&#39;v2&#39;</span><span class="p">)</span> \
        <span class="o">.</span><span class="n">emit</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">gl</span><span class="o">.</span><span class="n">EgoGraph</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s1">&#39;v&#39;</span><span class="p">],</span> <span class="p">[</span><span class="n">ag</span><span class="o">.</span><span class="n">Layer</span><span class="p">(</span><span class="n">nodes</span><span class="o">=</span><span class="n">x</span><span class="p">[</span><span class="s1">&#39;v1&#39;</span><span class="p">]),</span> <span class="n">ag</span><span class="o">.</span><span class="n">Layer</span><span class="p">(</span><span class="n">nodes</span><span class="o">=</span><span class="n">x</span><span class="p">[</span><span class="s1">&#39;v2&#39;</span><span class="p">])]))</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">_sample_seed</span></code> and <code class="docutils literal notranslate"><span class="pre">_positive_sample</span></code> use to sample seed nodes and
positive samples. <code class="docutils literal notranslate"><span class="pre">_receptive_fn</span></code> samples neighbors and organizes
<code class="docutils literal notranslate"><span class="pre">EgoGraph</span></code>. <code class="docutils literal notranslate"><span class="pre">OutV</span></code> returns one-hop neighbors so the above code
samples two-hop neighbors. Users can choose different neighbor sampling
methods. For the original GCN, it requires all neighbors of each node
are so we use ‘full’ for sampling. We aggregate the sampling results in
<code class="docutils literal notranslate"><span class="pre">EgoGraph</span></code> which is the return value.</p>
<p>### Graph Data Flow</p>
<p>In <code class="docutils literal notranslate"><span class="pre">build</span></code> function, we convert <code class="docutils literal notranslate"><span class="pre">EgoGraph</span></code> to <code class="docutils literal notranslate"><span class="pre">EgoTensor</span></code> using
<code class="docutils literal notranslate"><span class="pre">EgoFlow</span></code>. <code class="docutils literal notranslate"><span class="pre">EgoFlow</span></code> contains an data flow iterator and several
<code class="docutils literal notranslate"><span class="pre">EgoTensor</span></code>s.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">GCN</span><span class="p">(</span><span class="n">gl</span><span class="o">.</span><span class="n">LearningBasedModel</span><span class="p">):</span>
 <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
   <span class="n">ego_flow</span> <span class="o">=</span> <span class="n">gl</span><span class="o">.</span><span class="n">EgoFlow</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_sample_seed</span><span class="p">,</span>
                         <span class="bp">self</span><span class="o">.</span><span class="n">_positive_sample</span><span class="p">,</span>
                         <span class="bp">self</span><span class="o">.</span><span class="n">_receptive_fn</span><span class="p">,</span>
                         <span class="bp">self</span><span class="o">.</span><span class="n">src_ego_spec</span><span class="p">)</span>
   <span class="n">iterator</span> <span class="o">=</span> <span class="n">ego_flow</span><span class="o">.</span><span class="n">iterator</span>
   <span class="n">pos_src_ego_tensor</span> <span class="o">=</span> <span class="n">ego_flow</span><span class="o">.</span><span class="n">pos_src_ego_tensor</span>
   <span class="c1"># ...</span>
</pre></div>
</div>
<p>We can get the <code class="docutils literal notranslate"><span class="pre">EgoTensor</span></code> corresponding to the previous <code class="docutils literal notranslate"><span class="pre">EgoGraph</span></code>
from <code class="docutils literal notranslate"><span class="pre">EgoFlow</span></code>.</p>
</div>
<div class="section" id="encoder">
<h2>Encoder<a class="headerlink" href="#encoder" title="Permalink to this headline"></a></h2>
<p>Next, we first use the feature encoder to encode the original features.
In this example, we use <code class="docutils literal notranslate"><span class="pre">IdentityEncoder</span></code> that returns itself, because
the features of cora are already in vector formats. For the both
discrete and continuous features, we can use <code class="docutils literal notranslate"><span class="pre">WideNDeepEncoder</span></code>, To
learn more encoders, please refer to
<code class="docutils literal notranslate"><span class="pre">python/model/tf/encoders/feature_encoder.py</span></code>. Then, we use the
<code class="docutils literal notranslate"><span class="pre">GCNConv</span></code> layer to construct the graph encoder. For each node in GCN,
we sample all of its neighbors, and organize them in a sparse format.
Therefore, we use <code class="docutils literal notranslate"><span class="pre">SparseEgoGraphEncoder</span></code>. For the neighbor-aligned
model, please refer to the implementation of GraphSAGE.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">GCN</span><span class="p">(</span><span class="n">gl</span><span class="o">.</span><span class="n">LearningBasedModel</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">_encoders</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">depth</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hops_num</span>
    <span class="n">feature_encoders</span> <span class="o">=</span> <span class="p">[</span><span class="n">gl</span><span class="o">.</span><span class="n">encoders</span><span class="o">.</span><span class="n">IdentityEncoder</span><span class="p">()]</span> <span class="o">*</span> <span class="p">(</span><span class="n">depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">conv_layers</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># for input layer</span>
    <span class="n">conv_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">gl</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">GCNConv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">))</span>
    <span class="c1"># for hidden layer</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">depth</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
      <span class="n">conv_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">gl</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">GCNConv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">))</span>
    <span class="c1"># for output layer</span>
    <span class="n">conv_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">gl</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">GCNConv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">,</span> <span class="n">act</span><span class="o">=</span><span class="kc">None</span><span class="p">))</span>
    <span class="n">encoder</span> <span class="o">=</span> <span class="n">gl</span><span class="o">.</span><span class="n">encoders</span><span class="o">.</span><span class="n">SparseEgoGraphEncoder</span><span class="p">(</span><span class="n">feature_encoders</span><span class="p">,</span>
                                                  <span class="n">conv_layers</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;src&quot;</span><span class="p">:</span> <span class="n">encoder</span><span class="p">,</span> <span class="s2">&quot;edge&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;dst&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="loss-function-and-training-process">
<h2>Loss Function and Training Process<a class="headerlink" href="#loss-function-and-training-process" title="Permalink to this headline"></a></h2>
<p>For the Cora node classification model, we can select the corresponding
classification loss function in TensorFlow. Then, we combine the encoder
and loss function in the <code class="docutils literal notranslate"><span class="pre">build</span></code> function, and finally return a data
iterator and a loss function.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">GCN</span><span class="p">(</span><span class="n">gl</span><span class="o">.</span><span class="n">LearningBasedModel</span><span class="p">):</span>
  <span class="c1"># ...</span>
  <span class="k">def</span> <span class="nf">_supervised_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">emb</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sparse_softmax_cross_entropy_with_logits</span><span class="p">(</span><span class="n">emb</span><span class="p">,</span> <span class="n">label</span><span class="p">))</span>

  <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">ego_flow</span> <span class="o">=</span> <span class="n">gl</span><span class="o">.</span><span class="n">EgoFlow</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_sample_seed</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">_positive_sample</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">_receptive_fn</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">src_ego_spec</span><span class="p">,</span>
                          <span class="n">full_graph_mode</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">full_graph_mode</span><span class="p">)</span>
    <span class="n">iterator</span> <span class="o">=</span> <span class="n">ego_flow</span><span class="o">.</span><span class="n">iterator</span>
    <span class="n">pos_src_ego_tensor</span> <span class="o">=</span> <span class="n">ego_flow</span><span class="o">.</span><span class="n">pos_src_ego_tensor</span>
    <span class="n">src_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoders</span><span class="p">[</span><span class="s1">&#39;src&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">pos_src_ego_tensor</span><span class="p">)</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">pos_src_ego_tensor</span><span class="o">.</span><span class="n">src</span><span class="o">.</span><span class="n">labels</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_supervised_loss</span><span class="p">(</span><span class="n">src_emb</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">iterator</span>
</pre></div>
</div>
<p>Next, we use <code class="docutils literal notranslate"><span class="pre">LocalTFTrainer</span></code> to train on a single-machine.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">graph</span><span class="p">)</span>
  <span class="k">def</span> <span class="nf">model_fn</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">GCN</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span>
               <span class="n">config</span><span class="p">[</span><span class="s1">&#39;class_num&#39;</span><span class="p">],</span>
               <span class="n">config</span><span class="p">[</span><span class="s1">&#39;features_num&#39;</span><span class="p">],</span>
               <span class="n">config</span><span class="p">[</span><span class="s1">&#39;batch_szie&#39;</span><span class="p">],</span>
               <span class="o">...</span><span class="p">)</span>
  <span class="n">trainer</span> <span class="o">=</span> <span class="n">gl</span><span class="o">.</span><span class="n">LocalTFTrainer</span><span class="p">(</span><span class="n">model_fn</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
  <span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">config</span> <span class="o">=</span> <span class="p">{</span><span class="o">...</span><span class="p">}</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">load_graph</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
    <span class="n">g</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">server_id</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">server_count</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">tracker</span><span class="o">=</span><span class="s1">&#39;../../data/&#39;</span><span class="p">)</span>
    <span class="n">train</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">g</span><span class="p">)</span>
</pre></div>
</div>
<p>This concludes building a GCN model. Please refer to the examples/GCN
directory for the complete code.</p>
<p>We have implemented GCN, GAT, GraphSage, DeepWalk, LINE, TransE,
Bipartite GraphSage, sample-based GCN and GAT models, which can be used
as a starting point for building a similar model.</p>
</div>
</div>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020-2023, DAMO Academy, Alibaba Inc..</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
  

  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="fa fa-book"> Read the Docs</span>
      v: latest
      <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
      <dl>
        <dt>Versions</dt>
        
          

            
              
                <dd><a href="../../../latest/index.html">latest</a></dd>
              
            

          
        
          

            
              
                <dd><a href="../../../index.html">stable</a></dd>
              
            

          
        
          

            
              
                <dd><a href="../../../v0.16.0/index.html">v0.16.0</a></dd>
              
            

          
        
          

            
              
                <dd><a href="../../../v0.15.0/index.html">v0.15.0</a></dd>
              
            

          
        
          

            
              
                <dd><a href="../../../v0.14.0/index.html">v0.14.0</a></dd>
              
            

          
        
          

            
              
                <dd><a href="../../../v0.13.0/index.html">v0.13.0</a></dd>
              
            

          
        
          

            
              
                <dd><a href="../../../v0.12.0/index.html">v0.12.0</a></dd>
              
            

          
        
          

            
              
                <dd><a href="../../../v0.11.0/index.html">v0.11.0</a></dd>
              
            

          
        
          

            
              
                <dd><a href="../../../v0.10.1/index.html">v0.10.1</a></dd>
              
            

          
        
          

            
              
                <dd><a href="../../../v0.10.0/index.html">v0.10.0</a></dd>
              
            

          
        
          

            
              
                <dd><a href="../../../v0.9.1/index.html">v0.9.1</a></dd>
              
            

          
        
          

            
              
                <dd><a href="../../../v0.9.0/index.html">v0.9.0</a></dd>
              
            

          
        
          

            
              
                <dd><a href="../../../v0.8.0/index.html">v0.8.0</a></dd>
              
            

          
        
          

            
              
                <dd><a href="../../../v0.7.0/index.html">v0.7.0</a></dd>
              
            

          
        
          

            
              
                <dd><a href="../../../v0.6.1/index.html">v0.6.1</a></dd>
              
            

          
        
          

            
              
                <dd><a href="../../../v0.6.0/index.html">v0.6.0</a></dd>
              
            

          
        
          

            
              
                <dd><a href="../../../v0.5.0/index.html">v0.5.0</a></dd>
              
            

          
        
          

            
              
                <dd><a href="../../../v0.4.1/index.html">v0.4.1</a></dd>
              
            

          
        
          

            
              
                <dd><a href="../../../v0.4.0/index.html">v0.4.0</a></dd>
              
            

          
        
          

            
              
                <dd><a href="../../../v0.3.0/index.html">v0.3.0</a></dd>
              
            

          
        
          

            
              
                <dd><a href="../../../v0.2.1/index.html">v0.2.1</a></dd>
              
            

          
        
          

            
              
                <dd><a href="../../../v0.2.0/index.html">v0.2.0</a></dd>
              
            

          
        
          

            
              
                <dd><a href="../../../v0.1.3/index.html">v0.1.3</a></dd>
              
            

          
        
          

            
              
                <dd><a href="../../../v0.1.2/index.html">v0.1.2</a></dd>
              
            

          
        
          

            
              
                <dd><a href="../../../v0.1.1/index.html">v0.1.1</a></dd>
              
            

          
        
          

            
              
                <dd><a href="../../../v0.1.0/index.html">v0.1.0</a></dd>
              
            

          
        
      </dl>
    </div>
  </div>

  <div class="rst-languages shift-up" role="note" aria-label="languages">
    <div class="rst-other-languages">
      <dl>
        <dt>Languages</dt>
        <dd><a href="../../index.html">en</a></dd>
        <dd><a href="../../zh/index.html">zh_CN</a></dd>
      </dl>

      <hr />
      <small>
        <span>Hosted by <a href="https://pages.github.com/">Github Pages</a>.</span>
      </small>
    </div>
  </div>


</body>
</html>