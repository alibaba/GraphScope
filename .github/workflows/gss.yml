name: GraphScope Store CI

on:
  # Trigger the workflow on push or pull request,
  # but only for the main branch
  push:
    branches:
      - main
    paths-ignore:
      - 'CONTRIBUTORS'
      - 'LICENSE'
      - 'NOTICE.txt'
      - '**.md'
      - '**.rst'
      - 'docs/**'
      - 'demo/**'
      - 'scripts/**'
      - 'tutorials/**'
  pull_request:
    branches:
      - main
    paths:
      - 'proto/**'
      - 'interactive_engine/**'
      - 'python/graphscope/client/**'
      - 'charts/graphscope-store/**'
      - '.github/workflows/gss.yml'
      - '!interactive_engine/**.md'
      - '!charts/graphscope-store/**.md'

concurrency:
  group: ${{ github.repository }}-${{ github.event.number || github.head_ref || github.sha }}-${{ github.workflow }}
  cancel-in-progress: true

env:
  GSS_IMAGE: registry.cn-hongkong.aliyuncs.com/graphscope/graphscope-store

jobs:
  gremlin-test:
    # Require the host is able to run docker without sudo and
    # can `ssh localhost` without password, which may need to
    # be configured manually when a new self-hosted runner is added.
    runs-on: [self-hosted, manylinux2014]
    if: ${{ github.repository == 'alibaba/GraphScope' }}
    steps:
    - uses: actions/checkout@v3
    - uses: actions/cache@v3
      with:
        path: ~/.m2/repository
        key: ${{ runner.os }}-maven-${{ hashFiles('**/pom.xml') }}
        restore-keys: |
          ${{ runner.os }}-maven-

    - uses: actions/cache@v3
      with:
        path: |
          ~/.cargo/bin/
          ~/.cargo/registry/index/
          ~/.cargo/registry/cache/
          ~/.cargo/git/db/
          ~/.cache/sccache
        key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}

    - name: Install Dependencies
      run: |
        # install rdkafka
        sudo yum install -y librdkafka-devel

        # install cppkafka
        git clone -b 0.4.0 --single-branch --depth=1 \
            https://github.com/mfontanini/cppkafka.git /tmp/cppkafka && \
          cd /tmp/cppkafka && git submodule update --init && \
          mkdir -p build && cd build && \
          cmake .. && make -j && sudo make install && \
          rm -fr /tmp/cppkafka

    - name: Build GraphScope Store With Column Filter Push Down
      run: |
        source ${HOME}/.bashrc
        export SCCACHE_DIR=~/.cache/sccache
        export RUSTC_WRAPPER=/usr/local/bin/sccache
        sccache --start-server
        cd ${GITHUB_WORKSPACE}/interactive_engine
        mvn clean install -P groot,groot-assembly -Drust.compile.mode=debug -DskipTests -Dgroot.compile.feature="column_filter_push_down" --quiet

        sccache --show-stats

    - name: Gremlin Tests with Column Filter Push Down
      run: |
        cd interactive_engine/groot-server
        mvn test -P gremlin-test

    - name: Setup tmate session
      run: |
        sleep 1800
      if: always()

    - name: Build GraphScope Store
      run: |
        source ${HOME}/.bashrc
        export SCCACHE_DIR=~/.cache/sccache
        export RUSTC_WRAPPER=/usr/local/bin/sccache
        cd ${GITHUB_WORKSPACE}/interactive_engine
        mvn clean install -P groot,groot-assembly -Drust.compile.mode=debug -DskipTests --quiet

        sccache --show-stats

    - name: Gremlin Test
      run: |
        cd interactive_engine/groot-server
        mvn test -P gremlin-test

    - name: Upload tools for helm test to Artifact
      uses: actions/upload-artifact@v3
      with:
        name: groot.tar.gz
        path: interactive_engine/assembly/target/groot.tar.gz
        retention-days: 5

  helm-test:
    runs-on: [self-hosted, ubuntu2004]
    if: ${{ github.repository == 'alibaba/GraphScope' }}
    needs: [gremlin-test]
    steps:
    - uses: actions/checkout@v3
      with:
        submodules: true

    - uses: actions/download-artifact@v3
      with:
        name: groot.tar.gz
        path: artifacts

    - name: Set GITHUB_ENV
      run: |
        short_sha=$(git rev-parse --short HEAD)
        echo "SHORT_SHA=${short_sha}" >> $GITHUB_ENV

    - name: Prepare Image
      run: |
        docker build -t ${{ env.GSS_IMAGE }}:${SHORT_SHA} \
                -f .github/workflows/docker/graphscope-store.Dockerfile .

    - name: Setup SSH
      run: |
        ssh-keygen -t rsa -f ~/.ssh/id_rsa -N ''
        cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
        chmod og-wx ~/.ssh/authorized_keys
        echo "StrictHostKeyChecking no" >> ~/.ssh/config
        sudo /etc/init.d/ssh start

    - name: Python Test with Helm Deployment
      env:
        JAVA_HOME: /usr/lib/jvm/default-java
        GS_TEST_DIR: ${{ github.workspace }}/gstest
      run: |
        # groot.tar.gz is needed for offline_load.sh
        # see .github/workflows/hadoop_scripts/offline_load.sh.template
        pushd artifacts
        tar -zxf ./groot.tar.gz
        # download gstest
        git clone -b master --single-branch --depth=1 https://github.com/7br/gstest.git ${GS_TEST_DIR}

        minikube start --base-image='registry-vpc.cn-hongkong.aliyuncs.com/graphscope/kicbase:v0.0.30' \
                        --cpus='12' --memory='32000mb' --disk-size='40000mb'

        minikube image load ${{ env.GSS_IMAGE }}:${SHORT_SHA}

        # update helm dependency
        cd ${GITHUB_WORKSPACE}/charts/graphscope-store
        helm dependency update

        # helm deployment and testing
        cd ${GITHUB_WORKSPACE}/charts
        helm install ci --set image.tag=${SHORT_SHA} ./graphscope-store
        helm test ci --timeout 5m0s

        # 1. get gss service endpoint
        export GRPC_PORT=$(kubectl get --namespace default -o jsonpath="{.spec.ports[0].nodePort}" services ci-graphscope-store-frontend)
        export GREMLIN_PORT=$(kubectl get --namespace default -o jsonpath="{.spec.ports[1].nodePort}" services ci-graphscope-store-frontend)
        export NODE_IP=$(kubectl get nodes --namespace default -o jsonpath="{.items[0].status.addresses[0].address}")

        # 2. deploy hadoop hdfs
        tar -zxf /home/runner/hadoop-2.10.1.tar.gz -C /tmp/
        cd ${GITHUB_WORKSPACE}/.github/workflows/hadoop_scripts
        ./prepare_hadoop.sh /tmp/hadoop-2.10.1
        export PATH=${PATH}:/tmp/hadoop-2.10.1/bin

        REPLACE_STR=${GITHUB_WORKSPACE}/artifacts/groot
        sed s/GROOT_HOME/${REPLACE_STR//\//\\/}/ offline_load.sh.template > offline_load.sh
        chmod +x offline_load.sh
        export LOAD_DATA_SCRIPT=${GITHUB_WORKSPACE}/.github/workflows/hadoop_scripts/offline_load.sh
        sed s/GRAPH_ENDPOINT/$NODE_IP:$GRPC_PORT/ databuild.config.template > databuild.config

        # 3. upload data to HDFS
        hadoop fs -mkdir /ldbc_sample || true
        hadoop fs -put ${GS_TEST_DIR}/ldbc_sample/person_0_0.csv /ldbc_sample/person_0_0.csv
        hadoop fs -put ${GS_TEST_DIR}/ldbc_sample/person_knows_person_0_0.csv /ldbc_sample/person_knows_person_0_0.csv
        # python test
        cd ${GITHUB_WORKSPACE}/python
        python3 -m pip install -r ./requirements.txt --user
        python3 -m pip install -r ./requirements-dev.txt --user
        python3 -m pip install pytest-cov --user
        python3 setup.py build_proto
        python3 -m pytest -s -vvv graphscope/tests/kubernetes/test_store_service.py -k test_demo_fresh
        # restart helm and run demo with the PersistentVolume
        helm uninstall ci
        cd ${GITHUB_WORKSPACE}/charts
        helm install ci --set image.tag=${SHORT_SHA} ./graphscope-store
        # helm test and python test on the restarted store
        export GRPC_PORT=$(kubectl get --namespace default -o jsonpath="{.spec.ports[0].nodePort}" services ci-graphscope-store-frontend)
        export GREMLIN_PORT=$(kubectl get --namespace default -o jsonpath="{.spec.ports[1].nodePort}" services ci-graphscope-store-frontend)
        export NODE_IP=$(kubectl get nodes --namespace default -o jsonpath="{.items[0].status.addresses[0].address}")
        helm test ci --timeout 5m0s
        cd ${GITHUB_WORKSPACE}/python
        python3 -m pytest -s -vvv graphscope/tests/kubernetes/test_store_service.py -k test_demo_after_restart
