name: GraphScope Store CI

on:
  # Trigger the workflow on push or pull request,
  # but only for the main branch
  push:
    branches:
      - main
    paths-ignore:
      - 'CONTRIBUTORS'
      - 'LICENSE'
      - 'NOTICE.txt'
      - '**.md'
      - '**.rst'
      - 'docs/**'
      - 'demo/**'
      - 'scripts/**'
      - 'tutorials/**'
  pull_request:
    branches:
      - main
    paths:
      - 'proto/**'
      - 'interactive_engine/**'
      - 'python/graphscope/client/**'
      - 'charts/graphscope-store/**'
      - '.github/workflows/gss.yml'
      - '!interactive_engine/**.md'
      - '!charts/graphscope-store/**.md'

concurrency:
  group: ${{ github.repository }}-${{ github.event.number || github.head_ref || github.sha }}-${{ github.workflow }}
  cancel-in-progress: true

env:
  GSS_IMAGE: registry.cn-hongkong.aliyuncs.com/graphscope/graphscope-store

jobs:
  gremlin-test:
    # Require the host is able to run docker without sudo and
    # can `ssh localhost` without password, which may need to
    # be configured manually when a new self-hosted runner is added.
    runs-on: [self-hosted, manylinux2014]
    if: ${{ github.repository == 'alibaba/GraphScope' }}
    steps:
    - uses: actions/checkout@v2
    - uses: actions/cache@v3
      with:
        path: ~/.m2/repository
        key: ${{ runner.os }}-maven-${{ hashFiles('**/pom.xml') }}
        restore-keys: |
          ${{ runner.os }}-maven-

    - uses: actions/cache@v3
      with:
        path: |
          ~/.cargo/bin/
          ~/.cargo/registry/index/
          ~/.cargo/registry/cache/
          ~/.cargo/git/db/
          ~/.cache/sccache
        key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}

    - name: Install Dependencies
      run: |
        # install rdkafka
        sudo yum install -y librdkafka-devel

        # install cppkafka
        git clone -b 0.4.0 --single-branch --depth=1 \
            https://github.com/mfontanini/cppkafka.git /tmp/cppkafka && \
          cd /tmp/cppkafka && git submodule update --init && \
          mkdir -p build && cd build && \
          cmake .. && make -j && sudo make install && \
          rm -fr /tmp/cppkafka

    - name: Build GraphScope Store
      run: |
        source ${HOME}/.bashrc
        export SCCACHE_DIR=~/.cache/sccache
        export RUSTC_WRAPPER=/usr/local/bin/sccache
        sccache --start-server
        cd ${GITHUB_WORKSPACE}/interactive_engine
        mvn clean install -P groot,groot-assembly -Drust.compile.mode=debug -DskipTests --quiet

        sccache --show-stats

    - name: Gremlin Test
      run: |
        cd interactive_engine/groot-server
        mvn test -P gremlin-test

    - name: Upload tools for helm test to Artifact
      uses: actions/upload-artifact@v2
      with:
        name: groot.tar.gz
        path: interactive_engine/assembly/target/groot.tar.gz
        retention-days: 5

  helm-test:
    runs-on: [self-hosted, "47.242.9.60"]
    if: ${{ github.repository == 'alibaba/GraphScope' }}
    needs: [gremlin-test]
    steps:
    - name: Clean Up
      run: |
        echo "CI is running on host $(curl -s 'https://api.ipify.org')"
        sudo chmod -R a+wrx ${GITHUB_WORKSPACE}
        sudo rm -rf ./* || true
        find ./ -name "*.egg-info" | xargs sudo rm -rf || true
        find ./ -name "*.whl" | xargs sudo rm -rf || true
        find ./ -name "*_pb2.py" | xargs sudo rm -rf || true
        find ./ -name "*_pb2_grpc.py" | xargs sudo rm -rf || true
    - uses: actions/checkout@v2
      with:
        submodules: true

    - uses: actions/download-artifact@v2
      with:
        name: groot.tar.gz
        path: artifacts

    - name: Set GITHUB_ENV
      run: |
        short_sha=$(git rev-parse --short HEAD)
        echo "SHORT_SHA=${short_sha}" >> $GITHUB_ENV

    - name: Prepare Image
      env:
        CI: true
      run: |
        make graphscope-store-image
    - name: Python Test with Helm Deployment
      env:
        JAVA_HOME: /usr/lib/jvm/default-java
        GS_TEST_DIR: ${{ github.workspace }}/gstest
      run: |
        # groot.tar.gz is needed for offline_load.sh
        # see .github/workflows/hadoop_scripts/offline_load.sh.template
        pushd artifacts
        tar -zxf ./groot.tar.gz
        # download gstest
        git clone -b master --single-branch --depth=1 https://github.com/7br/gstest.git ${GS_TEST_DIR}
        # retag image for helm test
        sudo docker tag graphscope/graphscope-store:${SHORT_SHA} \
            ${{ env.GSS_IMAGE }}:${SHORT_SHA}
        # update helm dependency
        cd ${GITHUB_WORKSPACE}/charts/graphscope-store
        helm dependency update
        # helm deployment and testing
        cd ${GITHUB_WORKSPACE}/charts
        helm install ci --set image.tag=${SHORT_SHA} ./graphscope-store
        helm test ci --timeout 5m0s
        # 1. get gss service endpoint
        export GRPC_PORT=$(kubectl get --namespace default -o jsonpath="{.spec.ports[0].nodePort}" services ci-graphscope-store-frontend)
        export GREMLIN_PORT=$(kubectl get --namespace default -o jsonpath="{.spec.ports[1].nodePort}" services ci-graphscope-store-frontend)
        export NODE_IP=$(kubectl get nodes --namespace default -o jsonpath="{.items[0].status.addresses[0].address}")
        # 2. deploy hadoop hdfs
        cd /tmp
        wget -q https://mirror.cogentco.com/pub/apache/hadoop/common/hadoop-2.10.1/hadoop-2.10.1.tar.gz
        tar -zxf hadoop-2.10.1.tar.gz
        cd ${GITHUB_WORKSPACE}/.github/workflows/hadoop_scripts
        REPLACE_STR=${GITHUB_WORKSPACE}/artifacts/groot
        sed s/GROOT_HOME/${REPLACE_STR//\//\\/}/ offline_load.sh.template > offline_load.sh
        chmod +x offline_load.sh
        export LOAD_DATA_SCRIPT=${GITHUB_WORKSPACE}/.github/workflows/hadoop_scripts/offline_load.sh
        sed s/GRAPH_ENDPOINT/$NODE_IP:$GRPC_PORT/ databuild.config.template > databuild.config
        ./prepare_hadoop.sh /tmp/hadoop-2.10.1
        export PATH=${PATH}:/tmp/hadoop-2.10.1/bin
        # 3. upload data to HDFS
        hadoop fs -mkdir /ldbc_sample || true
        hadoop fs -put ${GS_TEST_DIR}/ldbc_sample/person_0_0.csv /ldbc_sample/person_0_0.csv
        hadoop fs -put ${GS_TEST_DIR}/ldbc_sample/person_knows_person_0_0.csv /ldbc_sample/person_knows_person_0_0.csv
        # python test
        cd ${GITHUB_WORKSPACE}/python
        python3 -m pip install -r ./requirements.txt --user
        python3 -m pip install -r ./requirements-dev.txt --user
        python3 -m pip install pytest-cov --user
        python3 setup.py build_proto
        python3 -m pytest -s -vvv graphscope/tests/kubernetes/test_store_service.py -k test_demo_fresh
        # restart helm and run demo with the PersistentVolume
        helm uninstall ci
        cd ${GITHUB_WORKSPACE}/charts
        helm install ci --set image.tag=${SHORT_SHA} ./graphscope-store
        # helm test and python test on the restarted store
        export GRPC_PORT=$(kubectl get --namespace default -o jsonpath="{.spec.ports[0].nodePort}" services ci-graphscope-store-frontend)
        export GREMLIN_PORT=$(kubectl get --namespace default -o jsonpath="{.spec.ports[1].nodePort}" services ci-graphscope-store-frontend)
        export NODE_IP=$(kubectl get nodes --namespace default -o jsonpath="{.items[0].status.addresses[0].address}")
        helm test ci --timeout 5m0s
        cd ${GITHUB_WORKSPACE}/python
        python3 -m pytest -s -vvv graphscope/tests/kubernetes/test_store_service.py -k test_demo_after_restart
    - name: Clean
      if: always()
      run: |
        HADOOP_SSH_OPTS="-o StrictHostKeyChecking=no" /tmp/hadoop-2.10.1/sbin/stop-dfs.sh || true
        rm -rf /tmp/hadoop* || true
        helm uninstall ci || true
        kubectl delete pvc -l app.kubernetes.io/instance=ci --wait=false || true
        kubectl delete pod ci-graphscope-store-frontend-test-grpc-service ci-graphscope-store-frontend-test-gremlin-service --wait=false || true
        sudo docker rmi -f graphscope/graphscope-store:${SHORT_SHA}
        sudo docker rmi -f ${{ env.GSS_IMAGE }}:${SHORT_SHA} || true
